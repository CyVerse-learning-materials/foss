{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-foundational-open-science-skills-foss-fall-2024","title":"Welcome to Foundational Open Science Skills (FOSS) Fall 2024!","text":""},{"location":"#workshop-summary","title":"Workshop Summary","text":"<p>Cyverse and the University of Arizona Data Science Institute presents Foundational Open Science Skills (FOSS) as both a curriculum and a roadmap to guide your computational research and level up your teaching, collaboration, proposal writing, and publishing. FOSS online offers hands-on learning resources to build a solid Open Science foundation for your research and educational projects in a supportive atmosphere with peers and project mentors. </p> <p>The workshop focuses on introducing you to a host of software tools to help manage your data and make your science open, reproducible, and scaleable. Please see the Schedule for the list of lessons and content covered throughout the workshop. </p>"},{"location":"#workshop-structure","title":"Workshop Structure","text":"<p>Synchronously, we will meet each week virtually for 1.5 hours to discuss and have hands-on activities with our instructors. The workshop content is always available for you to read through to develop your own project-based ideas for strengthening your Open Science skills. </p> <p>Much of the content interconnects from week to week and many of the skills and approaches we discuss relate to each other. However, students should be able to derive significant value from attending single sessions. </p> <p>Our ultimate goal in this workshop is for you to \"level up\" one or more of those philosophies/approaches/skills. </p>"},{"location":"#capstone-project","title":"Capstone Project","text":"<p>Throughout the duration of the course, students will be working on a project of their choosing that uses the tools and concepts presented in FOSS. The idea is that doing something tangible related to your own science or work will help you 'level up' your open science skills. This could be solo work or a group project depending on your interests. The culmination of the project will be a short presentation to the class on the last day of the course. You can read more about it at the capstone project page.</p>"},{"location":"#expected-outcomes","title":"Expected Outcomes","text":"<ul> <li>Proficiently organize your lab, external and internal communications, and teach and conduct research with open source software</li> <li>Ability to scale out computations from laptop to the cloud and High Performance Computing/High Throughput Computing systems</li> <li>Skillfully manage your research data through the data lifecycle </li> <li>Join a larger community of Open Science practitioners</li> <li>Be an Advocate for Open Science in your professional circles and communities</li> </ul> <p>By working through an example project relevant to your interests, you will practice open science skills using CyVerse, GitHub, R or Python, and other resources. At the end of the course, you and your team will present a plan for how to integrate open science into your research, lab, or other areas of your choosing.</p> <p>Funding and Citations:</p> <p>CyVerse is funded by the Arizona Board of Regents and the US  National Science Foundation under Award Numbers: </p> <p> </p> <p>The CyVerse Zenodo Community has published, citable versions of CyVerse materials: </p> <p></p> <p>Please cite CyVerse appropriately when you make use of our resources; see CyVerse citation policy.</p> <p> </p>"},{"location":"01_intro_open_sci/","title":"Introduction to Open Science","text":"<p>Learning Objectives</p> <p>After this lesson, you should be able to:</p> <ul> <li>Explain what Open Science is</li> <li>Explain the components of Open Science</li> <li>Describe the behaviors of Open Science</li> <li>Explain why Open Science matters in education, research, and society</li> <li>Understand the advantages and the challenges to Open Science</li> </ul> <p> </p>"},{"location":"01_intro_open_sci/#what-is-open-science","title":"What is Open Science?","text":"<p>\"Open Science is transparent and accessible knowledge that is shared and developed through collaborative networks\"</p> <p>-Vincente-Saez &amp; Martinez-Fuentes 2018</p> <p> </p> <p>\"Open Science is a collaborative and transparent approach to scientific research that emphasizes the accessibility, sharing, and reproducibility of data, methodologies, and findings to foster innovation and inclusivity\"</p> <p>-ChatGPT</p> <p> </p> <p>\"A series of reforms that interrogate every step in the research life cycle to make it more efficient, powerful and accountable in our emerging digital society\".</p> <p>-Jeffrey Gillan</p> <p>  The Research Life Cycle from Open Science Framework</p> <p> </p> <p>Other Definitions</p> <p>\"Open Science is defined as an inclusive construct that combines various movements and practices aiming to make multilingual scientific knowledge openly  available,  accessible  and  reusable  for  everyone,  to  increase  scientific  collaborations  and  sharing of information for the benefits of science and society, and to open the processes of scientific knowledge creation, evaluation and communication to societal actors beyond the traditional scientific community.\" - UNESCO Definition</p> <ul> <li>UNESCO's Recommendation on Open Science</li> </ul> <p>\"Open Science is the movement to make scientific research (including publications, data, physical samples, and software) and its dissemination accessible to all levels of society, amateur or professional...\"   Wikipedia definition</p> <p></p>"},{"location":"01_intro_open_sci/#foundational-open-science-skills","title":"Foundational Open Science Skills","text":"<p>1. Building a culture of scientists eager to share research materials - such as data, code, methods, documentation, and early results - with colleagues and society at large, in addition to traditional publications </p> <p> </p> <p>2. Mastery of digital tools to create reproducible science that others can build upon</p> <p> </p> <p>3. Understanding the push towards increased transparency and accountability for those practicing science (ie., compliance)</p> <p> </p>  Open Science Word Cloud by Pownall et al. 2023 <p> </p> What is Open Science | The Royal Society <p> </p>"},{"location":"01_intro_open_sci/#2023-the-year-of-open-science","title":"2023: the Year of Open Science","text":"<p>The White House, joined by 10 federal agencies, and a coalition of more than 85 universities, declared 2023 the Year of Open Science as a way to bring awareness to the benefits of Open Science and to steer the scientitic community towards its adoption. </p> <p>NASA leads a prominent program called Transform to Open Science which includes an online class on Open Science. </p> <p>  NASA Transform to Open Science (TOPS) </p> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#6-pillars-of-open-science","title":"6 Pillars of Open Science","text":"<p> Open Access Publications</p> <p> Open Data</p> <p> Open Educational Resources</p> <p> Open Methodology</p> <p> Open Peer Review</p> <p> Open Source Software</p> Wait, how many pillars  of Open Science Are There Really? <p>The number can be from 4  to 8 </p> <p> </p>"},{"location":"01_intro_open_sci/#open-access-publications","title":"Open Access Publications","text":"<p>Definition</p> <p>\"Open access is a publishing model for scholarly communication that makes research information available to readers at no cost, as opposed to the traditional subscription model in which readers have access to scholarly information by paying a subscription (usually via libraries).\" -- OpenAccess.nl</p> <p> </p> <p>Open Access Journal Examples</p> <p>Major publishers have provided access points for publishing your work </p> <ul> <li>AAAS Science</li> <li>Nature</li> <li>American Geophysical Union</li> <li>Commonwealth Scientific and Industrial Research Organisation (CSIRO)</li> <li>Open Research Europe</li> <li>PLOS</li> <li>MDPI</li> <li>Ecosphere</li> </ul> <p> </p>"},{"location":"01_intro_open_sci/#types-of-publishing-business-models","title":"Types of Publishing Business Models:","text":"<ol> <li> <p>Subscription model - the author pays a smaller fee (or no fee) for the article to be published. The publisher then sells subscription access to the article (usually to institutes of higher education).</p> </li> <li> <p>Open Access model - The author pays a larger fee to make the article freely available to anyone through a Creative Commons license. </p> <ul> <li>Open Access publishing in Nature costs $12,290!</li> <li>Open Access publising in PlosOne costs $2,290</li> </ul> </li> </ol> <p> </p>"},{"location":"01_intro_open_sci/#research-article-versions","title":"Research Article Versions","text":"<ol> <li> <p>Preprint - In academic publishing, a preprint is a version of scholary paper that precedes formal peer-review and publication in a scientific journal. The preprint may be available, often as a non-typeset version available for free online. </p> Pre-print Services <ul> <li>ASAPbio Pre-Print Server List - ASAPbio is a scientist-driven non-profit promoting transparency and innovation comprehensive list of pre-print servers inthe field of life science communication.</li> <li>ESSOar - Earth and Space Science Open Archive hosted by the American Geophysical Union.</li> <li>Peer Community In (PCI) a free recommendation process of scientific preprints based on peer reviews</li> <li>OSF.io Preprints are partnered with numerous projects under the \"-rXivs\"</li> </ul> The rXivs <ul> <li> <p>AfricArXiv</p> </li> <li> <p>AgrirXiv</p> </li> <li> <p>Arabixiv</p> </li> <li> <p>arXiv - is a free distribution service and an open-access archive for 2,086,431 scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics.</p> </li> <li> <p>BioHackrXiv</p> </li> <li>BioRxiv -  is an open access preprint repository for the biological sciences.</li> <li>BodorXiv</li> <li>EarthArXiv - is an open access preprint repository for the Earth sciences.</li> <li>EcsArXiv - a free preprint service for electrochemistry and solid state science and technology</li> <li>EdArXiv - for the education research community</li> <li>EngrXiv for the engineering community</li> <li>EvoEcoRxiv - is an open acccess preprint repository for Evolutionary and Ecological sciences.</li> <li>MediArXiv for Media, Film, &amp; Communication Studies</li> <li>MedRxiv - is an open access preprint repository for Medical sciences.</li> <li>PaleorXiv - is an open access preprint repository for Paleo Sciences</li> <li>PsyrXiv - is an open access preprint repository for Psychological sciences.</li> <li>SocArXiv - is an open access preprint repository for Social sciences.</li> <li>SportrXiv - is an open access preprint for Sports sciences.</li> <li>ThesisCommons - open Theses</li> </ul> </li> <li> <p>Author's accepted manuscript (AAM) - includes changes that came about during peer-review process. It is a non-typeset or formatted article. This often had an embargo period of 12-24 months</p> </li> <li> <p>Published version of record (VOR) - includes stylistic edits, online &amp; print formatting. This is the version that publishers claim ownership of with copyrights or exclusive licensing. </p> </li> </ol> <p> </p> Copyrights and Science Publishing <p>Upon completion of a peer-reviewed science paper, the author typically 1. signs over the copyright of the paper to the publisher or 2. signs an exclusive license agreement with the publisher</p> <p>For example authors that publish in Science retain their copyright but sign a 'license to pubish' agreement with AAAS</p> <p>Elsevier requires authors to sign over copyright of the article but authors retains some rights of distribution</p> <ul> <li>Elesevier summary of copyright policies</li> <li>Elesevier article sharing policy</li> <li>Wiley policy on self-archiving</li> <li>Springer Nature copyright policies</li> </ul> <p> </p>"},{"location":"01_intro_open_sci/#new-open-access-mandates-in-us","title":"New Open Access Mandates in US","text":"<p>The White House Office of Science and Technology (OSTP) has recently released a policy document known as the Nelson Memo stating that tax-payer funded research must by open access by 2026 with no embargo period. </p> <p>Authors can comply with the memo by either:</p> <ol> <li>Publishing Open Access (this usually requires higher fees)</li> <li>Distributing the Author's Accepted Manuscript (AAM) </li> </ol> <p>Read NSF's open access plan in reponse to the Nelson Memo</p> <p>Read USDA's open access plan in reponse to the Nelson Memo</p> <p> </p>"},{"location":"01_intro_open_sci/#additional-info","title":"Additional Info","text":"<p>University of Arizona Libraries information on Open Access publishing including agreements with several journals to reduce or waive publishing fees. </p> <p>https://www.coalition-s.org/</p> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#open-data","title":"Open Data","text":"<p>Definitions</p> <p>\u201cOpen data and content can be freely used, modified, and shared by anyone for any purpose\u201d - The Open Definition</p> <p>\"Open data is data that can be freely used, re-used and redistributed by anyone - subject only, at most, to the requirement to attribute and sharealike.\" - Open Data Handbook</p> <p> Wikipedia definition</p> <p> </p> <p>Data are the foundation for any scientific endeavor. A lot of thought needs to go into how to best collect, store, analyze, curate, share, and archive data.</p> <p>  DIKW Pyramid</p> <p> </p>"},{"location":"01_intro_open_sci/#fair-principles","title":"FAIR Principles","text":"<p>In 2016, the FAIR Guiding Principles for scientific data management and stewardship were published in Scientific Data. </p> <p>Findable: Making data discoverable by the wider academic community and the public</p> <p>Accessible: Using unique identifiers, metadata and a clear use of language and access protocols</p> <p>Interoperable: Applying standards to encode and exchange data and metadata</p> <p>Reusable: Enabling the repurposing of researach outputs to maximize their research potential</p> <p> </p> <p>Reasons to Make your Data Open</p> <ul> <li>Unnecessary duplication. Duplication of research is costly for society, and places unnecessary burden on heavily researched people and populations.  </li> <li>The data underlying publications are maintained and accessible, allowing for validation of results.</li> <li>Data openness leads to more collaboration and advances research and innovation.</li> <li>Your research is more visible and has greater impact. Publications which allow access to the underlying data get more citations. Greater visibility also allows for better validation and scrutiny of findings.</li> <li>Other researchers can cite your data, which will drive up your citation number and increase your influence in your field of research.</li> <li>Storing your data in a public repository also provides you with secure and ongoing storage that may otherwise not be available to you. -Foster Open Science</li> </ul> <p> </p>"},{"location":"01_intro_open_sci/#as-open-as-possible-as-closed-as-necessary","title":"As Open as Possible, as Closed as Necessary","text":"<p>There are many circumstances where open data could be harmful:</p> <ul> <li> <p>Data on human health</p> </li> <li> <p>Location of endangered species or archaeological sites</p> </li> <li> <p>Data that individuals or groups do not want to be public</p> CARE Principles <p>The CARE Principles for Indigenous Data Governance were drafted at the International Data Week and Research Data Alliance Plenary co-hosted event \"Indigenous Data Sovereignty Principles for the Governance of Indigenous Data Workshop,\" 8 November 2018, Gaborone, Botswana.</p> <p>Collective Benefit</p> <ul> <li>C1. For inclusive development and innovation</li> <li>C2. For improved governance and citizen engagement</li> <li>C3. For equitable outcomes</li> </ul> <p>Authority to Control</p> <ul> <li>A1. Recognizing rights and interests</li> <li>A2. Data for governance</li> <li>A3. Governance of data</li> </ul> <p>Responsibility</p> <ul> <li>R1. For positive relationships</li> <li>R2. For expanding capability and capacity</li> <li>R3. For Indigenous languages and worldviews</li> </ul> <p>Ethics</p> <ul> <li>E1. For minimizing harm and maximizing benefit</li> <li>E2. For justice</li> <li>E3. For future use</li> </ul> </li> <li> <p>Data for making lethal weapons</p> </li> </ul> <p> </p> <p>Open vs. FAIR</p> <p>FAIR does not demand that data be open: See one definition of open: http://opendefinition.org/</p> <p>Open data does not necessarily mean it is FAIR</p> <p> </p>"},{"location":"01_intro_open_sci/#additional-info_1","title":"Additional Info","text":"<ul> <li> <p>The Ethics of Geolocated Data from UK Statistics Authority </p> </li> <li> <p>Health information US HIPAA</p> </li> <li> <p>Indigenous data sovereignty: CARE Principles for Indigenous Data Governance , Global Indigenous Data Alliance (GIDA), First Nations OCAP\u00ae (Ownership Control Access and Possession), Circumpolar Inuit Protocols for Equitable and Ethical Engagement </p> </li> </ul> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#open-educational-resources","title":"Open Educational Resources","text":"<p>Definitions</p> <p>\"Open Educational Resources (OER) are learning, teaching and research materials in any format and medium that reside in the public domain or are under copyright that have been released under an open license, that permit no-cost access, re-use, re-purpose, adaptation and redistribution by others.\" - UNESCO</p> <p> Wikipedia definition</p> Digital Literacy Organizations <ul> <li>The Carpentries - teaches foundational coding and data science skills to researchers worldwide  </li> <li>EdX - Massively Open Online Courses (not all open) hosted through University of California Berkeley</li> <li>EveryoneOn - mission is to unlock opportunity by connecting families in underserved communities to affordable internet service and computers, and delivering digital skills trainings </li> <li>ConnectHomeUSA - is a movement to bridge the digital divide for HUD-assisted housing residents in the United States under the leadership of national nonprofit EveryoneOn</li> <li>Global Digital Literacy Council -  has dedicated more than 15 years of hard work to the creation and maintenance of worldwide standards in digital literacy</li> <li>IndigiData - training and engaging tribal undergraduate and graduate students in informatics</li> <li>National Digital Equity Center a 501c3 non-profit, is a nationally recognized organization with a mission to close the digital divide across the United States</li> <li>National Digital Inclusion Allaince - advances digital equity by supporting community programs and equipping policymakers to act</li> <li>Net Literacy</li> <li>Open Educational Resources Commons</li> <li>Project Pythia is the education working group for Pangeo and is an educational resource for the entire geoscience community</li> <li>Research Bazaar - is a worldwide festival promoting the digital literacy emerging at the centre of modern research</li> <li>TechBoomers - is an education and discovery website that provides free tutorials of popular websites and Internet-based services in a manner that is accessible to older adults and other digital technology newcomers</li> </ul> Educational Materials <ul> <li>Teach Together by Greg Wilson</li> <li>DigitalLearn</li> </ul> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#open-methodology","title":"Open Methodology","text":"<p>Definitions</p> <p>\"An open methodology is simply one which has been described in sufficient detail to allow other researchers to repeat the work and apply it elsewhere.\" - Watson (2015)</p> <p>\"Open Methodology refers to opening up methods that are used by researchers to achieve scientific results and making them publicly available.\" - Open Science Network Austria</p> <p> </p>"},{"location":"01_intro_open_sci/#sharing-research-computer-code","title":"Sharing Research Computer Code","text":"<p>Scientists around the globe are creating computer code for scientific analysis. These are valuable contributions that need to be shared!</p> <p>Platforms like GitHub and GitLab are ideal for collaboratively developing code and sharing with the open internet. In FOSS, we will show you how to use Github for sharing code, documentation, hosting websites, and software version control. </p> <p> </p>"},{"location":"01_intro_open_sci/#publishing-your-methods-or-protocols","title":"Publishing Your Methods or Protocols","text":"Platforms for Publishing Protocols &amp; Bench Techniques <ul> <li>BioProtocol</li> <li>Current Protocols</li> <li>Gold Biotechnology Protocol list</li> <li>JoVE - Journal of Visualized Experiments</li> <li>Nature Protocols</li> <li>OpenWetWare</li> <li>Protocol Exchange</li> <li>Protocols Online</li> <li> Protocols</li> <li>SciGene</li> <li>Springer Nature Experiments</li> </ul>"},{"location":"01_intro_open_sci/#preregistration","title":"PreRegistration","text":"<p>Preregistration is detailing your research and analysis plan and submitting it to an online registry before you engage in the research. </p> <p>  PreRegistration in the Research Life Cycle</p>"},{"location":"01_intro_open_sci/#why-do-this","title":"Why Do This?","text":"<p>Preregistration makes your process more open and records the difference between your initial research plan what you end up actually doing.</p> <p>Preregistration separates hypothesis-generating  (exploratory) from hypothesis-testing (confirmatory) research. Both are important. But the same data cannot be used to generate and test a hypothesis, which can happen unintentionally and reduce the credibility of your results. </p> <p>It also helps us avoid practices like p-hacking or Hypothesizing After the Results are Known(HARKing). </p> <p></p>"},{"location":"01_intro_open_sci/#additional-info_2","title":"Additional Info","text":"<p>Read this publication by Nosek et al. 2018</p> <p>Open Science Framework Preregistration https://www.cos.io/initiatives/prereg</p> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#open-peer-review","title":"Open Peer Review","text":"<p>Definitions</p> <p>Open peer review is an umbrella term for a number of overlapping ways that peer review models can be adapted in line with the aims of Open Science, including making reviewer and author identities open, publishing review reports and enabling greater participation in the peer review process.  </p> <p>-Ross-Hellauer et al. (2017)</p> <p></p> <p> Wikipedia's definition</p> <p> </p>"},{"location":"01_intro_open_sci/#traditional-closed-peer-review-system","title":"Traditional Closed Peer-Review System","text":"<ul> <li>Throughout and after the process, the author remains unaware of the reviewers' identities, while the reviewers know the identity of the authors. </li> <li>All communications between authors, reviewers and editors remains private </li> </ul>"},{"location":"01_intro_open_sci/#complaints-with-the-traditional-closed-peer-review-system","title":"Complaints with the Traditional Closed Peer-Review System","text":"<ul> <li>Unreliable and Inconsistent</li> <li>Delays and Expense</li> <li>Lack of Accountability and Risks of Subversion</li> <li>Social and Publication Biases</li> <li>Lack of Incentives</li> </ul> <p>Ross-Hallauer 2017</p> <p> </p>"},{"location":"01_intro_open_sci/#open-peer-review-ideas","title":"Open Peer-Review Ideas","text":"<p>  Open Peer Review Options at PLOS</p> <p> </p> <p>Defenders of the Traditional Peer-Review System</p> <p> </p> <p>Example Open Peer-Review Systems</p> <p>F1000Research An open research publishing platform that offers open peer review and rapid publication. The article from Ross-Hellauer et al. (2017) has open peer-reviews.</p> <p></p> <p>Platforms for Reviewing Preprints</p> <ul> <li>PREreview </li> <li>Sciety </li> <li>PubPeer </li> <li>ASAPbio </li> </ul> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#open-source-software","title":"Open Source Software","text":"<p>Definitions</p> <p>\"Open source software is code that is designed to be publicly accessible\u2014anyone can see, modify, and distribute the code as they see fit. Open source software is developed in a decentralized and collaborative way, relying on peer review and community production.\" -  Red Hat</p> <p> Wikipedia definition</p> <p> </p> <p>Research science (and also many companies) rely on open source software to operate</p> <p> </p> <p>Open Source Software</p> <ul> <li>Linux operating system and shell</li> <li>Python </li> <li>R</li> <li>git</li> <li>Conda</li> <li>Docker</li> <li>Cyverse</li> <li>Pytorch</li> <li>Tyson's Awesome List</li> </ul> <p> </p> <p>When you create a new software, library, or package, you become its parent and guardian.</p> <p>  Image Credit: XKCD Dependency </p> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#why-do-open-science","title":"WHY do Open Science?","text":"<p>A paper from Bartling &amp; Friesike (2014) posits that there are 5 main schools of thought in Open Science, which represent 5 underlying motivations:</p> <ol> <li>Democratic school: primarily concerned with making scholarly work freely available to everyone</li> <li>Pragmatic school: primarily concerned with improving the quality of scholarly work by fostering collaboration and improving critiques</li> <li>Infrastructure school: primarily focused on the platforms, tools, and services necessary to conduct efficient research, collaboration, and communication</li> <li>Public school: primarily concerned with societal impact of scholarly work, focusing on engagement with broader public via citizen science, understandable scientific communication, and less formal communication</li> <li>Measurement school: primarily concerned with the existing focus on journal publications as a means of measuring scholarly output, and focused on developing alternative measurements of scientific impact</li> </ol> <p>  In Bartling &amp; Friesike (2014) Open Science: One Term, Five Schools of Thought </p> <p>We have added another school of thought </p> <ol> <li>Compliance school: government, universities, and granting agencies have embraced Open Science and are mandating some elements (e.g., data sharing with publications)  </li> </ol> <p> </p>"},{"location":"01_intro_open_sci/#discussion-questions","title":"Discussion Questions","text":"Which of the  pillars of Open Science is nearest to your own heart? <p> Open Access Publications</p> <p> Open Data</p> <p> Open Educational Resources</p> <p> Open Methodology</p> <p> Open Peer Review</p> <p> Open Source Software</p> Are any of the  pillars more important than the others? Are there any  pillars not identified that you think should be considered? What characteristics might a paper, project, lab group require to qualify as doing Open Science What are some barriers to you, your lab group, or your domain doing Open Science? What motivates you to do Open Science? Do you feel that you fall into a particular \"school\"? If so, which one, and why? Are there any motivating factors for doing Open Science that don't fit into this framework? <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#recommended-open-science-communities","title":"Recommended Open Science Communities","text":"<p> Open Scholarship Grassroots Community Networks</p>  International Open Science Networks <ul> <li>Center for Scientific Collaboration and Community Engagement (CSCCE)</li> <li>Center for Open Science (COS)</li> <li>Eclipse Science Working Group</li> <li>eLife</li> <li>NumFocus</li> <li>Open Access Working Group</li> <li>Open Research Funders Group</li> <li>Open Science Foundation</li> <li>Open Science Network</li> <li>pyOpenSci</li> <li>R OpenSci</li> <li>Research Data Alliance (RDA)</li> <li>The Turing Way</li> <li>UNESCO Global Open Science Partnership</li> <li>World Wide Web Consortium (W3C)</li> </ul>  US-based Open Science Networks <ul> <li>CI Compass - provides expertise and active support to cyberinfrastructure practitioners at USA NSF Major Facilities in order to accelerate the data lifecycle and ensure the integrity and effectiveness of the cyberinfrastructure upon which research and discovery depend.</li> <li>Earth Science Information Partners (ESIP) Federation -  is a 501\u00a9(3) nonprofit supported by NASA, NOAA, USGS and 130+ member organizations.</li> <li>Internet2 - is a community providing cloud solutions, research support, and services tailored for Research and Education. </li> <li>Minority Serving Cyberinfrastructure Consortium (MS-CC) envisions a transformational partnership to promote advanced cyberinfrastructure (CI) capabilities on the campuses of Historically Black Colleges and Universities (HBCUs), Hispanic-Serving Institutions (HSIs), Tribal Colleges and Universities (TCUs), and other Minority Serving Institutions (MSIs). </li> <li>NASA Transform to Open Science (TOPS) - coordinates efforts designed to rapidly transform agencies, organizations, and communities for Earth Science</li> <li>OpenScapes - is an approach for doing better science for future us</li> <li>The Quilt - non-profit regional research and education networks collaborate to develop, deploy and operate advanced cyberinfrastructure that enables innovation in research and education.</li> </ul>  Oceania Open Science Networks <ul> <li>New Zealand Open Research Network - New Zealand Open Research Network (NZORN) is a collection of researchers and research-associated workers in New Zealand.</li> <li>Australia &amp; New Zealand Open Research Network - ANZORN is a network of local networks distributed without Australia and New Zealand.</li> </ul> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#self-assessment","title":"Self Assessment","text":"True or False: All research papers published in the top journals, like Science and Nature, are always Open Access? Answer <p>False</p> <p>Major Research journals like Science and Nature have an \"Open Access\" option when a manuscript is accepted, but they charge an extra fee to the authors to make those papers Open Access.</p> <p>These high page costs are exclusionary to the majority of global scientists who cannot afford to front these costs out of pocket.</p> <p>This will soon change, at least in the United States. The Executive Branch of the federal government recently mandated that future federally funded research be made Open Access after 2026.</p> True or False: an article states all of the research data used in the experiments \"are available upon request from the corresponding author(s),\" meaning the data are \"Open\" Answer <p>False</p> <p>In order for research to be open, the data need to be freely available from a digital repository, like Data Dryad, Zenodo.org, or CyVerse.</p> <p>Data that are 'available upon request' do not meet the FAIR data principles. </p> Using a version control system to host the analysis code and computational notebooks, and including these in your Methods section or Supplementary Materials, is an example of an Open Methodology? Answer <p>Yes!</p> <p>Using a VCS like GitHub or GitLab is a great step towards making your research more reproducible. </p> <p>Ways to improve your open methology can include documentation of your physical bench work, and even video recordings and step-by-step guides for every part of your project.</p> You are asked to review a paper for an important journal in your field. The editor asks if you're willing to release your identity to the authors, thereby \"signing\" your review. Is this an example of \"Open Peer Review\"? Answer <p>Maybe</p> <p>There are many opinions on what 'open-review' should consist of. A reviewer signing their review and releasing their identity to the authors is a step toward a more open process. However, it is far less open than publishing the peer-review reports online next to the final published paper. </p> You read a paper where the author(s) wrote their own code and licensed as \"Open Source\" software for a specific set of scientific tasks which you want to replicate. When you visit their personal website, you find the GitHub repository does not exist (because its now private). You contact the authors asking for access, but they refuse to share it 'due to competing researchers who are seeking to steal their intellectual property\". Is the software open source? Answer <p>No</p> <p>Just because an author states they have given their software a permissive software license, does not make the software open source. </p> <p>Always make certain there is a LICENSE associated with any software you find on the internet. </p> <p>In order for the software to be open, it must follow the Open Source Initiative definition</p>"},{"location":"02_managing_data/","title":"Managing Data","text":"<p>Learning Objectives</p> <p>After this lesson, you should be able to:</p> <ul> <li>Recognize data as the foundation of open science and be able to describe the \"life cycle of data\"</li> <li>Use self-assessments to evaluate your current data management practices</li> <li>Cite tools and resources to improve your data management practices</li> <li>Know the biggest challenge to effective data management</li> </ul> How would you answer? <ul> <li>If you give your data to a colleague who has not been involved with your project, would they be able to make sense of it? Would they be able to use it properly?</li> <li>If you come back to your own data in five years, will you be able to make sense of it? Will you be able to use it properly?</li> <li>When you are ready to publish a paper, is it easy to find all the correct versions of all the data you used and present them in a comprehensible manner?</li> </ul>"},{"location":"02_managing_data/#why-should-you-care-about-data-management","title":"Why should you care about data management?","text":"<p>The biggest challenge to data management is  making it an afterthought. </p> <p>Poor data management doesn't have an upfront cost. You can do substantial work before realizing you are in trouble.</p> <p>The solution? Make data management the first thing you consider when starting a research project.</p> <p>Well-managed Data Sets:</p> <ul> <li>Can make life much easier for you and your collaborators</li> <li>Benefit the scientific research community by allowing others to reuse your data</li> <li>Are becoming required by most funders and many journals, which are requesting a submission of a Data Management Plan (DMP) with the initial submission of your proposal.</li> </ul> <p>The NSF is stepping in, getting stricter about data</p> <ul> <li>Recent Dear Colleague letterfrom NSF's points out that:<ul> <li>Open science promotes broader access to research data, enhancing public benefits and replicability.</li> <li>NSF requires (DMPs) in proposals, encouraging use of persistent IDs and machine-readable DMPs.</li> </ul> </li> <li>NSF proposal preparation guidelines now require at least the following:<ul> <li>Proposals must include a 2-page DMP outlining data types, formats, sharing, and archiving.</li> <li>The DMP must address privacy, intellectual property, and reuse policies, and collaborative projects should submit one unified DMP.</li> <li>A DMP stating no detailed plan is needed is allowed with justification, and the DMP will be reviewed as part of the proposal's merit.</li> </ul> </li> </ul>"},{"location":"02_managing_data/#what-classifies-as-data","title":"What Classifies as Data?","text":"<p>Different types of data require different management practices. Here are some examples of what we can call Data (Adapted from DMPTool Data management general guidance).</p> <p>Data Types:</p> <ul> <li>Text: field or laboratory notes, survey responses</li> <li>Numeric: tables, counts, measurements</li> <li>Audiovisual: images, sound recordings, video</li> <li>Models, computer code</li> <li>Discipline-specific: FASTA in biology, FITS in astronomy, CIF in chemistry</li> <li>Instrument-specific: equipment outputs</li> </ul> <p>Data Sources:</p> <p>Observational</p> <ul> <li>Captured in real-time, typically outside the lab</li> <li>Usually irreplaceable and therefore the most important to safeguard</li> <li>Examples: Sensor readings, telemetry, survey results, images</li> </ul> <p>Experimental</p> <ul> <li>Typically generated in the lab or under controlled conditions</li> <li>Often reproducible, but can be expensive or time-consuming</li> <li>Examples: gene sequences, chromatograms, magnetic field readings</li> </ul> <p>Simulation</p> <ul> <li>Machine generated from test models</li> <li>Likely to be reproducible if the model and inputs are preserved</li> <li>Examples: climate models, economic models</li> </ul> <p>Derived / Compiled</p> <ul> <li>Generated from existing datasets</li> <li>Reproducible, but can be very expensive and time-consuming</li> <li>Examples: text and data mining, compiled database, 3D models</li> </ul>"},{"location":"02_managing_data/#data-self-assessment","title":"Data Self-assessment","text":"<p>Activity</p> <p>In small groups, discuss the following questions.</p> <ol> <li>What are the two or three data types that you most frequently work with?         -   Think about the sources (observational, experimental, simulated, compiled/derived)         -   Also consider the formats (tabular, sequence, database, image, etc.)    </li> <li> <p>What is the scale of your data?</p> Tip: think of the Three V's <ul> <li>Volume: Size of the data (MBs, GBs, TBs); can also include how many files (e.g dozens of big files, or millions of small ones)</li> <li>Velocity: How quickly are these data produced and analyzed? A lot coming in a single batch infrequently, or, a constant small amount of data that must be rapidly analyzed?</li> <li>Variety: How many different data types (raw files? databases?) A fourth V (Veracity) captures the need to make decisions about data processing (i.e., separating low- and high-quality data)</li> </ul> </li> <li> <p>What is your strategy for storing and backing up your data?    </p> </li> <li>What is your strategy for verifying the integrity of your data? (i.e. verifying that your data has not be altered)  </li> <li>What is your strategy for searching your data?  </li> <li>What is your strategy for sharing (and getting credit for) your data? (i.e. How will do you share with your community/clients? How is that sharing documented? How do you evaluate the impact of data shared? )</li> </ol>"},{"location":"02_managing_data/#the-data-life-cycle","title":"The Data Life Cycle","text":"<p>Data management is the set of practices that allow researchers to effectively and efficiently handle data throughout the data life cycle. Although typically shown as a circle (below) the actually life cycle of any data item may follow a different path, with branches and internal loops. Being aware of your data's future helps you plan how to best manage them.</p>  The Data Life Cycle, from Strasser et al.  Breaking down the Data Life Cycle Graph <p>Plan</p> <ul> <li>Describe the data that will be compiled, and how the data will be managed and made accessible throughout its lifetime</li> <li>A good plan considers each of the stages below</li> </ul> <p>Collect</p> <ul> <li>Have a plan for data organization in place before collecting data</li> <li>Collect and store observation metadata at the same time you collect the metadata</li> <li>Take advantage of machine generated metadata</li> </ul> <p>Assure</p> <ul> <li>Record any conditions during collection that might affect the quality of the data</li> <li>Distinguish estimated values from measured values</li> <li>Double check any data entered by hand</li> <li>Perform statistical and graphical summaries (e.g., max/min, average, range) to check for questionable or impossible values.</li> <li>Mark data quality, outliers, missing values, etc.</li> </ul> <p>Describe</p> <ul> <li>Comprehensive data documentation (i.e. metadata) is the key to future understanding of data. Without a thorough description of the context of the data, the context in which they were collected, the measurements that were made, and the quality of the data, it is unlikely that the data can be easily discovered, understood, or effectively used.</li> <li>Thoroughly describe the dataset (e.g., name of dataset, list of files, date(s) created or modified, related datasets) including the people and organizations involved in data collection (e.g., authors, affiliations, sponsor). Also include:<ul> <li>An ORCID (obtain one if you don't have one).</li> <li>The scientific context (reason for collecting the data, how they were collected, equipment and software used to generate the data, conditions during data collection, spatial and temporal resolution)</li> <li>The data themselves</li> <li>How each measurement was produced</li> <li>Units</li> <li>Format</li> <li>Quality assurance activities</li> <li>Precision, accuracy, and uncertainty</li> </ul> </li> </ul> <p>Some metadata standards you may want to consider:</p> <ul> <li>DataCite for publishing data</li> <li>Dublin Core for sharing data on the web</li> <li>MIxS Minimum Information for any (x) sequence</li> <li>OGC standards for geospatial data</li> </ul> Ontologies provide standardization for metadata values <p>Example of ontologies:</p> <ul> <li>Environment Ontology terms for the MIxS standards</li> <li>Plant Ontology for plant tissue types or development stages</li> <li>FAIRSharing.org lists standards and ontologies for life sciences.</li> </ul> <p>Preserve</p> <p>In general, data must be preserved in an appropriate long-term archive (i.e. data center). Here are some examples:</p> <ul> <li>Sequence data should go to a national repository, frequently NCBI</li> <li>Identify data with value - it may not be necessary to preserve all data from a project</li> <li>The CyVerse Data Commons provides a place to publish and preserve data that was generated on or can be used in CyVerse, where no other repository exists.</li> <li>See lists of repositories at FAIRSharing.org</li> <li>See lists of repositories at Data Dryad</li> <li>Github repos can get DOIs through Zenodo</li> <li>Be aware of licensing and other intellectual property issues<ul> <li>Repositories will require some kind of license, often the least restrictive (see for example Creative Commons)</li> <li>Repositories are unlikely to enforce reuse restrictions, even if you apply them.</li> </ul> </li> </ul> <p>Discover</p> <ul> <li>Good metadata allows you to discover your own data!</li> <li>Databases, repositories, and search indices provide ways to discover relevant data for reuse <ul> <li>Google dataset search</li> <li>DataOne</li> <li>FAIRSharing.org</li> </ul> </li> </ul> <p>Integrate</p> <ul> <li>Data integration is a lot of work</li> <li>Standards and ontologies are key to future data integration</li> <li>Know the data before you integrate them</li> <li>Don't trust that two columns with the same header are the same data</li> <li>Properly cite the data you reuse!</li> <li>Use DOIs (Digital Object Identifiers) wherever possible</li> </ul> <p>Analyze</p> <ul> <li>Follow open science principles for reproducible analyses (CyVerse, RStudio, notebooks, IDEs)</li> <li>State your hypotheses and analysis workflow before collecting data. Tools like Open Science Framework (OSF) allow you to make this public.</li> <li>Record all software, parameters, inputs, etc.</li> </ul> References and Resources <ul> <li>DataOne best practices</li> <li>Center for Open Science</li> </ul>"},{"location":"02_managing_data/#data-principles","title":"Data Principles","text":"FAIR data, NIH.   CARE data, University of Arizona.  <p>Learning Objectives</p> <ul> <li>Recall the meaning of FAIR</li> <li>Understand why FAIR is a collection of principles (rather than rules)</li> <li>Understand CARE</li> </ul>"},{"location":"02_managing_data/#fair-principles","title":"FAIR Principles","text":"<p>In 2016, the FAIR Guiding Principles for scientific data management and stewardship were published in Scientific Data.</p> <p> Read it.</p> <p>Why Principles?</p> <p>FAIR is a collection of principles. Ultimately, different communities within different scientific disciplines must work to interpret and implement these principles. Because technologies change quickly, focusing on the desired end result allows FAIR to be applied to a variety of situations now and in the foreseeable future.</p> <p>Findable</p> <ul> <li>F1. (meta)data are assigned a globally unique and persistent identifier</li> <li>F2. data are described with rich metadata (defined by R1 below)</li> <li>F3. metadata clearly and explicitly include the identifier of the data it describes</li> <li>F4. (meta)data are registered or indexed in a searchable resource</li> </ul> <p>Accessible</p> <ul> <li>A1. (meta)data are retrievable by their identifier using a standardized communications protocol</li> <li>A1.1 the protocol is open, free, and universally implementable</li> <li>A1.2 the protocol allows for an authentication and authorization procedure, where necessary</li> <li>A2. metadata are accessible, even when the data are no longer available</li> </ul> <p>Interoperable</p> <ul> <li>I1. (meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation.</li> <li>I2. (meta)data use vocabularies that follow FAIR principles</li> <li>I3. (meta)data include qualified references to other (meta)data</li> </ul> <p>Reusable</p> <ul> <li>R1. meta(data) are richly described with a plurality of accurate and relevant attributes</li> <li>R1.1. (meta)data are released with a clear and accessible data usage license</li> <li>R1.2. (meta)data are associated with detailed provenance</li> <li>R1.3. (meta)data meet domain-relevant community standard</li> </ul> <p>Open vs. Public vs. FAIR</p> <p>Open: \u201cOpen data and content can be freely used, modified, and shared by anyone for any purpose\u201d.</p> <p>FAIR does NOT demand that data be open: See one definition of open: http://opendefinition.org/.</p>"},{"location":"02_managing_data/#care-principles","title":"CARE Principles","text":"<p> Nihil de nobis, sine nobis.</p> <p>Nothing about us without us.</p> <p></p> <p>Who owns the a\u00e7a\u00ed?</p> <p>The CARE Principles for Indigenous Data Governance were drafted at the International Data Week and Research Data Alliance Plenary co-hosted event \"Indigenous Data Sovereignty Principles for the Governance of Indigenous Data Workshop,\" 8 November 2018, Gaborone, Botswana.</p> <p>Collective Benefit</p> <ul> <li>C1. For inclusive development and innovation</li> <li>C2. For improved governance and citizen engagement</li> <li>C3. For equitable outcomes</li> </ul> <p>Authority to Control</p> <ul> <li>A1. Recognizing rights and interests</li> <li>A2. Data for governance</li> <li>A3. Governance of data</li> </ul> <p>Responsibility</p> <ul> <li>R1. For positive relationships</li> <li>R2. For expanding capability and capacity</li> <li>R3. For Indigenous languages and worldviews</li> </ul> <p>Ethics</p> <ul> <li>E1. For minimizing harm and maximizing benefit</li> <li>E2. For justice</li> <li>E3. For future use</li> </ul> <p>Connecting FOSS and CARE: Lydia Jennings</p> <p>Dr. Lydia Jennings was a Data Science Fellow at the University of Arizona, who attended FOSS in  Fall of 2022.     Lydia graduated from the University of Arizona's Department of Evironemtal Sciences, and has published a paper on the application of the CARE principles to ecology and biodiversity research. Go Lydia! Appying the 'CARE Principles for Indigenous Data Governance' to ecology and biodiversity, Nature Ecology &amp; Evolution, 2023. </p>"},{"location":"02_managing_data/#how-to-get-to-fair","title":"How to get to FAIR?","text":"<p>This is a question that only you can answer, that is because it depends on (among other things)</p> <ol> <li>Your scientific discipline: Your datatypes and existing standards for what constitutes acceptable data management will vary.</li> <li>The extent to which your scientific community has implemented FAIR: Some disciplines have significant guidelines on FAIR, while others have not addressed the subject in any concerted way.</li> <li>Your level of technical skills: Some approaches to implementing FAIR may require technical skills you may not yet feel comfortable with.</li> </ol> <p>While a lot is up to you, the first step is to evaluate how FAIR you think your data are:</p> Assessing the FAIRness of you data <p>Thinking about a dataset you work with, complete the ARDC FAIR assessment in your own time.</p> Resources <ul> <li>The FAIR Guiding Principles for scientific data management and stewardship</li> <li>Wilkinson et al. (2016) established the guidelines to improve the Findability, Accessibility, Interoperability, and Reuse (FAIR) of digital assets for research. </li> <li>Go-FAIR website</li> <li>Carroll et al. (2020) established the CARE Principles for Indigenous Data Governance. full document </li> <li>Indigenous Data Sovereignty Networks</li> </ul>"},{"location":"02_managing_data/#data-management-plans","title":"Data Management Plans","text":"<p>\"Those who fail to plan, plan to fail.\"</p> <p>Learning Objectives</p> <ul> <li>Describe the purpose of a data management plan</li> <li>Describe the important elements of a data management plan</li> </ul> <p>What is a DMP?</p> <p>\"A data management plan or DMP is a formal document that outlines how data are to be handled both during a research project, and after the project is completed. The goal of a data management plan is to consider the many aspects of data management, metadata generation, data preservation, and analysis before the project begins; this may lead to data being well-managed in the present, and prepared for preservation in the future.\"</p> <p>Source: Wikipedia.</p> <p>Here are some Example DMPs made public from the DMPtool website. You can use these as example for creating your own DMP.</p> <p>Why bother with a DMP?</p> How would you answer? <p>Do you have a data management plan? If so, how do you use it?</p> <p>Returning to the assertion that data (and its value) is at the foundation of your science, working without a data management plan should be considered scientific misconduct.</p> <p>Those are strong words. And while we might have an intuition of the boundaries of research ethics - data mismanagement seems more like an annoyance than misconduct. However, if your mismanagement leads to error in your research data, or the inability to make publicly-funded research open to the public, these are serious consequences. Increasingly, funders realize this.</p>  \"Europe 1916\", by cartoonist Boardman Robinson, depicting the carrot and stick metaphor.  <p>Stick:</p> <ul> <li>You have to make one.</li> <li>Reviewers definitely look at them, but they may not be enforced.</li> </ul> <p>Carrot:</p> <ul> <li>Make your life easier.</li> <li>Planning for you project makes it run more smoothly.</li> <li>Avoid surprise costs.</li> </ul> <p> </p> <p>DMPTools: making your (data) life a little easier</p> <p>Here are a couple of tools you can utilize in order to create a Data Management Plan:</p> <ul> <li>Data Stewardship Wizard.</li> <li>DMPTool.</li> </ul>"},{"location":"02_managing_data/#licenses","title":"Licenses","text":"<p>By default, when you make creative work, that work is under exclusive copyright. This means that you have the right to decide how your work is used, and that others must ask your permission to use your work.</p> <p>If you want your work to be Open and used by others, you need to specify how others can use your work. This is done by licensing your work.</p> <p>License Examples</p> <ul> <li>MIT License</li> <li>GNU General Public License v3.0</li> <li>FOSS material has been licensed using the Creative Commons Attribution 4.0 International License</li> </ul>"},{"location":"02_managing_data/#license-options-from-uarizona-library","title":"License Options from UArizona Library","text":"<p>  License options for University of Arizona Research Data Repository (ReDATA).  </p> <p></p> <p>Additional Info</p> <ul> <li>General guidance on how to choose a license https://choosealicense.com/</li> <li>More good guidance on how to choose a license https://opensource.guide/legal/</li> <li>Licensing options for your Github Repository</li> </ul> References and Resources <ul> <li>NSF Guidelines on DMPs</li> <li>https://dmptool.org/general_guidance</li> <li>https://dmptool.org/public_templates</li> <li>Professional and scholarly societies, e.g., theEcological Society of America http://www.esa.org/esa/science/data-sharing/resources-and-tools/</li> <li>DataOne - https://dataoneorg.github.io/Education/bestpractices/</li> <li>Data Carpentry - http://datacarpentry.org/</li> <li>The US Geological Survey https://www.usgs.gov/data-management</li> <li>Repository registry (and search) service: http://www.re3data.org/</li> <li>Your university library</li> </ul>"},{"location":"02_managing_data/#self-assessment","title":"Self Assessment","text":"What is a Data Management Plan? <p>Important: A data management plan (DMP) is now required aspect of publicly funded research.</p> <p>DMPs are short, formal, documents outlining what types of data will be used, and what will be done with the data both during and after a research project concludes.</p> True or False: When science project funding ends, the data should end with it <p>False</p> <p>Data live on after a project ends.</p> <p>Ensuring that data have a full lifecycle where they can be (re)hosted and made available after a project ends is critical to open science and reproducible research</p> <p>Maybe</p> <p>Sometimes destroying data is part of the life cycle of data - this may be required if data are sensitive and could be used unethically in the future, beyond the control of the original investigator team. </p> True or False: FAIR and CARE data principles are the same <p>False</p> <p>The CARE principles were created in order to help guide and answer when and how applying FAIR data principles to soverign indigenous-controlled data should be done and when it should not. </p>"},{"location":"03_documentation_communication/","title":"Documentation &amp;  Communication","text":"<p>Learning Objectives</p> <p>After this lesson, you should be able to:</p> <ul> <li>Identify and explain different types of project documentation (both internal and external)</li> <li>Describe tools and approaches to creating your own documentation</li> <li>Create your own GitHub Pages website (!)</li> </ul> <p></p>"},{"location":"03_documentation_communication/#project-documentation","title":"Project Documentation","text":"<p>A great Open Scientist is someone who documents their work and shares it with the world. This means going well beyond peer-reviewed publications.</p> <ul> <li> <p>Describe how to use or build your computer code or tools</p> </li> <li> <p>Share best practices for a method or protocol</p> </li> <li> <p>Create and share educational material so others in your field can learn from you</p> </li> <li> <p>Share a first-person account of your journey through a project</p> </li> </ul> <p> </p> <p>  Read more in depth on the documentation system here: https://documentation.divio.com </p> Explanining the quadrants <ul> <li>Tutorials: Lessons! Tutorials are lessons that take the reader by the hand to understand how the basics of a tool work. They are what your project needs in order to show a beginner that they can achieve something with it. The techical teaching we do in FOSS are mostly tutorials. For example, we do simple tutorials to teach the mechanics of version control. </li> <li>How-to-guides: Recipes! How-to-guides take the reader through the steps required to acheive a specific outcome or answer a specific question. An example how-to-guide could be a guide on how to install a specific software on a specific operating system.</li> <li>References: References offer technical descriptions of the machinery and how to operate it. References have one job only: to describe. They are code-determined, because ultimately that\u2019s what they describe: key classes, functions, APIs, and so they should list things like functions, fields, attributes and methods, and set out how to use them.</li> <li>Explanation: Discussions! The aims of explanations are to clarify and illuminate a particular topic by broadening the documentation\u2019s coverage of a topic.</li> </ul> <p> </p>"},{"location":"03_documentation_communication/#tips-for-great-documentation","title":"Tips for Great Documentation","text":"<ul> <li> Clarity: Documentation should be easy to understand with clear language and no ambiguity.</li> <li> Completeness: It must cover all essential details, leaving nothing crucial undocumented.</li> <li> Accuracy: Information should be up-to-date and correct to prevent errors and misunderstandings.</li> <li> Organization: A logical structure and clear organization make it easy to navigate and find information.</li> <li> Relevance: Documentation should focus on what's pertinent to its intended audience or purpose, avoiding unnecessary information.</li> </ul>"},{"location":"03_documentation_communication/#public-repositories-for-documentation","title":"Public Repositories for Documentation","text":"GitHub Readme <ul> <li>On Github, good documentation starts with a robust ReadMe file. The ReadMe file is the first thing that people see when they visit your repository. It is a good place to explain what your project does, how to use it, and how to contribute to it. Here is an example.</li> </ul>  GitHub Wiki <ul> <li>Also on Github, you can use the Wiki feature to create a separate space for documentation. The Wiki is a place to document your project in a way that is separate from the code. Here is an example</li> </ul>  GitHub Pages <ul> <li>Github Pages are hosted directly from your GitHub repository</li> <li>GitHub pages are free, fast, and easy to build, but limited in use of subdomain or URLs</li> <li>You can pull templates from other GitHub users for your website, e.g.  Jekyll themes</li> <li>The FOSS website is rendered using  GitHub Pages using  MkDocs and the Material theme for MkDocs.</li> <li>Other popular website generator for GitHub Pages is  Bootstrap.js.</li> </ul>  Material MkDocs <ul> <li>Material Design theme for MkDocs, a static site generator geared towards (technical) project documentation.</li> <li>Publish via GitHub Actions</li> <li>Uses open source Material or ReadTheDocs Themes</li> </ul>  ReadTheDocs <ul> <li>publishing websites via ReadTheDocs.com costs money.</li> <li>You can work in an offline state, where you develop the materials and publish them to your localhost using Sphinx</li> <li>You can work on a website template in a GitHub repository, and pushes are updated in near real time using ReadTheDocs.com.</li> <li>Here is example documentation of Pytorch using ReadTheDocs: PyTorch.</li> </ul>  Bookdown <ul> <li> Bookdown is an open-source R package that facilitates writing books and long-form articles/reports with R Markdown.</li> <li>Bookdown websites can be hosted by RStudio Connect</li> <li>You can publish a Bookdown website using Github Pages</li> </ul>  Quarto <ul> <li> Quarto is an open-source scientific and technical publishing system built on Pandoc</li> <li>Build a website using Quarto's template builder</li> <li>Build with Github Pages</li> </ul>  JupyterBook <ul> <li>Based on Project Jupyter <code>ipynb</code> and MarkDown</li> <li>Uses <code>conda</code> package management</li> </ul>  GitBook <ul> <li>GitBook websites use MarkDown syntax</li> <li>Free for open source projects, paid plans are available</li> </ul>  Confluence Wikis <ul> <li> Confluence Wikis are another tool for documenting your work. You can see an example from Cyverse.</li> </ul> <p>Things to remember about Documentation</p> <ul> <li> <p>Documentation should be written in such a way that people who did not write the documentation can read and then use or read and then teach others in the applications of the material.</p> </li> <li> <p>Documentation is best treated as a living document, but version control is necessary to maintain it</p> </li> <li> <p>Technology changes over time, expect to refresh documentation every 3-5 years as your projects age and progress.</p> </li> </ul> <p> </p> <p>Public Communication</p> <p>Communicating with the public and other members of your science community (in addition to traditional peer-review publications and conferences) is one of the most important parts of your science!</p> <p>There are many ways scientists use social media and the web to share their data science ideas:</p> <ol> <li> \"Science Twitter\" (now ) -     is really just regular Twitter, but with a focus on following other scientists and organizations, and tweeting about research you're interested in. By building up a significant following, more people will know you, know about your work, and you'll have a higher likelihood of meeting other new collaborators.    <ul> <li>Since the rebranding to , a lot of the scientific communities on Twitter have now moved to  Mastodon, an open-source self-hosted alternative to social media.</li> </ul> </li> <li>Blogging Platforms such as Medium are a great place to self publish your writing on just about any topic. It's free to sign up and start blogging, but does have a fee for accessing premium content. Some of my favorite blogs include Toward Data Science and Chris Holmes.</li> <li>Community groups - There are lists (and lists of lists) of nationals research organizations, in which a researcher can become involved. These older organziations     still rely on official websites, science journal blogs, and email lists to communicate with their members. In the earth sciences there are open groups which focus on communication like the Earth Science Information Partners (ESIP) with progressive ideas about how data and science can be done. Other groups, like The Carpentries and Research Bazaar are focused on data science training and digital literacy.</li> <li>Podcasts - Creating and distributing audio content to masses is easier than ever before. There are many podcast hosting platforms including Spotify, Podbean, Acast, and Libsyn. From there is it simple to make your podcast availble in the Google Podcast app or Apple Podcast app. </li> <li>Webinars - With platforms such as Zoom, Microsoft Teams, and Google Meet, it is so easy nowadays to host a webinar touting and explaining your science. </li> <li>Youtube - The king of video sharing platforms is a great place to post content promoting your science (and yourself!). For example, Cyverse posts lots of content on cyberinfrastructure and data processing pipelines. Some of my favorite podcasts hosted on Youtube include StarTalk and Lex Fridman.<ul> <li>CyVerse and the Data Science Institute have a number of videos that can help you expand your science. Navigate our DataLab YouTube channel to learn more on AI, Natural Language Processing (NLP), geospatial science, bioinformatics/genomics and project management; Go to our CyVerse Channel to see the various projects CyVerse is involved in, or learn tips and tricks on how CyVerse works.</li> </ul> </li> </ol> <p>Important</p> <p>Remember: Personal and Professional Accounts are Not Isolated</p> <p>You decide what you post on the internet. Your scientist identity may be a part of your personal identity on social media, it might be separate. A future employer or current employer can see your old posts. What you post in your personal accounts can be considered a reflection of the organization you work for and may be used in decisions about hiring or dismissal.</p> <p> </p>"},{"location":"03_documentation_communication/#hands-on-building-a-github-pages-website-using-mkdocs","title":"Hands-on: Building a GitHub Pages Website using MkDocs","text":"<p>This section is built in order to educate on and simplify the steps necessary that newcomers need to take in order to build a successful GitHub Pages hosted website. </p> <p>This tutorial is inspired by academicpages, a Jekyll themed template created in order to help scientists and academics build their own websites.</p> <p>This tutorial will cover the necessary files and repository structure you require in order to build a successful personal website. </p> <p>The website we will create is going to be hosted on GitHub Pages using the MkDocs site generator and material for MkDocs theme.</p> <p>How does this work?</p> <ul> <li>You will build a website on GitHub, which will host it on GitHub pages. This tutorial does not require a local git copy of the repository.</li> <li>MkDocs is a static website generator: using the Markdown language you can create tables, format paragraphs, add images etc.; Through a GitHub Action, MkDocs will take your Markdown formatted pages and create the necessary HTML for a website.</li> <li>The material for MkDocs theme will \"prettify\" your website, rendering similar to the FOSS documentation, the CyVerse Learning center, or the U of A HPC documentation.</li> </ul> <p>This tutorial will create the basic requirements for the website. It will be up to you to populate it further.   You can base your formatting on either the FOSS materials or find out more from the material for MkDocs theme pages.</p> <p>Repository Explanation</p> <p>A GitHub hosted website running the MkDocs-material theme requires the following files in order to function:</p> <ul> <li>A <code>docs</code> folder:<ul> <li>A folder that contains all the documents necessary to populate the website's pages.</li> <li>All of the documents that the user needs to change are in here.</li> </ul> </li> <li>A <code>mkdocs.yml</code> file:<ul> <li>A <code>yml</code> file which contains critical information on the website structure, including themes, fonts, and extensions.</li> </ul> </li> <li>A <code>requirements.txt</code> file:<ul> <li>A file with a list of software necessary to build the website, primilily used by GitHub Actions.</li> </ul> </li> <li>A <code>.github/workflow</code> folder:<ul> <li>Contains the <code>ghpages.yml</code> file that controls the GitHub Action.</li> </ul> </li> </ul> <p>The structure of the basic repository is the following:</p> <pre><code>.\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 mkdocs.yml              &lt;- Governing file for website building\n\u251c\u2500\u2500 requirements.txt        &lt;- Requirements file for pip installation (required by website)      \n\u251c\u2500\u2500 docs                           \n\u2502   \u251c\u2500\u2500 assets              &lt;- Folder for images and additional graphic assets\n\u2502   \u2514\u2500\u2500 index.md            &lt;- Main website home page\n\u2514\u2500\u2500 .github\n    \u2514\u2500\u2500 workflows\n        \u2514\u2500\u2500 ghpages.yml     &lt;- GitHub Actions controlling file\n</code></pre> <p>Upon pushing changes, a <code>gh-pages</code> branch will be automatically created by the GitHub Action; it is where the website is rendered from.</p> <p>There are 2 ways of doing this exercise: </p> <ul> <li>Direction A: Forking or Importing a pre existing template</li> <li>Direction B: Creating the materials by yourself. </li> </ul> <p>Here below are the steps for Direction B.</p> <p>The workflow for this exercise is the following:</p> <ol> <li>Create the repository.</li> <li>Create the <code>docs</code> folder and populate it with <code>index.md</code>.</li> <li>Address the Settings such that GitHub Actions have the correct settings.</li> <li>Create a <code>requirements.txt</code> (used by GitHub Actions to build the website).</li> <li>Create the <code>mkdocs.yml</code> (used by MkDocs to create the sttructure).</li> <li>Create a GitHub workflow file <code>.github/workflows</code></li> <li>Address the Settings to deploy the website from a newly created branch.</li> <li>Edit pages in your own time.</li> </ol> <p>All the code is available on this page or on the HackMD. Ideally, all you need to do is copy and paste it!</p> <p>Prerequisites</p> <p>You will require the following in case you want to add code locally.</p> Create a GitHub account <p>Navigate to the GitHub website and click Sign Up, and follow the on screen instructions.</p> <p>Additionally, you can choose between Generating a Personal Access Token or using SSH keys. This is useful if you want to work locally and push your changes to GitHub. We are going to cover this further in next week's lesson on Version Control.</p> Choice A: Generate a Personal Access Token <p>You can follow the official documentation on how to generate Tokens here. We  discussed how to generate tokens in Week 0. Here's are quick steps you can follow in order to setup your account on your machine using tokens:</p> <ol> <li>On your coumputer:<ol> <li>Clone your repository (<code>git clone &lt;repository&gt;</code>)</li> <li>Make changes where necessary, and add (<code>git add &lt;changed files&gt;</code>), commit (<code>git commit -m \"&lt;message on changes&gt;\"</code>) and push your changes (<code>git push origin</code>).</li> <li>You should be prompted to logging in your GitHub account. Put your email but not your password. Instead, open your web browser and follow the steps below:</li> </ol> </li> <li>On GitHub:<ol> <li>Navigate to your GitHub Settings (You can access your account Settings from the drop down menu where your account icon is, on the top right of the screen)</li> <li>Scroll to the bottom of the left hand side menu to find Developer settings and open it.</li> <li>Click Personal access tokens &gt; Tokens (classic)</li> <li>Click Generate new token &gt; Generate new token (classic). You might need to input your Authentification code if you have enabled 2FA.</li> <li>Give it a name, and all the scopes you require (tip: select all scopes and No Expiration), then click Generate Token. Copy the new generated Token</li> </ol> </li> <li>Back on your computer:<ol> <li>If you have been following the steps above, you should still be in your shell with GitHub still asking for your password.</li> <li>Paste your Token here, and you should be logging in. Your changes should then be saved to GitHub.</li> </ol> </li> </ol> Choice B: Connecting via SSH <p>The process of connecting your computer to GitHub using an SSH key is more expedited (and probably less confusing). </p> <p>As a setup step, see if your computer is already connected to GitHub by doing <code>ssh -T git@github.com</code>. If the response message is <code>git@github.com: Permission denied (publickey).</code> it signifies that your computer is not yet linked with GitHub. To link your computer to github to the following:</p> <ol> <li>Generate an SSH key with a level of encryption that you prefer: <code>ssh-keygen -t ed25519 -C &lt;your github email&gt;</code>. This command generates an SSH key with ed25519 encryption (harder to crack!) and adds your email as \"comment\" (<code>-C</code>, will help recongizing the user adding the key). A number of additional questions are going to ask you where you'd like to save the key and whether you'd like to add a password for protection; unless you want to save it elsewhere, feel free to use the default options. Upon completion you should see something like this: <pre><code>Your identification has been saved in /c/Users/&lt;user&gt;/.ssh/id_ed25519\nYour public key has been saved in /c/Users/&lt;user&gt;/.ssh/id_ed25519.pub\nThe key fingerprint is:\nSHA256:SMSPIStNyA00KPxuYu94KpZgRAYjgt9g4BA4kFy3g1o &lt;your github email&gt;\nThe key's randomart image is:\n+--[ED25519 256]--+\n|^B== o.          |\n|%*=.*.+          |\n|+=.E =.+         |\n| .=.+.o..        |\n|....  . S        |\n|.+ o             |\n|+ =              |\n|.o.o             |\n|oo+.             |\n+----[SHA256]-----+\n</code></pre></li> <li>Upon generating the ssh key, copy it. You can reveal it by doing <code>cat ~/.ssh/id_ed25519.pub</code>.</li> <li>In GitHub, go to your settings: click your account icon on top right, and from the drop down menu, select Settings and then SSH and GPG keys. Here, click on New SSH Key, where you can then paste the newly geneated key. Add a name reflecting your machine and save changes. </li> </ol> <p>Optional: if you want to check if you successfully linked your computer to GitHub, do <code>ssh -t git@github.com</code>. You should receive the following message: `Hi ! You've successfully authenticated, but GitHub does not provide shell access. <ol> <li>Create your own repository<ul> <li>Add a README and a license and keep the repository public</li> </ul> </li> <li>Create a <code>docs</code> folder<ul> <li>Within the folder, create an <code>index.md</code> file</li> </ul> </li> <li>Navigate to Settings &gt; Actions &gt; General:<ul> <li>Under Action Permissions select Allow all actions and reusalbe workflows</li> <li>Under Workflow permissions select Read and write permissions and Allow GitHub Actions to create and approve pull requests</li> </ul> </li> <li> <p>Create an <code>requirements.txt</code> file and populate it with the following requirement list:</p> Expand for code! <pre><code>bump2version\ncoverage\nflake8\ngrip\nipykernel\nlivereload\nnbconvert&gt;=7\npip\nsphinx\ntox\ntwine\nwatchdog\nwheel\nmkdocs-git-revision-date-plugin \nmkdocs-jupyter \nmkdocs-material \nmkdocs-pdf-export-plugin\nmkdocstrings \nmkdocstrings-crystal\nmkdocstrings-python-legacy\n#pygments&gt;=2.10,&lt;2.12\n#pymdown-extensions&lt;9.4\n\n# Requirements for core\njinja2&gt;=3.0.2\nmarkdown&gt;=3.2\nmkdocs&gt;=1.4.0\nmkdocs-material-extensions&gt;=1.0.3\npygments&gt;=2.12\npymdown-extensions&gt;=9.4\n\n# Requirements for plugins\nrequests&gt;=2.26\n</code></pre> </li> <li> <p>Create an <code>mkdocs.yml</code> file and  populate it with the following:</p> Expand for code! <pre><code>site_name: Name of your website\nsite_description: Tell people what this website is about\nsite_author: Who you are\nsite_url: 'https://foss.cyverse.org'\n\n# Repository\nrepo_name: The repository name\nrepo_url: 'https://github.com/CyVerse-learning-materials/foss'\nedit_uri: edit/main/docs/\n# Copyright\ncopyright: 'Copyright &amp;copy; 2023 - 2024'\n\n\n# Configuration\ntheme:\n    name: material\nhighlightjs: true\nfont:\n    text: Roboto\n    code: Regular\npalette:\n    scheme: default\n\n# Features  \nfeatures:\n- navigation.instant\n- navigation.tracking\n- navigation.tabs\n- navigation.tabs.sticky\n- navigation.indexes\n- navigation.top\n- toc.follow\n\n# 404 page\nstatic_templates:\n    - 404.html\n\n# Search feature\ninclude_search_page: false\nsearch_index_only: true\n\n# Palette and theme (uses personalized colours)\nlanguage: en\npalette:\n    primary: custom\n    accent: custom\nicon:\n    logo: material/cogs\n    favicon: material/cogs\n\n# Page tree\nnav:\n- Home: index.md\n\n# Extra Plugins\nplugins:\n    - search\n    - mkdocstrings\n    - git-revision-date\n    - mkdocs-jupyter:\n        include_source: True\n        ignore_h1_titles: True\n\n# Extensions (leave as is)\nmarkdown_extensions:\n- admonition\n- abbr\n- attr_list\n- def_list\n- footnotes\n- meta\n- md_in_html\n- toc:\n    permalink: true\n    title: On this page\n- pymdownx.arithmatex:\n    generic: true\n- pymdownx.betterem:\n    smart_enable: all\n- pymdownx.caret\n- pymdownx.critic\n- pymdownx.details\n- pymdownx.emoji:\n    emoji_index: !!python/name:materialx.emoji.twemoji\n    emoji_generator: !!python/name:materialx.emoji.to_svg\n- pymdownx.highlight\n- pymdownx.inlinehilite\n- pymdownx.keys\n- pymdownx.magiclink:\n    repo_url_shorthand: true\n    user: squidfunk\n    repo: mkdocs-material\n- pymdownx.mark\n- pymdownx.smartsymbols\n- pymdownx.superfences:\n    custom_fences:\n        - name: mermaid\n        class: mermaid\n        format: !!python/name:pymdownx.superfences.fence_code_format\n- pymdownx.tabbed\n- pymdownx.tasklist:\n    custom_checkbox: true\n- pymdownx.tilde\n</code></pre> </li> <li> <p>Create a <code>.github/workflows</code> folder and add a <code>ghpages.yml</code> with the following:</p> Expand for code! <pre><code>name: Publish docs via GitHub\non:\npush:\n    branches:\n    - main\n\njobs:\nbuild:\n    name: Deploy docs\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-python@v4\n        with:\n        python-version: 3.9\n    - name: run requirements file\n        run:  pip install -r requirements.txt \n    - name: Deploy docs\n        run: mkdocs gh-deploy --force\n        env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n</code></pre> </li> <li> <p>Navigate to Settings &gt; Pages and make sure that Source is Deploy from a branch and Branch is gh-pages, /(root)</p> <ul> <li>You should be able to access your website at <code>https://&lt;github-username&gt;.github.io/</code>. If you cannot find your website, go to the repository's settings page and navigate to Pages: your website address will be there.</li> </ul> </li> <li>Edit documents as necessary.<ul> <li>Don't forget to add, commit and push changes!</li> <li>Changes will only be visible on the website after a successful push.</li> <li>After each push, next to the commit identifier GitHub will show either a yellow circle (, meaning building), green check (, meaning success), or red cross (, meaning failure).</li> </ul> </li> </ol>"},{"location":"03_documentation_communication/#further-documentation","title":"Further Documentation","text":"<p>Here are some guides that you may find useful:</p> <ul> <li>MarkDown cheatsheet: for correct MarkDown synthax.</li> <li>MkDocs-material: a starting guide to MkDocs Material theme (massive list of supported emojis here).</li> <li>MkDocs-material References: more sophisticated documentation for MkDocs Material. </li> <li>YouTube link to FOSS 2022: Michael explains (~1h mark) his Jekyll-based website and gives a tutorial on how to use academicpages.</li> </ul>"},{"location":"03_documentation_communication/#self-paced-material","title":"Self-Paced Material","text":"<ul> <li>15 Data Science Communities to Join</li> <li>Python &amp; Slack</li> <li>Slack CLI notifications</li> <li>Meetups</li> </ul> GitHub Pages Website Quickstarts <ul> <li> <p> GitHub Pages</p> <ol> <li>Create a GitHub account</li> <li>Clone the repo <code>https://github.com/username/username.github.io</code></li> <li>Create an <code>index.html</code></li> <li>Push it back to GitHub</li> </ol> </li> <li> <p> ReadTheDocs.org</p> <ol> <li>Install</li> <li>Use Github</li> <li>Create a ReadTheDocs account</li> </ol> </li> <li> <p> Material MkDocs</p> <ol> <li>Install Material <ol> <li>use a <code>reqirements.txt</code> </li> <li>or <code>pip install mkdocs-material</code></li> </ol> </li> <li>Clone a repository with an existing template or create a new repo with <code>mkdocs new .</code> </li> <li>Run <code>python -m mkdocs serve</code> to build and serve locally</li> <li>Open your browser to preview the build at https://localhost:8000`</li> </ol> </li> <li> <p> Bookdown</p> <ol> <li>Install R and RStudio</li> <li>Install Bookdown package with <code>install.packages(\"bookdown\", dependencies=TRUE)</code></li> <li>Open the Bookdown demo and get started</li> </ol> </li> <li> <p> Quarto</p> <ul> <li>Follow these instructions</li> </ul> </li> <li> <p> JupyterBook</p> <ul> <li>Create your first book</li> </ul> </li> <li> <p> GitBook</p> <ul> <li>Follow Template builder</li> </ul> </li> </ul>"},{"location":"04_talk_to_computer/","title":"How to Talk to Computers","text":""},{"location":"04_talk_to_computer/#the-command-line-interface","title":"The Command Line Interface","text":"<p>When using a computer, it is typical to use a keyboard and mouse to navigate a cursor across the screen or simply tap on the screens of our smart phones or tablets. Both of these methods make use of the Graphical User Interface (GUI) and have become central to the way we interact with computers. GUIs make computers so easy to use! </p> <p>However, for a more direct and powerful way to instruct your computer, you should learn to use the Command Line Interface (CLI). CLIs are found throughout all operating systems (Windows, MacOS, Linux) though they might have different commands and syntax. </p> <p>For this FOSS lesson on CLI, we will focus on the Unix CLI which is present in MacOS and all Linux operating systems. </p> <p> </p> <p>Attention  Windows users</p> <p>Much of what we are going to be teaching is based on open-source software which operates on cloud and is incompatible with Windows OS.</p> <p>Unix-based systems such as Linux  Ubuntu and  MacOS X, as many scientific tools require a Unix Operating System (OS). </p> <p>There are a number of software that allow  Windows users to execute Unix commands, however we recommend the use of  Windows Subsystem for Linux (WSL) 2.0.</p> Quickstart installation of Window's WSL <p>A system reboot is necessary</p> <ol> <li>Open  PowerShell in Administrator mode (open  Search and look for PowerShell, right click and select \"Run as Administrator\")</li> <li>type <code>wsl --install</code></li> <li>Restart your machine</li> <li>Open  Search and open  WSL; create a username and password, wait for it to finish setting up (should take a few minutes)</li> <li>You're now ready to use  Linux on your Windows Machine!</li> </ol> Where is the WSL Home folder? <p>The Home folders for Linux and Windows are different. The Windows path to the  WSL home folder is <code>\\\\wsl$\\Ubuntu\\home\\&lt;username&gt;</code>.</p> <p>We suggest creating a bookmark in your Windows machine to allow quicker access to the  Linux partition (for quicker access to files).</p> <p>To quickly open the folder, open  WSL and execute <code>explorer.exe .</code>. This will open a folder in Windows at the Linux Home folder. </p> <p> </p> <p> </p>"},{"location":"04_talk_to_computer/#the-unix-shell","title":"The Unix Shell","text":"<p>The CLI sees the computer stripped down to only a Terminal from where one can run powerful commands executed through the Shell.</p> <p>Though there are technical differences between them, the terms Command Line Interface, Terminal, Shell, and BASH will be used more or less interchangeably throughout the lesson. </p> <p>  The Terminal shell</p> <p> </p> Quick video on the shell. <p> </p>"},{"location":"04_talk_to_computer/#accessing-a-linux-shell-in-github","title":"Accessing a Linux Shell in Github","text":"<p>In addition to sharing code and documentation, Github is also a place to do direct computing. Using Github Codespaces we can access a Linux virtual machine and do computing tasks directly from a Github repository. </p>"},{"location":"04_talk_to_computer/#steps-to-launch-codespaces","title":"Steps to Launch Codespaces","text":"<p>1 From your personal Github account, create a new repository</p> <p> </p> <p>2 Name the respository <code>foss_shell_lesson</code> or something similar</p> <p> </p> <p>3 Within your new repository, click the big green button that says &lt;&gt;Code. Go to the Codespaces tab and click on <code>Create codespaces on main</code></p> <p> </p> <p> </p>"},{"location":"04_talk_to_computer/#introductory-shell-commands","title":"Introductory Shell Commands","text":"<p>The following tutorial material was taken from the Carpentries' Shell Module. </p> <p>Download Some Data from the Carpentries</p> <p>To follow along with the tutorial, please download and unzip this data. shell-lesson-data.zip </p> The Command Line Way to Download and Unzip! <p>Execute the following commands: <pre><code>$ sudo apt install unzip\n$ wget https://swcarpentry.github.io/shell-novice/data/shell-lesson-data.zip\n$ unzip shell-lesson-data.zip\n</code></pre></p> <p> </p>"},{"location":"04_talk_to_computer/#navigation","title":"Navigation","text":"<p>  Linux Directory Structure</p> Command Explanation <code>pwd</code> print working directory <code>ls</code> list content of folder <code>cd</code> change directory <p></p> <p>By typing <code>pwd</code>, the current working directory is printed.</p> <p><pre><code>$ pwd\n\n/home/jgillan\n</code></pre> </p> <p>We can then use <code>ls</code> to see the contents of the current directory. </p> <p><pre><code>$ ls  \nshell-lesson-data/   shell-lesson-data.zip*\n</code></pre> </p> Command Flags <p>Each command has flags, or options that you can specify. which are summoned with a <code>-</code>, such as <code>&lt;command&gt; -&lt;flag&gt;</code>. <pre><code>$ ls -a -l -h\n</code></pre></p> <ul> <li> <p>The above command calls for the <code>-a</code> (all), <code>-l</code> (long), <code>-h</code> (human readable) flags. This causes <code>ls</code> to output a list of all files (inculding hidden files/folders) with human readable file size (e.g., it will list 3MB instead of 3000000), permissions, creator, and date of creation.</p> </li> <li> <p>If you do not know what flags are available, you can refer to the <code>man</code> command (or for many tools, use the <code>-h</code> (help) flag).</p> </li> </ul> <p> </p> <p>We can then move inside the folder of our choice doing <code>cd</code>. Doing <code>ls</code> following the opening of the folder of choice, will show the contents of the folder you just moved in. Feel free to explore the contents of the folders by using <code>cd</code> and <code>ls</code>.</p> <p><pre><code>$ cd shell-lesson-data\n$ ls \n\nexercise-data/  north-pacific-gyre/\n\n$ ls exercise-data/\n\nanimal-counts/  creatures/  numbers.txt*  proteins/  writing/\n</code></pre> </p> Tips for Directory Navigation <p><code>.</code> refers to current directory</p> <p><code>..</code> refers to above directory</p> <p><code>/</code> is the directory separator</p> <p><code>~</code> indicates the home directory</p> <p>For example: <pre><code>$ ls .            # lists files and folders in the current directory\n$ ls ..           # lists files and folders in the above directory\n$ ls ~            # lists files and folders in the home directory\n$ ls ~/Documents  # lists files and folders in Documents (a folder present in the home directory)\n</code></pre></p> <p> </p> <p>Use the Tab key to autocomplete</p> <p>You do not need to type the entire name of a folder or file. By using the tab key, the Shell will autocomplete the name of the files or folders. For example, typing the following</p> <pre><code>$ ls exer\n</code></pre> <p>and pressing the tab key, will result in autocompletion.</p> <pre><code>$ ls exercise-data/\n</code></pre> <p>You can then press tab twice, to print a list of the contents of the folder.</p> <pre><code>$ ls exercise-data/\nanimal-counts/ creatures/     numbers.txt    proteins/      writing/ \n</code></pre> <p></p> <p></p>"},{"location":"04_talk_to_computer/#working-with-files-and-directories","title":"Working with Files and Directories","text":"Command Explanation <code>mkdir</code> make a directory <code>touch</code> creat empty file <code>nano</code> or <code>vim</code> text editors <code>mv</code> move command <code>cp</code> copy command <code>rm</code> remove command Help with Commands <p>For every command, typing <code>man</code> (manual) before the command, will open the manual for said command. <pre><code>$ man ls\n</code></pre></p> <ul> <li>The above command will result in opening the manual for the <code>ls</code> command. You can exit the man page by pressing <code>q</code>.</li> </ul> <p> </p> <p>Return to <code>shell-lesson-data</code>, and create a directory with <code>mkdir &lt;name of folder&gt;</code>.</p> <pre><code>$ mkdir my_folder\n$ ls\n\nexercise-data/  my_folder/  north-pacific-gyre/\n</code></pre> <p>Notice the new <code>my_folder</code> directory.</p> <p> </p> <p>Naming your files</p> <p>It is strongly suggested that you avoid using spaces when naming your files. When using the Shell to communicate with your machine, a space can cause errors when loading or transferring files. Instead, use dashes (<code>-</code>), underscores (<code>_</code>), periods (<code>.</code>) and CamelCase when naming your files.</p> <p>Acceptable naming: <pre><code>$ mkdir my_personal_folder\n$ mkdir my_personal-folder\n$ mkdir MyPersonal.Folder\n</code></pre> </p> What will happen if you create a directory with spaces? <p>You will obtain as many folders as typed words! <pre><code>$ mkdir my folder\n$ ls -F\nexercise-data/  folder/  my/  north-pacific-gyre/\n</code></pre> Notice the two folders <code>my</code> and <code>folder</code>.</p> <p> </p> <p>Create an empty file with <code>touch &lt;name of file&gt;</code></p> <pre><code>$ touch new_file.txt\n</code></pre> <p><code>touch</code> will create an empty file</p> <p></p> <p>Add text to the new file <pre><code>nano new_file.txt \n</code></pre></p> <p> </p> <p>Use <code>mv &lt;name of file or folder you want to move&gt; &lt;name of destination folder&gt;</code> to move your newly created file to the directory you created previously (you can then use <code>ls</code> to check if you successully moved the file).</p> <p><pre><code>$ ls\nexercise-data/  new_file*  my_folder/  north-pacific-gyre/\n\n$ mv new_file.txt my_folder/\n$ ls \nexercise-data/  my_folder/  north-pacific-gyre/\n\n$ ls my_folder/\nnew_file.txt*\n</code></pre> <code>mv</code> can also be used to rename a file or folder with  <code>mv &lt;name of file or folder you want to change&gt; &lt;new name&gt;</code>.</p> <pre><code>$ cd my_folder/\n$ mv new_file my_file\n$ ls\nmy_file*\n</code></pre> <p> </p> <p><code>cp</code> is the command to copy a file with the syntax <code>cp &lt;name of file you want to copy&gt; &lt;name of copy file&gt;</code></p> <pre><code>$ cp my_file copy_my_file\n$ ls\ncopy_my_file*  my_file*\n</code></pre> <p>Copying folders</p> <p>To copy folders and the content of these folders, you will have to use the <code>-r</code> flag (recursive) for <code>cp</code> in the following manner <code>cp -r &lt;name of folder you want to copy&gt; &lt;name of copy folder&gt;</code> (following example is from the <code>shell-lesson-data/</code> directory). <pre><code>$ cp -r my_folder/ copy_my_folder\n$ ls \ncopy_my_folder/  exercise-data/  my_folder/  north-pacific-gyre/\n\n$ ls my_folder/\ncopy_my_file*  my_file*\n\n$ ls copy_my_folder/\ncopy_my_file*  my_file*\n</code></pre></p> <p> </p> <p>To remove an unwanted file, use <code>rm &lt;name of file to remove&gt;</code>.</p> <pre><code>$ rm copy_my_file\n$ ls \nmy_file\n</code></pre> <p>Removing folders</p> <p>Save as the \"Copying Folders\" note, you have to use the <code>-r</code> flag to remove a folder <code>rm -r &lt;name of folder you want to remove&gt;</code> (following example is from the <code>shell-lesson-data/</code> directory). <pre><code>$ rm -r copy_my_folder/\n$ ls -F\nexercise-data/  my_folder/  north-pacific-gyre/\n</code></pre></p> <p> </p>"},{"location":"04_talk_to_computer/#shell-script","title":"Shell Script","text":"<p>Here we are going to show an example command line automation using a shell script. This is what makes the command line powerful!</p> <p>Shell Script</p> <p>A shell script is a file with the extension '.sh'. It is essentially a text file that lists out multiple shell commands. When the shell script is run, the computer will run all of the commands in sequence in an automated way.  </p> <p></p> <p>Navigate to the <code>shell-lesson-data</code> directory</p> <pre><code>$ cd /home/jgillan/shell-lesson-data\n</code></pre> <p></p> <p>Create the shell script</p> <p><pre><code>$ nano backup.sh\n</code></pre> The text editor Nano will pop up and it will be empty.</p> <p></p> <p>Copy and paste the following commands into <code>backup.sh</code></p> <p><pre><code>#use Bash shell to run the following commands\n#!/bin/bash\n\n## Variables\n#the directory you want to back up (e.g., shell-lesson-data)\nSOURCE_DIR=$(find / -type d -name \"shell-lesson-data\" 2&gt;/dev/null) # Note: if you are working on your computer, this will look in every folder. Be careful with this line!\n\n#location where the backup will be stored\nBACKUP_DIR=\"$HOME/Backup\"\n\n#used to create a unique name for each backup based on the current date and time\nTIMESTAMP=$(date +\"%Y-%m-%d_%H-%M-%S\")\n\n# name of the compressed backup file\nARCHIVE_NAME=\"backup_$TIMESTAMP.tar.gz\"\n\n\n# Create backup directory if it doesn't exist\nmkdir -p \"$BACKUP_DIR\"\n\n# Create a compressed archive of the source directory\ntar -czf \"$BACKUP_DIR/$ARCHIVE_NAME\" -C \"$SOURCE_DIR\" .\n\n# Output the result\necho \"Backup of $SOURCE_DIR completed!\"\necho \"Archive created at $BACKUP_DIR/$ARCHIVE_NAME\"\n</code></pre> </p> <p>Exit nano with <code>ctrl + x</code></p> <p></p> <p>Modify permission to make the shell script executable <pre><code>$ chmod +x backup.sh\n</code></pre></p> <p></p> <p>Run the shell script <pre><code>$ ./backup.sh\n</code></pre></p> <p> Go back to your home directory and look for the new backup directory <pre><code>$ cd ~\n$ cd ls\n</code></pre></p> <p>There should be a new directory called 'Backup' with a compressed file within it. </p> <p> </p>"},{"location":"04_talk_to_computer/#more-carpentries-lessons-on-linux-command-line","title":"More Carpentries Lessons on Linux Command line","text":"<ul> <li>Pipes and Filters</li> <li>Loops</li> <li>Scripts</li> <li>Finding Things</li> </ul>"},{"location":"04_talk_to_computer/#llm-chatbots-for-open-science","title":"LLM Chatbots for Open Science","text":"<p>Large Language Model (LLM) chatbots have fundamentally changed how we humans are going to interact with computers going forward. They provide a natural language interface to instruct computers to do many tasks including:</p> <ul> <li>Read, write, and summarize text</li> <li>Analyze data</li> <li>Explain techical topics</li> <li>Search the web and retrieve information</li> <li>Generate, optimize, and explain many types of computer code </li> <li>Understand and generate images</li> </ul> <p></p> <p>Current LLMs generally provide recommendation for how you could do things. ie, they provide you code and text recommendations but don't actually execute anything. But these technologies are advancing quickly and new capabilities are developed and released constantly. Soon, AI Agents could be everywhere executing on instructions in autonomous and semi-autonomous ways.</p> <p></p>"},{"location":"04_talk_to_computer/#commercial-chatbots","title":"Commercial Chatbots","text":"<ul> <li> ChatGPT</li> <li> Gemini</li> <li> Claude</li> <li> Copilot</li> </ul>"},{"location":"04_talk_to_computer/#llms-in-150-words-or-less","title":"LLMs in 150 words (or less)","text":"<p>How they're made: LLMs work by training on vast amounts of text from the internet. They learn patterns, grammar, and context from this data. When you give them a prompt, they generate text based on what they've learned. Imagine a super-smart autocomplete for text, but it can also create entire paragraphs or articles.</p> <p>How they work: LLMs don't understand like humans do. They predict what comes next in a sentence using math and probabilities. They don't have thoughts or feelings. They mimic human language but can make mistakes or write nonsense if not guided well.</p> <p>How you can use them: They're incredibly versatile. You can use them for answering questions, writing essays, coding help, and more. But you must be cautious because they can generate biased or false information if not used responsibly. </p> <p>In a nutshell, LLMs are like super-powered text generators trained on the internet's vast knowledge.</p> <p> </p> <p> VERIFY EVERTHING CHATBOTS TELL YOU! </p> <p> </p>"},{"location":"04_talk_to_computer/#prompt-writing","title":"Prompt Writing","text":"<p>LLM Chatbots are meant to be conversational. In general, you are asking the Chatbot questions (known as Prompts) and the Chatbot will respond with answers. </p> <p>It is a bit of an artform to get the Chatbot to provide answers with the specificity and format that you want. An entire field of study has sprung up, called Prompt Engineering, which seeks to find the magic words that will elicit the best (and technically correct) responses from the Chatbot. </p> <p> </p>"},{"location":"04_talk_to_computer/#prompt-priming","title":"Prompt Priming","text":"<p>Provide lots of organized details to help the Chatbot understand the question and what it's task is. This could include adding a backstory or context for why you are asking the question. Be very specific in terms of what you want from the Chatbot and how you want it. </p> <p>Zero-shot unconditioned prompts are likely to return the least specific responses. Responses are more likely to be useful when multiple specific output types are defined.</p> Types of Priming Example Zero (Shot) \"Write five examples of assessments for watershed health.\" Single \"Write five examples of assessments for watershed health. Here is one example: Geomorphology\" Multiple \"Write five examples of assessments for watershed health related to geomorphology, water quality, and species diversity.\" <p> </p>"},{"location":"04_talk_to_computer/#linked-prompts","title":"Linked Prompts","text":"<p>Responses to prompts may not return the exact details or information that you are after the first time. Follow-up by rephrasing your prompts more carefully and continuing with iterative prompting can build upon your priors.</p> <p>\"Chain prompting\" or \"Linked Prompting\" brings multiple prompts together.</p> Linked Prompting Examples Step 1: Priming \"I want you to act as an eminent hydrologist from CUASHI. Provide me with a list of the ten most important topics in hydrology over the last decade focused around research in the global south, working with indigenous communities, and traditional ecological knowledge systems.\" Step 2: Summarizing \"Based on the list you just created, summarize the most pressing financial challenges faced by indigenous communities in the Global South, versus indigenous communities in North America, in less than 50 words.\" Step 3: Try again with a web search \"Based on the results of web access, can you confirm the validity of the ten important topics and provide at least one reference to each.\" <p>Encouraging the Chatbot to do Better</p> <p>Chatbot responses can be missing information or just plain wrong. When this occurs, you can point out the mistake and ask the Chatbot to provide a more complete or better answer. Don't settle for poor responses!</p> <p> </p>"},{"location":"04_talk_to_computer/#role-playing","title":"Role Playing","text":"<p>Some people find that asking the Chatbot to adopt a persona will lead to better responses. </p> <p>\"I want you to act as ...\" will establish what type of conversation you are planning to have. </p> Types of Roles Project Manager Copywriter / Editor Paper Reviewer Teacher / Mentor / Advisor Student / Learner / Participant Software Engineer DevOps Engineer Linux Terminal Python Interpreter Web Browser <p> </p>"},{"location":"04_talk_to_computer/#prompting-chatbots-for-foss","title":"Prompting Chatbots for FOSS","text":""},{"location":"04_talk_to_computer/#provide-a-general-outline-for-a-data-management-plan","title":"Provide a general outline for a data management plan","text":"<p><pre><code>I am writing a grant proposal to the National Science Foundation. \nCould you please provide me a basic template for a data management plan (DMP) and \nplease provide url links to resources that can help me with NSF DMP requirements.\n</code></pre> </p>"},{"location":"04_talk_to_computer/#provide-a-step-by-step-recipe-to-create-and-serve-an-mkdocs-website-in-github","title":"Provide a step-by-step recipe to create and serve an mkdocs website in Github","text":"<p><pre><code>I would like to create a personal website using the MKdocs style \nand host it on Github pages.\n\nCould you please write me a step-by-step guide starting \nwith importing an existing github repository that has the mkdocs material.\n</code></pre> </p>"},{"location":"04_talk_to_computer/#write-shell-commands-and-shell-scripts","title":"Write shell commands and shell scripts","text":"<pre><code>I would like to create a linux shell script to automate the backup of my working directory. \nCould you please suggest a shell script that will copy my working directory \nin a different directory and compress the file into an archive. \nPlease name the file based on the current time and date. \n</code></pre>"},{"location":"04_talk_to_computer/#write-git-commands","title":"Write git commands","text":"<pre><code>Could you please provide me a step-by-step workflow for using git with github? \nI found a repository that I want to build on in Github. \nI would like to work on the material on my local machine and then save it back up to github. \nI would like to workflow to be for the linux command line. \n</code></pre>"},{"location":"04_talk_to_computer/#write-download-and-conda-commands","title":"Write download and conda commands","text":"<p><pre><code>I am writing a lot of scripts using python. I have heard that environment managers such as conda may be useful to me. \nI don't know anything about conda, so can you explain some things?\n1. Give me a high level overview of what environment managers are and what conda is specifically.\n2. Please create a step-by-step guide for downloading conda on my machine, and how to use conda to create custom environments. \n3. Please explain and give my steps to share my environment with colleagues.\n</code></pre> </p>"},{"location":"04_talk_to_computer/#write-docker-run-commands","title":"Write docker run commands","text":"<pre><code>I would like to run a docker container that consists of a jupyter notebook. \nCan you please suggest a docker run command that launches the jupyter notebook\nand mounts a volume of data in it. \n</code></pre>"},{"location":"04_talk_to_computer/#write-docker-files","title":"Write docker files","text":"<pre><code>I would like to create a docker image that consists of R studio and \nsome customized Rcode. Can you tell me the steps to 1. make a dockerfile and \nbuild the docker image; and 2. Upload the docker image to docker hub.\n</code></pre> ChatGPT  Awesome Lists <p>There is an ever changing meta-list of  Awesome lists curated around ChatGPT plugins and extensions.</p> <p> search: <code>chatgpt+awesome</code></p> <p>Check out lists around:</p> <p> ChatGPT Prompts</p> <p> ChatGPT Data Science Prompts</p> <p> API plugins, extensions, &amp; applications</p>"},{"location":"05_version_control/","title":"Version Control","text":"<p>Learning Objectives</p> <p>After this lesson, you should be able to:</p> <ul> <li>Understand the basics of <code>git</code> as a resource for reproducible programming</li> <li>Describe tools and approaches to creating your <code>git</code> Repositories</li> <li>Describe best practices for maintaining GitHub Organizations and Repositories</li> <li>Maintain own GitHub user profile and repositories</li> </ul> <p>Version control refers to keeping track of the version of a file, set of files, or a whole project.</p> <p>Some version control tools:</p> <ul> <li> Microsoft Office's Track Changes functionality</li> <li> Apple's Time Machine</li> <li> Google Docs' Version History</li> <li> Git</li> </ul> <p>Version control is as much a philosophy as a set of tools; you don't need to master Git to utilize version control (though it is certainly a worthwhile tool for many researchers).</p> <p>  We have all been here, taken by the Software Carpentry Version Control lesson. </p>"},{"location":"05_version_control/#git-vs-github","title":"Git vs.  GitHub","text":"<p>Git is a command-line program for version control of repositories. It keeps track of changes you make to files in your repository and stores those changes in a .git folder in that repository. These changes happen whenever you make a commit. Git stores the history of these commits in a \"tree\", so you can go back to any previous commit. By keeping track of the differences between commits, Git can be much more efficient than storing an entire copy of each version in a document's history.</p> <p>You could utilize Git completely on its own, on your local computer, and get a lot of benefits. You will have a history of the changes you made to a project, allowing you to go back to any old version of your work. However, where Git really shines is in collaborative work. In order to effectively collaborate with others on a project, you need two basic features: a way to allow people to work in parallel, and a way to host repositories somewhere where everyone can access them. The first feature is branching, which is part of Git, and the hosting part can be taken care of by platforms like GitHub, GitLab, or Bitbucket. We will focus on GitHub.</p> <p>GitHub is a site that can remotely host your Git repositories. By putting your repository onto GitHub, you get a backup of the repository, a way to collaborate with others, and a lot of other features.</p> <ul> <li> <p>Git: </p> <ul> <li>First developed in 2005, git is a version control software that allows users to make changes and add versions to their code.</li> <li>Changes and versions are saved locally.</li> <li>Accessible through the Shell.</li> </ul> </li> <li> <p>GitHub:</p> <ul> <li>First launched in 2008, its main focus is hosting and sharing code.</li> <li>Uses Git version control software. </li> <li>Changes and versions are saved online (requires an account).</li> <li>Mainly administered through the web (it also has a desktop app).</li> <li>Acquired by Microsoft in 2018.</li> </ul> </li> </ul> <p>  Git vs GitHub, simplified </p>"},{"location":"05_version_control/#definitions","title":"Definitions","text":"<p>Git-related Definitions</p> <p>Platforms:</p> <ul> <li>Git: tool for version control.</li> <li>GitHub: hosted server that is also interactive.</li> </ul> <p>Locations and directions:</p> <ul> <li>repo: short for repository</li> <li>local: on your personal computer.</li> <li>remote: somewhere other than your computer. GitHub can host remote repositories.</li> <li>upstream: primary or main branch of original repository.</li> <li>downstream: branch or fork of repository.</li> </ul> <p>Actions:</p> <ul> <li>clone: copy of a repository that lives locally on your computer. Pushing changes will affect the repository online.</li> <li>pull: getting latest changes to the repository on your local computer.<ul> <li>the fetch command does the same, however one needs to also merge the changes, whilst with pull, the merge action is automatic.</li> </ul> </li> <li>branch: a history of changes to a repository. You can have parallel branches with separate histories, allowing you to keep a \"main\" version and development versions.</li> <li>fork: copy of someone else's repository stored locally on your account. From forks, you can make pull requests to the main branch.</li> <li>commit: finalize a change.</li> <li>push: add changes back to the remote repository.</li> <li>merge: takes changes from a branch or fork and applies them to the main.</li> </ul> <p>These are also commands when paired with <code>git</code>!</p> <p>Using the following synthax <code>git &lt;command&gt;</code> one can trigger an action. An example is <code>git pull</code>, which will pull all of the latest changes in the remote repository.</p> <p>Funtional: </p> <ul> <li> <p>pull request: proposed changes to/within a repository.</p> </li> <li> <p>issue: suggestions or tasks needed for the repository. Allows you to track decisions, bugs with the repository, etc.</p> </li> </ul> <p>  Visualizing the commands through a workflow example  (graphic's correction: marged merged) </p>"},{"location":"05_version_control/#introducing-github","title":"Introducing GitHub","text":"<p>Since we are talking about making science accessible, we invite you to use GitHub to save and share your code. Please start by creating a GitHub account at https://github.com/.</p> <p>User Profile</p> <p>Just like in any other social media platform, you can create a profile for yourself. This is where you can add a picture, a description of yourself, and a link to your website. You can also add your location, your organization, and your pronouns. You can have a list of your most important repositories and show off your daily contributions. You are able to customize your profile to your liking. Check out this profile for fancy example. </p> <p></p> <p>Search</p> <p>At the top of most pages, is a search bar. Use this to find repositories, users, and organizations. You can also use it to search for specific code within a repository.</p> <p></p> <p>Starring Repositories</p> <p>You can star repositories that you like. This is a way to bookmark repositories that you want to come back to later. You can also use this to show your appreciation for a repository. You can see all of your starred repositories by clicking on your profile picture and then clicking on Your stars.</p> <p></p> <p>Creating Your Own Repository</p> <p>Repositories are where your code is stored. A suggestion is to have one repository for one project.</p> <p>You can create repositories by clicking on the Repositories tab, and then clicking New.</p> <p></p> <p>Here, you can choose the name of your own repository, choose to make it private or public, adding a README and a licence. It is strongly reccomended that you choose to add an empty README file.</p> <p></p> <p>So, why a README?</p> <p>There are two main reasons why you would like a README file:</p> <ol> <li>It adds structure to your repository automatically - otherwise you would need to create said structure by yourself (not recommended for beginners).</li> <li>It is the \"default\" file that GitHub reads upon opening the repository. It can be treated as the go-to file that explains what the repository is for, what each file does, how to cite your reasearch, amongst other things.</li> </ol> <p>Adding a Licence</p> <p>The addition of a licence can heavily contribute to the shareability of your code. Make sure that whichever licence you choose is in line with your principals as well as your project's. GitHub comes with a list of licences which you can review. It is also common to choose a licence later on!</p> <p>Ultimately, your new repository should look like the following screenshot. Notice the LICENCE document and the README.md</p> <p></p> <p>Editing the README.md (and other text files on GitHub)</p> <p>The Github repository file has a .md extension which stands for Markdown. Markdown is a lightweight markup language for creating formatted text using a plain-text editor common throughout text files on the web. It uses symbols (*~-#`) for syntaxing text, and it is what GitHub (and this website!) use to format text. Markdown is easier to use than HTML. You can read more on Markdown on the Markdown Guide.</p>"},{"location":"05_version_control/#practical-git-techniques","title":"Practical Git Techniques","text":"<p>  The version control path sofware takes before release </p> <p>The basic Git life cycle</p> <p>When using Git for your version control, the usual life cycle is the following:</p> Action Explanation 1. <code>git clone &lt;repository&gt;</code> Clones the target repository to your machine 2. <code>git status</code> Checks whether there are changes in the remote, original repository 3. <code>git pull</code> Pulls any change to your local repository 4. <code>git add &lt;changes&gt;</code> Adds to a future commit any change 5. <code>git commit -m \"&lt;message&gt;\"</code> Creates the commit and adds a descriptive message 6. <code>git push</code> Pushes the changes commited from local to the remote repository <p>If there are no branches or external pull requests, the basic Git life cycle is summarizable like this:</p> <pre><code>graph LR\nA[1. git clone] --&gt; B[2. git status] --&gt;C([differences from origin?]):::colorclass;\nC--&gt;|yes| D[3. git pull]--&gt; E;\nC--&gt;|no| E[4. git add];\nE--&gt;F[5. git commit] --&gt;G[6. git push];\nG--&gt;B;\nclassDef colorclass fill:#f96</code></pre> <p>After learning the basics of using Git, which you can learn with the Software Carpentry Git Lesson, there are some next things that can be useful to learn. Here are a couple topics that are worth digging into more:</p> <ul> <li> <p> Using the Git log</p> <ul> <li>You can access using git log</li> <li>Will show you your commit history</li> <li>Useful for figuring out where you need to roll back to</li> </ul> </li> <li> <p> Reverting</p> <ul> <li>There are a lot of different ways to \"undo\" something in Git</li> <li>Some are safer, some are a bit riskier</li> <li>Depends on what stage of the commit process you're in</li> <li>Here are some useful resources:<ul> <li>10 Common Git Problems and How to Fix Them</li> <li>\"So you have a mess on your hands...\"</li> <li>How to undo almost anything</li> </ul> </li> </ul> </li> <li> <p> Branching</p> <ul> <li>This is important to learn if you're going to be doing any sort of collaboration</li> <li>Here is a fantastic resource for learning how git branching really works: https://learngitbranching.js.org/</li> <li>you will probably have to deal with merge conflicts at some point<ul> <li>Merge conflicts happen when two branches are being merged, but they have different changes to the same part of a file</li> <li>Perhaps you are working on a feature branch, and you change line 61 in file.R, but someone else made a change to the main branch at line 61 in file.R. When you try to merge the feature and main branches, Git won't know which changes to line 61 in file.R are correct, and you will need to manually decide.</li> <li>Here are some good resources:<ul> <li>Resolving merge conflicsresolving-a-merge-conflict-using-the-command-line</li> <li>git - ours &amp; theirs, a CLI resource to help with conflicts</li> </ul> </li> </ul> </li> </ul> </li> <li> <p> .gitignore</p> <ul> <li>You often want Git to completely ignore certain files</li> <li>Generated files (like HTML files from Markdown docs)</li> <li>IDE-specific files like in .RStudio or .vscode folders</li> <li>really big files, like data or images<ul> <li>If you accidentally commit a really big file, GitHub might not let you push that commit</li> <li>If you have a huge file in Git, your repository size can get way too big</li> <li>This is a pain to solve, so use the .gitignore file ahead of time, but if you need to fix this, here is a great resource: </li> <li>Removing Large Files From git Using BFG and a Local Repository</li> </ul> </li> </ul> </li> </ul>"},{"location":"05_version_control/#large-data-and-github","title":"Large Data and GitHub","text":"<p>GitHub allows commited files to be uploaded only if the file is of 100MB or less (with a warning being issued for files between 50MB and 100MB). Additionally, GitHub recommends to keep repositories below the 1GB threshold, as this also allows for quicker cloning and sharing of the repository. If a large file has been uploaded by mistake and you wish to remove it, you can follow these instrutctions.</p> <p>If you do have to work with large files and Git, here are some questions to ask yourself:</p> <ul> <li>Is this data shareable?</li> <li>Are there alternative file hosting platforms I can use?</li> <li>How will this data impact the sharability of this repository?</li> <li>Am I using a .gitignore?</li> </ul> <p>GitHub now offers the Git Large File Storage ( Git LFS): the system works by storing references to the file in your repository, but not the file itself -- it creates a pointer file within the repo, and stores the file elsewhere. If you were to clone the repository, the pointer file will act as a map to show you how to obtain the original file.</p> <p>Git LFS data upload limits are based on your GitHub subscription: </p> <ul> <li>2 GB for GitHub free and GitHub Pro</li> <li>4 GB for GitHub Team</li> <li>5 GB for GitHub Enterprise Cloud</li> </ul> <p>  A depiction of how the Git LFS pointer-repository relationship works. </p>"},{"location":"05_version_control/#useful-github-features","title":"Useful GitHub Features","text":"<p>At its core, GitHub is just a place to host your Git repositories. However, it offers a lot of functionality that has less to do with Git, and more to do with Project Management. We will walk through a few of these useful features.</p> <ul> <li> <p> Issues</p> <ul> <li>Issues let you plan out changes and suggestions to a repo</li> <li>Closing/reopening</li> <li>Labels</li> <li>Assigning</li> <li>Templates</li> <li>Numbering/mentioning</li> </ul> </li> <li> <p> Pull Requests</p> <ul> <li>Pull requests are a way to request merging code from one branch to another</li> <li>typical workflow is for someone to fork a repo, then make a PR from that repo to another</li> <li>Reviews</li> <li>Commenting</li> <li>Merging</li> <li>Closing issues</li> </ul> </li> <li> <p> Organizations</p> <ul> <li>You can use Organizations to organize sets of repositories</li> <li>Roles</li> <li>Teams</li> <li>GitHub documentation:</li> </ul> </li> <li> <p>Other neat things</p> <ul> <li>Permissions/collaborators</li> <li>GitHub Classroom</li> <li>Gists</li> <li>CSV and map rendering</li> <li>Code editor</li> </ul> </li> </ul>"},{"location":"05_version_control/#beyond-git-and-github","title":"Beyond Git and GitHub","text":"<p>There are other platforms that address Version Control and have similar functionalities to GitHub:</p> <ul> <li> <p> GitLab: An alternative to GitHub, GitLab offers both a cloud-hosted platform and a self-hosted option (GitLab CE/EE). It provides a comprehensive DevOps platform with built-in CI/CD, container registry, and more.</p> </li> <li> <p> Bitbucket: Atlassian's Bitbucket is a Git repository hosting service that also supports Mercurial repositories. It offers integration with Jira, Confluence, and other Atlassian products.</p> </li> <li> <p> SourceForge: A platform that provides Git and Subversion hosting, as well as tools for project management, issue tracking, and collaboration.</p> </li> <li> <p> AWS CodeCommit: Part of Amazon Web Services (AWS), CodeCommit is a managed Git service that integrates seamlessly with other AWS services.</p> </li> <li> <p> Azure DevOps Services (formerly VSTS)): Microsoft's Azure DevOps Services offers Git repository hosting along with a wide range of DevOps tools for planning, developing, testing, and deploying software.</p> </li> <li> <p> Mercurial: Like Git, Mercurial is a distributed version control system, but with a different branching and merging model. It's an alternative to Git for version control.</p> </li> </ul>"},{"location":"05_version_control/#adding-code-to-github-via-command-line","title":"Adding Code to GitHub via Command Line","text":"Prerequisite: a GitHub account <p>Navigate to the GitHub website and click Sign Up, and follow the on screen instructions.</p> <p>Through this exercise, users will learn to make changes using the command line. To remove potential issues with SSH and Tokens, we are going to carry out this exercise using  CodeSpaces. Refer to the \"Steps to Launch Codespaces\" section in the How to Talk to Computers in order to launch a  CodeSpace.</p> Adding Code Locally Using Your Machine <p>This exercise can be carried out locally, on your machine. Here are the requisites and steps required to clone the repository and push changes back to GitHub.</p> <p>Prerequisites</p> Installing Git <p>You can follow the official guidelines here: https://github.com/git-guides/install-git. Here we recommend how to install Git on your local machine.</p> Windows <p>These instructions are for Windows users NOT using WSL2. If you do have WSL2, follow the Unix instructions.</p> <ol> <li>Navigate to the latest Git for Windows installer and download the latest version.</li> <li>Once the installer has started, follow the instructions as provided in the Git Setup wizard screen until the installation is complete.</li> <li>Search and open Git Bash. From here, you should be able to run Git commands.</li> </ol> MacOS <ol> <li>Install Homebrew (a package manager for MacOS): `/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"``</li> <li>Install Git: <code>brew install git</code></li> </ol> Unix <p>The following command will install git and all related packages on your Unix machine. <pre><code>$ sudo apt-get install -y git-all\n</code></pre></p> <p>You then need to choose between generating a Personal Access Token or using SSH keys. This is useful if you want to work locally and push your changes to GitHub.</p> Choice A: Generate a Personal Access Token <p>You can follow the official documentation on how to generate Tokens here. Following are quick steps you can follow in order to setup your account on your machine using tokens:</p> <ol> <li>On your coumputer:<ol> <li>Clone your repository (<code>git clone &lt;repository&gt;</code>)</li> <li>Make changes where necessary, and add (<code>git add &lt;changed files&gt;</code>), commit (<code>git commit -m \"&lt;message on changes&gt;\"</code>) and push your changes (<code>git push origin</code>).</li> <li>You should be prompted to logging in your GitHub account. Put your email but not your password. Instead, open your web browser and follow the steps below:</li> </ol> </li> <li>On GitHub:<ol> <li>Navigate to your GitHub Settings (You can access your account Settings from the drop down menu where your account icon is, on the top right of the screen)</li> <li>Scroll to the bottom of the left hand side menu to find Developer settings and open it.</li> <li>Click Personal access tokens &gt; Tokens (classic)</li> <li>Click Generate new token &gt; Generate new token (classic). You might need to input your Authentification code if you have enabled 2FA.</li> <li>Give it a name, and all the scopes you require (tip: select all scopes and No Expiration), then click Generate Token. Copy the new generated Token</li> </ol> </li> <li>Back on your computer:<ol> <li>If you have been following the steps above, you should still be in your shell with GitHub still asking for your password.</li> <li>Paste your Token here, and you should be logging in. Your changes should then be saved to GitHub.</li> </ol> </li> </ol> Choice B: Connecting via SSH <p>The process of connecting your computer to GitHub using an SSH key is more expedited (and probably less confusing). </p> <p>As a setup step, see if your computer is already connected to GitHub by doing <code>ssh -T git@github.com</code>. If the response message is <code>git@github.com: Permission denied (publickey).</code> it signifies that your computer is not yet linked with GitHub. To link your computer to github to the following:</p> <ol> <li>Generate an SSH key with a level of encryption that you prefer: <code>ssh-keygen -T ed25519 -C &lt;your github email&gt;</code>. This command generates an SSH key with ed25519 encryption (harder to crack!) and adds your email as \"comment\" (<code>-C</code>, will help recongizing the user adding the key). A number of additional questions are going to ask you where you'd like to save the key and whether you'd like to add a password for protection; unless you want to save it elsewhere, feel free to use the default options. Upon completion you should see something like this: <pre><code>Your identification has been saved in /c/Users/&lt;user&gt;/.ssh/id_ed25519\nYour public key has been saved in /c/Users/&lt;user&gt;/.ssh/id_ed25519.pub\nThe key fingerprint is:\nSHA256:SMSPIStNyA00KPxuYu94KpZgRAYjgt9g4BA4kFy3g1o &lt;your github email&gt;\nThe key's randomart image is:\n+--[ED25519 256]--+\n|^B== o.          |\n|%*=.*.+          |\n|+=.E =.+         |\n| .=.+.o..        |\n|....  . S        |\n|.+ o             |\n|+ =              |\n|.o.o             |\n|oo+.             |\n+----[SHA256]-----+\n</code></pre></li> <li>Upon generating the ssh key, copy it. You can reveal it by doing <code>cat ~/.ssh/id_ed25519.pub</code>.</li> <li>In GitHub, go to your settings: click your account icon on top right, and from the drop down menu, select Settings and then SSH and GPG keys. Here, click on New SSH Key, where you can then paste the newly geneated key. Add a name reflecting your machine and save changes. </li> </ol> <p>Optional: if you want to check if you successfully linked your computer to GitHub, do <code>ssh -T git@github.com</code>. You should receive the following message: `Hi ! You've successfully authenticated, but GitHub does not provide shell access. <p>Adding code locally is a more complex than adding code through the web page, but it allows for better control on what files you commit.</p> <ul> <li>To add or modify code locally, you need to clone the repository on your computer.</li> <li>You can then clone the repository by clicking on the Code button, and copying the link shown      </li> <li>On your machine, open a terminal window and type the following command: <pre><code>$ git clone &lt;repository address&gt;     # Replace &lt;repository address&gt; with the link you copied such as below\n\n$ git clone https://github.com/CosiMichele/FOSSF24-tutorial.git\nCloning into 'FOSSF24-tutorial_tutorial'...\nremote: Enumerating objects: 13, done.\nremote: Counting objects: 100% (13/13), done.\nremote: Compressing objects: 100% (12/12), done.\nremote: Total 13 (delta 5), reused 0 (delta 0), pack-reused 0\nUnpacking objects: 100% (13/13), 14.47 KiB | 90.00 KiB/s, done.\n</code></pre></li> <li>Your code is now available to you on your machine, and you can add and modify files as needed.</li> </ul> <p>When using CodeSpaces, there is no need to clone your repository (steps for cloning are reported in the admonition above).</p> <p>You can now modify or add files locally. However you will still have to push changes to the repository. Prior to doing so there are a couple of steps you should do:</p> <ul> <li><code>git status</code>: it checkes on the status of the repository (files that have been modified, deleted, added - from either local or in the online repository)</li> <li><code>git pull</code>: it checks and \"pulls\" changes from the online repository to your local repository. It ensures that you are always updated on the repository files and it can save a lot of time in case there are clashing commits from different users.</li> </ul> <p>To do so:</p> <ul> <li>Add all fiels you have modified and want to commit: <pre><code>$ git add .    # Recall that \".\" (period) stands for all files in a folder \n</code></pre></li> <li>Commit the changes. When committing changes, you have to add a message (in quotation marks) with the <code>-m</code> flag. This message is a concise and descriptive few words about what you did: <pre><code>$ git commit -m \"locally added and modified files\"\n[main 05f0ef6] locally added and modified files\n 2 files changed, 11 insertions(+), 1 deletion(-)\n create mode 100644 file_from_local.md\n</code></pre></li> <li>push your changes with push: <pre><code>$ git push\nEnumerating objects: 6, done.\nCounting objects: 100% (6/6), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (4/4), done.\nWriting objects: 100% (4/4), 585 bytes | 32.00 KiB/s, done.\nTotal 4 (delta 0), reused 0 (delta 0)\nTo https://github.com/CosiMichele/FOSSF24-tutorial.git\n   b649de3..05f0ef6  main -&gt; main\n</code></pre></li> </ul> <p>You can now see the changes you made locally on the GitHub repository page.</p> <p></p>"},{"location":"05_version_control/#branching","title":"Branching","text":"<p>Branching allows you to develop your code whilst in a contained environment separate from your main environment. You can view the list and number of branches on the top of your repository.</p> <p></p> <p>Why working on branches?</p> <p>Branches allow you to add/remove/change exisiting code independently from your main branch. This code can include alphas, betas and different versions of your code. Branches can be used to develop documentation or include different functionalitiets focused on Operating Systems and/or clusters and job schedulers. If needed, you can add these codes to your main branch later using pull requests.</p> <p>To create a new branch select the  branch icon (listing the number of branches). This will open the branch page, which will list all of the branches in this repository.</p> <p></p> <p>Select New Branch on the top right. Give the new branch a name of your choice, select the source of code (in this case the only source of code can be the main branch) and select Create branch.</p> <p></p> <p>You can now see the updated list of all your branches.</p> <p></p> <p>You can now use this new branch to create changes you are not yet ready to put in your main branch.</p> <p>Want to delete a branch?</p> <p>You can delete a branch from the branch web page by clicking on the  trash can icon. Beware! All the changes you've made on that branch will be deleted!</p> <p>Working on your machine?</p> <p>Once you create a branch online, you can change to the desired branch on your machine with <code>git switch &lt;branch&gt;</code>. Don't forget to push your changes first!</p> <p>Pull and Tab</p> <ul> <li>Don't forget to perform a <code>git pull</code>!</li> <li>Don't know your branches? Tab! When typing <code>git switch</code>, press tab to see the options of all the branches you've created.</li> </ul>"},{"location":"05_version_control/#pull-requests","title":"Pull Requests","text":"<p>Pull requests (PR) are proposed changes you can make on a repository. In this specific case, pull requests can be used to merge changes from a branch to another. Pull requests can also come from forks of your repository that another user or collaborator has made. </p> <p>Assuming you have made changes in your branch (added a file, for example), a pop up will notify you that a branch has pushed some changes. In case you want to merge the branch and the main repository, you can review and merge by clicking the Compare &amp; pull request button. However, you may want to wait until more changes are made.</p> <p></p> <p>Once you are ready to merge the changes onto your main branch, click on the  branch icon, and select New pull request from the branch you have just made changes. This will open a new page which will list all the changes made showing all files that have been modified, added, or deleted. When you're done reviewing your changes, click Create pull request.</p> <p></p> <p>Pay attention to the information on the PR page!</p> <p>The PR page will not only show you what changes you've made, but also where the changes are coming from (which branch), as well as reviewers, assigneers, labels and other information necessary when working on a big project. It will also show whether the changes are Able to be merged () or not ()! </p> <p>Upon createing the pull request, a new page will open which will test whether the changes can be merged automatically. Changes that are not able to be merged usually clash with other changes other collaborators have made - this will require your revision prior to merging the PR! After revision, select Merge pull request and Confirm merge.</p> <p></p> <p>Your main repository should now have the files created in your other branch and merged through the PR!</p> <p></p>"},{"location":"05_version_control/#self-assessment","title":"Self Assessment","text":"True or False: Using <code>Git</code> requires a GitHub account <p>False</p> <p><code>Git</code> is open source software.</p> <p>GitHub is a privately owned (Microsoft) company</p> <p>Other platforms like GitLab, GitBucket, and GNU Savannah all offer <code>Git</code> as a version control system service.</p> True or False: Using <code>Git</code> is easy <p>False</p> <p>Using <code>Git</code> can be frustrating to even the most experienced users</p> When you find a new repository on GitHub that you think can help your research, what are the first things you should do? <p>Look at the README.md</p> <p>Most GitHub repositories have a README.md file which explains what you're looking at.</p> <p>Look at the LICENSE</p> <p>Not all repositories are licensed the same way - be sure to check the LICENSE file to see whether the software is open source, or if it has specific requirements for reuse. </p>"},{"location":"06_reproducibility_I/","title":"Reproducibility I: Software Environments","text":"<p>Learning Objectives</p> <p>After this lesson, you should be able to:</p> <ul> <li>Understand the value of reproducible computing </li> <li>Know the challenges of reproducible computing</li> <li>Define a computing environment </li> <li>Share a software environment with a colleague</li> <li>Set up a software project with an environment</li> </ul> <p> </p>"},{"location":"06_reproducibility_I/#reproducible-scientific-computing","title":"Reproducible Scientific Computing","text":"<p>Defining Reproducibility</p> <p>\"Reproducing the result of a computation means running the same software on the same input data and obtaining the same results.\" Rougier et al. 2016</p> <p>\"Getting someone else's code to run on my computer\" - Anonymous</p> <p> </p> <p> Source: Peng, RD Reproducible Research in Computational Science Science (2011): 1226\u20131227 via Reproducible Science Curriculum</p> <p> </p>"},{"location":"06_reproducibility_I/#interactive-ie-point-and-click-computing","title":"Interactive (ie, point-and-click) Computing","text":"<p>Definition</p> <p>Manually navigating a mouse across a graphical user interface (GUI) and running commands by selecting from menu options.</p>"},{"location":"06_reproducibility_I/#advantages","title":"Advantages","text":"<ul> <li>Intuitive and easy to navigate a GUI and click buttons</li> </ul>"},{"location":"06_reproducibility_I/#limitations","title":"Limitations","text":"<ul> <li>It can be slow to sequence through hundreds of clicks to accomplish an analysis. </li> <li>Less reproducible - Cumbersome to write and follow a click-by-click tutorial </li> </ul>"},{"location":"06_reproducibility_I/#scripted-computing","title":"Scripted Computing","text":"<p>Definition</p> <p>Removing the GUI and instead instructing the computer to run a series of custom commands using a scripting/coding language. </p> <p>We are automating what used to take many manual clicks. </p> <p>We can write scripts to install software, clean data, run analyses, and generate figures.</p> <p></p>"},{"location":"06_reproducibility_I/#advantages_1","title":"Advantages","text":"<ul> <li>Much faster to run through commands</li> <li>The script runs identically every time, reducing the human element </li> <li>Easy for someone else to quickly reproduce the exact analysis and result</li> <li>Enables analysis tasks to scale up </li> </ul>"},{"location":"06_reproducibility_I/#challenges","title":"Challenges","text":"<ul> <li>Requires deeper computer knowledge</li> <li>More upfront effort to produce the script</li> </ul> <p>Discussion Question</p> <p>What are some tasks you have automated or want to automate?</p> <ul> <li>Have you ever successfully automated a task?</li> <li>Found a way to make something scale or take less time? </li> <li>What was the task, and how did you do it? </li> <li>Are there any things you wish you could automate?</li> <li>What are some barriers to automating them?</li> </ul> <p> </p>"},{"location":"06_reproducibility_I/#scripting-languages","title":"Scripting Languages","text":"<p>The most common open-source scripting languages (for science) are Python, R, and shell (Bash). </p> <p>If you recall from lesson 4 How to Talk to Computers, we ran a shell script to back up and compress files. The following admonitions show the original shell script as well as the same instructions in Python and R. Scripting languages are simply different ways to instruct a computer. </p> Shell Script <pre><code>#use Bash shell to run the following commands\n#!/bin/bash\n\n## Variables\n#the directory you want to back up (e.g., shell-lesson-data)\nSOURCE_DIR=$(find / -type d -name \"shell-lesson-data\" 2&gt;/dev/null) # Note: if you are working on your computer, this will look in every folder. Be careful with this line!\n\n#location where the backup will be stored\nBACKUP_DIR=\"$HOME/Backup\"\n\n#used to create a unique name for each backup based on the current date and time\nTIMESTAMP=$(date +\"%Y-%m-%d_%H-%M-%S\")\n\n# name of the compressed backup file\nARCHIVE_NAME=\"backup_$TIMESTAMP.tar.gz\"\n\n\n# Create backup directory if it doesn't exist\nmkdir -p \"$BACKUP_DIR\"\n\n# Create a compressed archive of the source directory\ntar -czf \"$BACKUP_DIR/$ARCHIVE_NAME\" -C \"$SOURCE_DIR\" .\n\n# Output the result\necho \"Backup of $SOURCE_DIR completed!\"\necho \"Archive created at $BACKUP_DIR/$ARCHIVE_NAME\"\n</code></pre> Python <pre><code>import os\nimport subprocess\nimport shutil\nfrom datetime import datetime\n\n# Variables\n# Find the source directory (e.g., shell-lesson-data)\ndef find_source_dir():\n    try:\n        # Run the 'find' command to locate the directory\n        result = subprocess.run(['find', '/', '-type', 'd', '-name', 'shell-lesson-data'], \n                                stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, text=True)\n        source_dir = result.stdout.strip()\n        return source_dir\n    except Exception as e:\n        print(f\"Error finding directory: {e}\")\n        return None\n\n# Set the backup directory to a folder called Backup in the home directory\nbackup_dir = os.path.join(os.path.expanduser(\"~\"), \"Backup\")\n\n# Create a unique timestamp for the backup\ntimestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n\n# Create the archive name with the timestamp\narchive_name = f\"backup_{timestamp}.tar.gz\"\n\n# Ensure backup directory exists\nos.makedirs(backup_dir, exist_ok=True)\n\n# Find source directory\nsource_dir = find_source_dir()\n\nif source_dir:\n    # Create the compressed archive using tar\n    archive_path = os.path.join(backup_dir, archive_name)\n    try:\n        subprocess.run(['tar', '-czf', archive_path, '-C', source_dir, '.'], check=True)\n        print(f\"Backup of {source_dir} completed!\")\n        print(f\"Archive created at {archive_path}\")\n    except subprocess.CalledProcessError as e:\n        print(f\"Error creating archive: {e}\")\nelse:\n    print(\"Source directory not found!\")\n</code></pre> R <pre><code># Load necessary libraries\nlibrary(lubridate)\n\n# Variables\n# Function to find the source directory (e.g., shell-lesson-data)\nfind_source_dir &lt;- function() {\nresult &lt;- system(\"find / -type d -name 'shell-lesson-data' 2&gt;/dev/null\", intern = TRUE)\nif (length(result) &gt; 0) {\n    return(result[1])  # Return the first match, if any\n} else {\n    return(NULL)\n}\n}\n\n# Backup directory\nbackup_dir &lt;- file.path(Sys.getenv(\"HOME\"), \"Backup\")\n\n# Create a unique timestamp for the backup\ntimestamp &lt;- format(now(), \"%Y-%m-%d_%H-%M-%S\")\n\n# Name of the compressed archive\narchive_name &lt;- paste0(\"backup_\", timestamp, \".tar.gz\")\n\n# Ensure backup directory exists\nif (!dir.exists(backup_dir)) {\ndir.create(backup_dir, recursive = TRUE)\n}\n\n# Find the source directory\nsource_dir &lt;- find_source_dir()\n\nif (!is.null(source_dir)) {\n# Create the compressed archive using tar\narchive_path &lt;- file.path(backup_dir, archive_name)\ntar_command &lt;- paste(\"tar -czf\", shQuote(archive_path), \"-C\", shQuote(source_dir), \".\")\n\n# Run the tar command\nsystem(tar_command)\n\ncat(\"Backup of\", source_dir, \"completed!\\n\")\ncat(\"Archive created at\", archive_path, \"\\n\")\n} else {\ncat(\"Source directory not found!\\n\")\n}\n</code></pre> <p>Each language consist of base software (Python Standard Library or R Base Package) and MANY additional packages that can be downloaded and installed for increased capabilities. </p> <p> </p>"},{"location":"06_reproducibility_I/#computing-environment","title":"Computing Environment","text":"<p>A computing environment is the combination of hardware, software, and network resources that provide the infrastructure for computing operations and user interactions. </p> <ul> <li>Hardware: CPUs, GPUs, RAM</li> <li>Operating system &amp; version: many flavors of Linux, MacOS, Windows</li> <li>Software versions: R, Python, etc.</li> <li>Package versions: specific R or Python packages, which often depend on other packages</li> </ul> <p> Python Package Dependency</p> <p> </p> <p>!!Very Important!!</p> <p></p>"},{"location":"06_reproducibility_I/#the-scripts-you-create","title":"The scripts you create:","text":"<ul> <li>Were designed to work in your specific computing environment </li> <li>May not work on someone else's computer because their computing environment is different</li> <li>May not work on your computer in the future, because your computing enviroment will probably change (eg., updated software versions)</li> </ul>"},{"location":"06_reproducibility_I/#software-dependency-hell","title":"Software Dependency Hell","text":"<p>Sometimes, it can be nearly impossible to get your computing environment correct enough to run someone else's code. </p> <p>This can be caused by incorrect software versions of the packages you are using or their dependencies.</p> <p>Don't Dispair! There are solutions to avoid software dependency hell and ensure reproducibility from one computer to another</p> <p> </p>"},{"location":"06_reproducibility_I/#software-installation","title":"Software Installation","text":"<p>When you download and install software onto your computer, it will typically install it in a set of specific directories that we call the System Path.</p>"},{"location":"06_reproducibility_I/#system-path","title":"System Path","text":"<p>In the context of computing, the system path, often referred to simply as PATH, is the set of directories in which the operating system looks for executable files when a command is issued. </p> <p>When you go to launch an application by clicking on a desktop icon or with a CLI command, the computer will search for the application within the PATH directories. If it finds the executable, it will launch. </p> <p>Find the PATH on your computer</p> <p>In Linux and Mac Terminal</p> <p><code>echo $PATH</code></p> <p></p> <p>In Windows Terminal</p> <p><code>$env:PATH</code></p> <p> </p> Nice and Short Video Describing the PATH. <p> </p> <p>The PATH prefers one version of any given software.</p> <p> </p>"},{"location":"06_reproducibility_I/#environment-managers","title":"Environment Managers","text":"<p>One solution to software dependency hell is to use an Environment Manager</p> <p>An environment manager allows you to create software installation directories (similar to PATH) that are isolated from your computer's PATH. You can create unique environments and install specific software version to run specific scripts.</p> <p></p>"},{"location":"06_reproducibility_I/#conda-open-source-environment-manager","title":"Conda - Open Source Environment Manager","text":"<p>Conda is a popular and open source environment manager tool that can be installed on any operating system (Windows, MacOS, Linux).</p> <ul> <li>Users can create environments that have their own set of packages, dependencies, and even their own version of Python.</li> <li>Projects can have their own specific requirements without interfering with each other</li> <li>It allows for consistent and reproducible results across different systems and setups</li> </ul> <p> Conceptual Graphic 1</p> <p> Conceptual Graphic 2</p>"},{"location":"06_reproducibility_I/#renv","title":"Renv","text":"<ul> <li>R package that allows you to create unique environments for an R project</li> </ul>"},{"location":"06_reproducibility_I/#sharing-your-environment-with-colleagues","title":"Sharing your Environment with Colleagues","text":"<p>Whether you are using Conda, Pip, or Renv, you should be able to share the specifications of your software environment so colleagues can reproduce the environment.</p> <p>The general sharing workflow:</p> <ol> <li> <p>Output an environment file that lists the software and versions of the environment</p> </li> <li> <p>Share the file with colleagues through a platform like Github</p> </li> <li> <p>Colleagues create an empty environment on their computer and populate it with the contents of the environment file</p> </li> </ol>  Conda to Share Environment  Pip to Share Environment  Renv to Share Environment <p> </p>"},{"location":"06_reproducibility_I/#conda","title":"Conda","text":"<ol> <li> <p>Export your Conda Environment <pre><code>conda env export &gt; my_conda_env.yml\n</code></pre></p> </li> <li> <p>Share the .yml file through Github </p> </li> <li> <p>Reproduce the Environment on a Different Computer <pre><code>conda env create --file environment.yml\n</code></pre></p> </li> </ol> <p>Conda exports your Pip environment as well</p> <p>Exporting your environment using Conda (<code>conda env export &gt; my_conda_env.yml</code>) will ALSO export your pip environment!</p>"},{"location":"06_reproducibility_I/#python","title":"Python","text":"<ol> <li> <p>Export python libraries present in your environment <pre><code>pip3 freeze &gt; requirements.txt \n</code></pre></p> </li> <li> <p>Share the <code>requirements.txt</code> on Github</p> </li> <li> <p>Reproduce the Environment on a Different Computer <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> </ol>"},{"location":"06_reproducibility_I/#renv_1","title":"Renv","text":"<ol> <li> <p>Create an isolated environment <pre><code>renv::init()\n</code></pre></p> </li> <li> <p>Export R packages to the renv.lock file <pre><code>renv:snapshot()\n</code></pre></p> </li> <li> <p>Share the <code>renv.lock</code>, <code>.Rprofile</code>, <code>renv/settings.json</code> and <code>renv/activate.R</code> files to Github</p> </li> <li> <p>Reproduce the Environment on a Different Computer <pre><code>renv::restore()\n</code></pre></p> </li> </ol>"},{"location":"06_reproducibility_I/#package-managers","title":"Package Managers","text":"<p>A software tool to find, download, and install software packages to PATH or virtual environment </p>  Conda  Pip  R <p> </p>"},{"location":"06_reproducibility_I/#conda_1","title":"Conda","text":"<p>Software: Python, R, Django, Celery, PostgreSQL, nginx, Node.js, Java programs, C and C++, Perl, and command line tools</p> <p>Repository: Conda-Forge. </p>"},{"location":"06_reproducibility_I/#pip","title":"Pip","text":"<p>Software: python </p> <p>Repository: PyPi</p> <p>Note: Pip can be used together with Conda environment manager. </p>"},{"location":"06_reproducibility_I/#r","title":"R","text":"<p>With the R language, a package manager is built directly into the R Base Package.  <pre><code>install.packages('ggplot2')\n</code></pre></p> <p>Repository: R Comprehensive R Archive Network (CRAN)</p>"},{"location":"06_reproducibility_I/#reproducibility-tutorial-using-conda","title":"Reproducibility Tutorial Using Conda","text":""},{"location":"06_reproducibility_I/#set-up","title":"Set Up","text":"<p>OS of choice</p> <p>To get everyone on the same page, we will do this exercise together using the Linux terminal in Github Codespaces. </p> <p>However, if you'd like to use your own computer feel free to! If you're on Mac or Linux, open your terminal; If you're on Windows, please use the Windows Subsystem for Linux (WSL) so you can follow along. </p> How to Scroll in Cyverse (Tmux) Cloud Shell <p>If you're using the Cyverse Cloud Shell, you can scroll up and down by pressing <code>Ctrl + b</code> and then <code>[</code> to enter scroll mode. You can then use the arrow keys to scroll up and down. Press <code>q</code> to exit scroll mode.</p> <p>The CLI in CyVerse is controlled with Tmux, a software that allows to \"window\" the CLI; Here is a cheat sheet that will teach you more Tmux tricks!</p> <p></p>"},{"location":"06_reproducibility_I/#launch-github-codespaces","title":"Launch Github Codespaces","text":"<p>1 Go to this Github repository and Fork it (i.e., make a copy of it in your Github account).</p> <p> </p> <p>2 Click on the green \"Code\" button and select \"Create Codespaces on main\"</p> <p> </p> <p>3 After a few moments, you will be taken to a new browser window with a Linux terminal.</p> <p> </p> <p></p>"},{"location":"06_reproducibility_I/#installing-conda","title":"Installing Conda","text":"<p>If you are using Codespaces, Conda is already installed.</p> <p>When you download and install Conda it comes in two different flavors: </p> <p>Miniconda - lightweight (500 mb) program that includes Conda, the environment and package manager, as well as a recent version of the Standard Python Library. </p> <p>Anaconda - a larger (2.5GB) program that includes Conda and many more python libraries pre-installed (in Conda base environment), as well as graphical user interface, acccess to jupyter notebooks, and support for easily integrating the R language.</p> <p>  Conda, Miniconda, and Anaconda.  Taken from Getting Started with Conda, Medium. </p> Installing Conda <p>For the appropriate installation package, visit https://docs.conda.io/en/latest/miniconda.html.  Note: If you are using the WSL, install the Linux version!!</p> <pre><code># Download conda and add right permissions\nwget https://repo.anaconda.com/miniconda/Miniconda3-py39_4.12.0-Linux-x86_64.sh     # Modify this to match the OS you're using.\nchmod +x Miniconda3-py39_4.12.0-Linux-x86_64.sh\n\n# install conda silenty (-b) and update (-u) and initial conda run\n./Miniconda3-py39_4.12.0-Linux-x86_64.sh -b -u\n~/miniconda3/bin/conda init\n\n# Restart bash so that conda is activated\nsource ~/.bashrc\n</code></pre> <p>You'll be able to tell when conda is active when next <code>(base)</code> is present next to the to the shell prompt such as</p> <pre><code>(base) user@machine\n</code></pre> <p>Conda should now be installed and can be used to install other necessary packages! </p> Tip: slow Conda? Try Mamba. <p>Conda is known to take time processing some software installation. A solution is to use Mamba, a reimplementation of Conda in C++ for quicker queries and installations. Mamba is then invoked by using <code>mamba</code> instead of <code>conda</code> (whilst keeping options and the rest of the command synthax the same). </p> <p>The quickest way to install mamba is with <code>conda install -c conda-forge mamba</code>, or follow the official installation documentation here. </p> <p> </p>"},{"location":"06_reproducibility_I/#environment-management-with-conda","title":"Environment Management with Conda","text":"<p>When you start a Codespaces terminal, the prompt will look something like this: </p> <p><pre><code>@jeffgillan \u279c /workspaces/foss_conda_lesson (main) $\n</code></pre> </p> <p>Type the following command to see the current conda environment. </p> <p><pre><code>conda info\n</code></pre> </p> <p>Initialize conda by running the following commands. </p> <p><pre><code>conda init\nexec $SHELL\n</code></pre> </p> <p>View the list of conda environments. There should only be one environment called <code>base</code>. <pre><code>conda env list\n</code></pre> </p> <p>View the software installed in the base directory. Notice the version of Python. <pre><code>conda list\n</code></pre> </p> <p>Create our own custom environment (type <code>y</code> when prompted).</p> <pre><code>conda create --name myenv\n</code></pre> <p> </p> <p>Activate your new environment with </p> <p><pre><code>conda activate myenv\n</code></pre>  You will notice that the prompt changed to <code>(myenv)</code></p> <p></p> <p>View the software that is installed in your new custom environment. It should be empty!</p> <pre><code>conda list\n</code></pre> <p> </p>"},{"location":"06_reproducibility_I/#package-management-with-conda","title":"Package management with Conda","text":"<p>Within your new custom environment (ie, myenv) download and install a specific version of python. This may take a few minutes to complete. </p> <pre><code>conda install python=3.9\n</code></pre> <p></p> <p>View the new software that has been installed. Notice the version of Python is now 3.9. while the base is 3.12 <pre><code>conda list\n</code></pre></p> <p> </p> <p>Install Salmon (genomics software) using Conda</p> <pre><code>conda install -c bioconda salmon \n</code></pre> <p></p> <p>Conda channels</p> <p>Conda operates through channels, specififc repositories where packages are stored. Specific packages sometimes may appear in multiple channels, however it is always helpful to specify a channel with the <code>-c</code> flag.</p> <p> </p>"},{"location":"06_reproducibility_I/#share-and-reproduce-a-conda-environment","title":"Share and Reproduce a Conda Environment","text":"<p>Export all of the software in your custom environment to a file</p> <p><pre><code>conda env export --no-builds &gt; myenv.yml\n</code></pre>  Let's view the contents of the .yml file. It should contain all the software you installed in the environment. This <code>myenv.yml</code> file can be shared with a colleague so they can reproduce the same environment on their computer. <pre><code>nano myenv.yml\n</code></pre> </p> <p>Reproduce someone else's environment with <code>mandelbrot.yml</code> environment file located in the repository.</p> <pre><code>conda env create --file mandelbrot.yml\n</code></pre> <p></p> <p>Activate the environment to use the software installed in the environment. </p> <pre><code>conda activate mandelbrot\n</code></pre> <p></p> <p>Look at the software installed in the environment. </p> <pre><code>conda list\n</code></pre> <p></p> <p>Run a python script that generates a Mandelbrot set </p> <pre><code>python3 mandelbrot.py\n</code></pre> <p></p>"},{"location":"07_reproducibility_II/","title":"Reproducibility II: Run Containers","text":"<p>Learning Objectives</p> <p>After this lesson, you should be able to:</p> <ul> <li>Explain what containers are used for in reproducible research contexts</li> <li>Search for and run a Docker container locally or on a remote system</li> <li>Understand how version control and data can be used inside a container</li> </ul>"},{"location":"07_reproducibility_II/#reproducible-computer-code","title":"Reproducible Computer Code","text":"<p>Sharing your scientific analysis code with your colleagues is an essential pillar of Open Science that will help push your field forward. </p> <p>There are, however, technical challenges that may prevent your colleagues from effectively running your code on their computers. In the previous lesson Reproducibility I we described computing environments and how they can make it difficult to run code from one computer to another. </p> <p></p>"},{"location":"07_reproducibility_II/#solutions-for-sharing-computer-code","title":"Solutions for Sharing Computer Code","text":"<ol> <li> <p>Create a custom environment and share the recipe so your colleauges can replicate on their computer (as shown in Reproducibility I)</p> </li> <li> <p>Package up the code and all of the software and send it to your colleague as a Container </p> </li> </ol> <p></p>"},{"location":"07_reproducibility_II/#what-are-containers","title":"What are containers?","text":"<p>A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another </p> <ul> <li>Container images are a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings</li> <li>Each of these elements are specifically versioned and do not change</li> <li>The recipient does not need to install the software in the traditional sense</li> </ul> <p></p> <p>A useful analogy is to think of software containers as shipping containers. It allows us move cargo (software) around the world in standard way. The shipping container can be offloading and executed anywhere, as long the destination has a shipping port (i.e., Docker) </p> <p>  Software Shipping Containers </p> <p></p> <p>Containers are similar to virtual machines (VMs), but are smaller and easier to share. A big distinction between Containers and VMs is what is within each environment: VMs require the OS to be present within the image, whilst containers rely on the host OS and the container engine (e.g., Docker Engine). </p> <p>  Difference between Virtual Machines and Containers. Containers are a lot more portable as these do not require an OS to be bundled with the software. Figure source: Microsoft Cloudblogs. </p> <p></p>"},{"location":"07_reproducibility_II/#containers-for-reproducible-science","title":"Containers for Reproducible Science","text":"<p>Software containers, such as those managed by Docker or Singularity, are incredibly useful for reproducible science for several reasons:</p>"},{"location":"07_reproducibility_II/#environment-consistency","title":"Environment Consistency:","text":"<p>Containers encapsulate the software environment, ensuring that the same versions of software, libraries, and dependencies are used every time, reducing the \"it works on my machine\" problem.</p> <ul> <li>Ease of Sharing:</li> <li>Containers can be easily shared with other researchers, allowing them to replicate the exact software environment used in a study.</li> <li>Platform Independence:</li> <li>Containers can run on different operating systems and cloud platforms, allowing for consistency across different hardware and infrastructure.</li> <li>Version Control:</li> <li>Containers can be versioned, making it easy to keep track of changes in the software environment over time.</li> <li>Scalability:</li> <li>Containers can be easily scaled and deployed on cloud infrastructure, allowing for reproducible science at scale.</li> <li>Isolation:</li> <li>Containers isolate the software environment from the host system, reducing the risk of conflicts with other software and ensuring a clean and controlled environment.</li> </ul> <p> </p> <p>  The container's life cycle. Figure source: Tutorialspoint. </p> <p>The most common container software is  Docker, which is a platform for developers and sysadmins to develop, deploy, and run applications with containers. Apptainer (formerly, Singularity), is another popular container engine, which allows you to deploy containers on HPC clusters.</p> <p>DockerHub is the world's largest respository of container images. Think of it as the 'Github' of container images. It facilitates collaboration amongst developers and allows you to share your container images with the world. Dockerhub allows users to maintain different versions of container images.</p> <p>While Docker allows you to quickly run software from other people, it may not work across every platform.   There are different CPU architectures (<code>arm</code>, <code>amd64</code>, <code>x64</code>, <code>x86</code>) deployed across cloud, computer workstations, laptops, and cellular phones. Docker containers and their software can be cross-compiled across architectures, but this must be done by the creators.</p>"},{"location":"07_reproducibility_II/#introduction-to-docker","title":"Introduction to  Docker","text":""},{"location":"07_reproducibility_II/#prerequisites","title":"Prerequisites","text":"<p>In order to complete these exercises we STRONGLY recommend that you set up a personal  GitHub and  DockerHub account (account creation for both services is free). </p> <p>There are no specific skills needed for this tutorial beyond elementary command line ability and using a text editor. </p> <p>We are going to be using  GitHub CodeSpaces for the hands on portion of the workshop, which features  VS Code as a fully enabled development environment with Docker already installed. </p> <p>Our instructions on starting a new CodeSpace are here. </p> Installing Docker on your personal computer <p>We are going to be using virtual machines on the cloud for this course, and we will explain why this is a good thing, but there may be a time when you want to run Docker on your own computer.</p> <p>Installing Docker takes a little time but it is reasonably straight forward and it is a one-time setup.</p> <p>Installation instructions from Docker Official Docs for common OS and chip architectures:</p> <ul> <li> Mac OS X</li> <li> Windows</li> <li> Ubuntu Linux</li> </ul> Never used a terminal before? <p>Before venturing much further, you should review the Software Carpentry lessons on \"The Unix Shell\" and \"Version Control with Git\" -- these are great introductory lessons related to the skills we're teaching here.</p> <p>You've given up on ever using a terminal? No problem, Docker can be used from graphic interfaces, like Docker Desktop, or platforms like Portainer. We suggest you read through their documentation on how to use Docker.</p>"},{"location":"07_reproducibility_II/#fundamental-docker-commands","title":"Fundamental Docker Commands","text":"<p>Docker commands in the terminal use the prefix <code>docker</code>.</p> <p>For every command listed, the correct execution of the commands through the command line is by using <code>docker</code> in front of the command: for example <code>docker help</code> or <code>docker search</code>. Thus, every  = <code>docker</code>.</p>"},{"location":"07_reproducibility_II/#help","title":"help","text":"<p>Like many other command line applications the most helpful flag is the <code>help</code> command which can be used with the Management Commands:</p> <pre><code>$ docker \n$ docker --help\n</code></pre>"},{"location":"07_reproducibility_II/#search","title":"search","text":"<p>We talk about the concept of Docker Registries in the next section, but you can search the public list of registeries by using the <code>docker search</code> command to find public containers on the Official Docker Hub Registry:</p> <pre><code>$ docker search  \n</code></pre>"},{"location":"07_reproducibility_II/#pull","title":"pull","text":"<p>Go to the Docker Hub and type <code>hello-world</code> in the search bar at the top of the page. </p> <p>Click on the 'tag' tab to see all the available 'hello-world' images. </p> <p>Click the 'copy' icon at the right to copy the <code>docker pull</code> command, or type it into your terminal:</p> <pre><code>$ docker pull hello-world\n</code></pre> <p>Note</p> <p>If you leave off the <code>:</code> and the tag name, it will by default pull the <code>latest</code> image</p> <pre><code>$ docker pull hello-world\nUsing default tag: latest\nlatest: Pulling from library/hello-world\n2db29710123e: Pull complete \nDigest: sha256:bfea6278a0a267fad2634554f4f0c6f31981eea41c553fdf5a83e95a41d40c38\nStatus: Downloaded newer image for hello-world:latest\ndocker.io/library/hello-world:latest\n</code></pre> <p>Now try to list the files in your current working directory:</p> <pre><code>$ ls -l\n</code></pre> Where is the image you just pulled? <p>Docker saves container images to the Docker directory (where Docker is installed). </p> <p>You won't ever see them in your working directory.</p> <p>Use 'docker images' to see all the images on your computer:</p> <pre><code>$ docker images\n</code></pre>"},{"location":"07_reproducibility_II/#run","title":"run","text":"<p>The single most common command that you'll use with Docker is <code>docker run</code> (see official help manual for more details).</p> <pre><code>$ docker run hello-world:latest\n</code></pre> <p>In the demo above, you used the <code>docker pull</code> command to download the <code>hello-world:latest</code> image.</p> <p>What about if you run a container that you haven't downloaded?</p> <pre><code>$ docker run alpine:latest\n</code></pre> <p>When you executed the command <code>docker run alpine:latest</code>, Docker first looked for the cached image locally, but did not find it, it then ran a <code>docker pull</code> behind the scenes to download the <code>alpine:latest</code> image and then execute your command.</p>"},{"location":"07_reproducibility_II/#images","title":"images","text":"<p>You can now use the <code>docker images</code> command to see a list of all the cached images on your system:</p> <pre><code>$ docker images \nREPOSITORY              TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\nalpine                  latest              c51f86c28340        4 weeks ago         1.109 MB\nhello-world             latest              690ed74de00f        5 months ago        960 B\n</code></pre> Inspecting your containers <p>To find out more about a Docker images, run <code>docker inspect hello-world:latest</code></p>"},{"location":"07_reproducibility_II/#ps","title":"ps","text":"<p>Now it's time to see the <code>docker ps</code> command which shows you all containers that are currently running on your machine. </p> <pre><code>docker ps\n</code></pre> <p>Since no containers are running, you see a blank line.</p> <pre><code>$ docker ps\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n</code></pre> <p>Let's try a more useful variant: <code>docker ps --all</code></p> <pre><code>$ docker ps --all\nCONTAINER ID   IMAGE                                            COMMAND                  CREATED          STATUS                      PORTS     NAMES\na5eab9243a15   hello-world                                      \"/hello\"                 5 seconds ago    Exited (0) 3 seconds ago              loving_mcnulty\n3bb4e26d2e0c   alpine:latest                                    \"/bin/sh\"                17 seconds ago   Exited (0) 16 seconds ago             objective_meninsky\n192ffdf0cbae   opensearchproject/opensearch-dashboards:latest   \"./opensearch-dashbo\u2026\"   3 days ago       Exited (0) 3 days ago                 opensearch-dashboards\na10d47d3b6de   opensearchproject/opensearch:latest              \"./opensearch-docker\u2026\"   3 days ago       Exited (0) 3 days ago                 opensearch-node1\n</code></pre> <p>What you see above is a list of all containers that you have run. </p> <p>Notice that the <code>STATUS</code> column shows the current condition of the container: running, or as shown in the example, when the container was exited.</p>"},{"location":"07_reproducibility_II/#stop","title":"stop","text":"<p>The <code>stop</code> command is used for containers that are actively running, either as a foreground process or as a detached background one.</p> <p>You can find a running container using the <code>docker ps</code> command.</p>"},{"location":"07_reproducibility_II/#rm","title":"rm","text":"<p>You can remove individual stopped containers by using the <code>rm</code> command. Use the <code>ps</code> command to see all your stopped contiainers:</p> <pre><code>@user \u279c /workspaces $ docker ps -a\nCONTAINER ID   IMAGE                        COMMAND                  CREATED              STATUS                          PORTS     NAMES\n03542eaac9dc   hello-world                  \"/hello\"                 About a minute ago   Exited (0) About a minute ago             unruffled_nobel\n</code></pre> <p>Use the first few unique alphanumerics in the CONTAINER ID to remove the stopped container:</p> <pre><code>@user \u279c /workspaces (mkdocs \u2717) $ docker rm 0354\n0354\n</code></pre> <p>Check to see that the container is gone using <code>ps -a</code> a second time (<code>-a</code> is shorthand for <code>--all</code>; the full command is <code>docker ps -a</code> or <code>docker ps --all</code>).</p>"},{"location":"07_reproducibility_II/#rmi","title":"rmi","text":"<p>The <code>rmi</code> command is similar to <code>rm</code> but it will remove the cached images. Used in combination with <code>docker images</code> or <code>docker system df</code> you can clean up a full cache</p> <pre><code>docker rmi\n</code></pre> <pre><code>@user \u279c /workspaces/ (mkdocs \u2717) $ docker images\nREPOSITORY                   TAG       IMAGE ID       CREATED        SIZE\nopendronemap/webodm_webapp   latest    e075d13aaf35   21 hours ago   1.62GB\nredis                        latest    a10f849e1540   5 days ago     117MB\nopendronemap/nodeodm         latest    b4c50165f838   6 days ago     1.77GB\nhello-world                  latest    feb5d9fea6a5   7 months ago   13.3kB\nopendronemap/webodm_db       latest    e40c0f274bba   8 months ago   695MB\n@user \u279c /workspaces (mkdocs \u2717) $ docker rmi hello-world\nUntagged: hello-world:latest\nUntagged: hello-world@sha256:10d7d58d5ebd2a652f4d93fdd86da8f265f5318c6a73cc5b6a9798ff6d2b2e67\nDeleted: sha256:feb5d9fea6a5e9606aa995e879d862b825965ba48de054caab5ef356dc6b3412\nDeleted: sha256:e07ee1baac5fae6a26f30cabfe54a36d3402f96afda318fe0a96cec4ca393359\n@user \u279c /workspaces (mkdocs \u2717) $ \n</code></pre>"},{"location":"07_reproducibility_II/#system","title":"system","text":"<p>The <code>system</code> command can be used to view information about containers on your cache, you can view your total disk usage, view events or info.</p> <p>You can also use it to <code>prune</code> unused data and image layers.</p> <p>To remove all cached layers, images, and data you can use the <code>-af</code> flag for <code>all</code> and <code>force</code></p> <pre><code>docker system prune -af\n</code></pre>"},{"location":"07_reproducibility_II/#tag","title":"tag","text":"<p>By default an image will recieve the tag <code>latest</code> when it is not specified during the <code>docker build</code> </p> <p>Image names and tags can be created or changed using the <code>docker tag</code> command. </p> <pre><code>docker tag imagename:oldtag imagename:newtag\n</code></pre> <p>You can also change the registry name used in the tag:</p> <pre><code>docker tag docker.io/username/imagename:oldtag harbor.cyverse.org/project/imagename:newtag\n</code></pre> <p>The cached image laters will not change their <code>sha256</code> and both image tags will still be present after the new tag name is generated. </p>"},{"location":"07_reproducibility_II/#example-of-running-a-container","title":"Example of Running a Container","text":"<p>This is a tutorial to demonstrate how to run PDAL using Docker. PDAL is a stand-alone software package that can analyze and manipulate point cloud data files such as .las and .laz. In this tutorial, we will convert a LiDAR .laz file into a Cloud-optimized Point Cloud format (.copc.laz). </p> <p>1. Clone this repository to your local machine</p> <p><code>git clone https://github.com/jeffgillan/pdal_copc.git</code></p> <p>2. Change directories into the newly cloned repository</p> <p><code>cd pdal_copc</code></p> <p>3. Run the Container</p> <p><code>docker run -v $(pwd):/data jeffgillan/pdal_copc:1.0</code></p> <p>You are mounting a local volume (-v) directory to the container (<code>/data</code>). This local directory should have all of the point clouds files you want to convert. <code>$(pwd)</code> is telling it that the point clouds are in the current working directory. </p> <p><code>jeffgillan/pdal_copc:1.0</code> is the name of the container image you want to run. </p> <p><code>jeffgillan</code> = the Dockerhub account name</p> <p><code>pdal_copc</code> = the name of the image</p> <p><code>1.0</code> = the tag name    </p> <p>Your if everything worked correctly, you should have a new file <code>tree.copc.laz</code> in your present working directory.</p>"},{"location":"07_reproducibility_II/#working-with-interactive-containers","title":"Working with Interactive Containers","text":"<p>Let's go ahead and run some Integrated Development Environment images from \"trusted\" organizations on the Docker Hub Registry.</p>"},{"location":"07_reproducibility_II/#jupyter-lab","title":"Jupyter Lab","text":"<p>In this section, let's find a Docker image which can run a Jupyter Notebook</p> <p>Search for official images on Docker Hub which contain the string 'jupyter'</p> <pre><code>$ docker search jupyter\n</code></pre> <p>It should return something like:</p> <pre><code>NAME                                   DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\njupyter/datascience-notebook           Jupyter Notebook Data Science Stack from htt\u2026   912                  \njupyter/all-spark-notebook             Jupyter Notebook Python, Scala, R, Spark, Me\u2026   374                  \njupyter/scipy-notebook                 Jupyter Notebook Scientific Python Stack fro\u2026   337                  \njupyterhub/jupyterhub                  JupyterHub: multi-user Jupyter notebook serv\u2026   307                  [OK]\njupyter/tensorflow-notebook            Jupyter Notebook Scientific Python Stack w/ \u2026   298                  \njupyter/pyspark-notebook               Jupyter Notebook Python, Spark, Mesos Stack \u2026   224                  \njupyter/base-notebook                  Small base image for Jupyter Notebook stacks\u2026   168                  \njupyter/minimal-notebook               Minimal Jupyter Notebook Stack from https://\u2026   150                  \njupyter/r-notebook                     Jupyter Notebook R Stack from https://github\u2026   44                   \njupyterhub/singleuser                  single-user docker images for use with Jupyt\u2026   43                   [OK]\njupyter/nbviewer                       Jupyter Notebook Viewer                         27                   [OK]\n</code></pre> Untrusted community images <p>An important thing to note: None of these Jupyter or RStudio images are 'official' Docker images, meaning they could be trojans for spyware, malware, or other nasty warez.</p>"},{"location":"07_reproducibility_II/#understanding-ports","title":"Understanding PORTS","text":"<p>When we want to run a container that runs on the open internet, we need to add a TCP or UDP port number from which we can access the application in a browser using the machine's IP (Internet Protocol) address or DNS (Domain Name Service) location.</p> <p>To do this, we need to access the container over a separate port address on the machine we're working on.</p> <p>Docker uses the flag <code>--port</code> or <code>-p</code> for short followed by two sets of port numbers. </p> Exposing Ports <p>Docker can in fact expose all ports to a container using the capital <code>-P</code> flag</p> <p>For security purposes, it is generally NEVER a good idea to expose all ports.</p> <p>Typically these numbers can be the same, but in some cases your machine may already be running another program (or container) on that open port.</p> <p>The port has two sides <code>left:right</code> separated by a colon. The left side port number is the INTERNAL port that the container software thinks its using. The right side number is the EXTERNAL port that you can access on your computer (or virtual machine).</p> <p>Here are some examples to run basic RStudio and Jupyter Lab:</p> <pre><code>$ docker run --rm -p 8787:8787 -e PASSWORD=cc2022 rocker/rstudio\n</code></pre> <p>note: on CodeSpaces, the reverse proxy for the DNS requires you to turn off authentication</p> <pre><code>$ docker run --rm -p 8787:8787 -e DISABLE_AUTH=true rocker/rstudio\n</code></pre> <p><pre><code>$ docker run --rm -p 8888:8888 jupyter/base-notebook\n</code></pre> <pre><code>docker run --rm -p 8888:8888 jupyter/base-notebook start-notebook.sh --NotebookApp.token='' --NotebookApp.password=''\n</code></pre></p> Preempting stale containers from your cache <p>We've added the <code>--rm</code> flag, which means the container will automatically removed from the cache when the container is exited.</p> <p>When you start an IDE in a terminal, the terminal connection must stay active to keep the container alive.</p>"},{"location":"07_reproducibility_II/#detaching-your-container-while-it-is-running","title":"Detaching your container while it is running","text":"<p>If we want to keep our window in the foreground  we can use the <code>-d</code> - the detached flag will run the container as a background process, rather than in the foreground. </p> <p>When you run a container with this flag, it will start, run, telling you the container ID:</p> <p><pre><code>$ docker run --rm -d -p 8888:8888 jupyter/base-notebook\n</code></pre> Note, that your terminal is still active and you can use it to launch more containers. </p> <p>To view the running container, use the <code>docker ps</code> command.</p>"},{"location":"07_reproducibility_II/#interactive-commands-with-containers","title":"Interactive Commands with Containers","text":"<p>Lets try another command, this time to access the container as a shell:</p> <pre><code>$ docker run alpine:latest sh\n</code></pre> <p>Wait, nothing happened, right? </p> <p>Is that a bug? </p> <p>Well, no.</p> <p>The container will exit after running any scripted commands such as <code>sh</code>, unless they are run in an \"interactive\" terminal (TTY) - so for this example to not exit, you need to add the <code>-i</code> for interactive and <code>-t</code> for TTY. You can run them both in a single flag as <code>-it</code>, which is the more common way of adding the flag:</p> <pre><code>$ docker run -it alpine:latest sh\n</code></pre> <p>The prompt should change to something more like <code>/ #</code>.</p> <p>You are now running a shell inside the container! </p> <p>Try out a few commands like <code>ls -l</code>, <code>uname -a</code> and others.</p> <p>Exit out of the container by giving the <code>exit</code> command.</p> <pre><code>/ # exit\n</code></pre> Making sure you've exited the container <p>If you type <code>exit</code> your container will exit and is no longer active. To check that, try the following:</p> <pre><code>$ docker ps --latest\nCONTAINER ID        IMAGE                 COMMAND                  CREATED             STATUS                          PORTS                    NAMES\nde4bbc3eeaec        alpine                \"/bin/sh\"                3 minutes ago       Exited (0) About a minute ago                            pensive_leavitt\n</code></pre> <p>If you want to keep the container active, then you can use keys <code>ctrl +p</code> <code>ctrl +q</code>. To make sure that it is not exited run the same <code>docker ps --latest</code> command again:</p> <pre><code>$ docker ps --latest\nCONTAINER ID        IMAGE                 COMMAND                  CREATED             STATUS                         PORTS                    NAMES\n0db38ea51a48        alpine                \"sh\"                     3 minutes ago       Up 3 minutes                                            elastic_lewin\n</code></pre> <p>Now if you want to get back into that container, then you can type <code>docker attach &lt;container id&gt;</code>. This way you can save your container:</p> <pre><code>$ docker attach 0db38ea51a48\n</code></pre>"},{"location":"07_reproducibility_II/#house-keeping-and-cleaning-up-exited-containers","title":"House Keeping and  Cleaning Up Exited Containers","text":""},{"location":"07_reproducibility_II/#managing-docker-images","title":"Managing Docker Images","text":"<p>In the previous example, you pulled the <code>alpine</code> image from the registry and asked the Docker client to run a container based on that image. To see the list of images that are available locally on your system, run the <code>docker images</code> command.</p> <pre><code>$ docker images\nREPOSITORY                 TAG                 IMAGE ID            CREATED             SIZE\nubuntu                     bionic              47b19964fb50        4 weeks ago         88.1MB\nalpine                     latest              caf27325b298        4 weeks ago         5.53MB\nhello-world                latest              fce289e99eb9        2 months ago        1.84kB\n</code></pre> <p>Above is a list of images that I've pulled from the registry. You will have a different list of images on your machine. The TAG refers to a particular snapshot of the image and the ID is the corresponding unique identifier for that image.</p> <p>For simplicity, you can think of an image akin to a Git repository - images can be committed with changes and have multiple versions. When you do not provide a specific version number, the client defaults to latest.</p>"},{"location":"07_reproducibility_II/#clutter-and-cache","title":"Clutter and Cache","text":"<p>Docker images are cached on your machine in the location where Docker was installed. These image files are not visible in the same directory where you might have used <code>docker pull &lt;imagename&gt;</code>.</p> <p>Some Docker images can be large. Especially data science images with many scientific programming libraries and packages pre-installed.</p> <p>Pulling many images from the Docker Registries may fill up your hard disk! To inspect your system and disk use:</p> <pre><code>$ docker system info\n$ docker system df\n</code></pre> <p>To find out how many images are on your machine, type:</p> <pre><code>$ docker images\n</code></pre> <p>To remove images that you no longer need, type:</p> <pre><code>$ docker system prune\n</code></pre> <p>This is where it becomes important to differentiate between images, containers, and volumes (which we'll get to more in a bit).  You can take care of all of the dangling images and containers on your system. </p> <p>Note, that <code>prune</code> will not remove your cached images </p> <pre><code>$ docker system prune\n    WARNING! This will remove:\n    - all stopped containers\n    - all networks not used by at least one container\n    - all dangling images\n    - all dangling build cache\n\nAre you sure you want to continue? [y/N]\n</code></pre> <p>If you added the <code>-af</code> flag it will remove \"all\" <code>-a</code> dangling images, empty containers, AND ALL CACHED IMAGES with \"force\" <code>-f</code>.</p>"},{"location":"07_reproducibility_II/#managing-data-in-docker","title":"Managing Data in Docker","text":"<p>It is possible to store data within the writable layer of a container, but there are some limitations:</p> <ul> <li>The data doesn\u2019t persist when that container is no longer running, and it can be difficult to get the data out of the container if another process needs it.</li> <li>A container\u2019s writable layer is tightly coupled to the host machine where the container is running. You can\u2019t easily move the data somewhere else.</li> <li>Its better to put your data into the container AFTER it is built - this keeps the container size smaller and easier to move across networks.</li> </ul> <p>Docker offers three different ways to mount data into a container from the Docker host: Volumes, tmpfs mounts and bind mounts. Here, we will only be exploring Volumes.</p> <p>  The various methods for accessing data using containers. tmpfs mounts store data directly in memory, bind mounts and volumes use the host's file system. Volumes are flexible and only attach a specific directory to the container, whilst bind mounts require the user to share the full path to a file in order to allow the container to access it. Taken from the official Docker documentation on data management with docker. </p> <p>Why Volumes?</p> <p>Volumes are often a better choice than persisting data in a container\u2019s writable layer, because using a volume does not increase the size of containers using it, and the volume\u2019s contents exist outside the lifecycle of a given container. Some of the advantages of volumes include:</p> <ul> <li>Volumes are easier to back up or migrate.</li> <li>You can manage volumes using Docker CLI commands or the Docker API.</li> <li>Volumes work on both UNIX and Windows containers.</li> <li>Volumes can be more safely shared among multiple containers.</li> <li>A new volume\u2019s contents can be pre-populated by a container.</li> </ul> <p>The <code>-v</code> flag is used for mounting volumes:</p> <p><code>-v</code> or <code>--volume</code>: Consists of three fields, separated by colon characters (:). </p> <p>The fields must be in the correct order, and the meaning of each field is not immediately obvious.</p> <p>Required:</p> <ul> <li>The first field is the path on your local machine that where the data are.</li> <li>The second field is the path where the file or directory are mounted in the container.</li> </ul> <p>Optional:</p> <ul> <li>The third field is optional, and is a comma-separated list of options, such as <code>ro</code> (read only).</li> </ul> <p>The synthax looks like the following: <pre><code>-v /home/username/your_data_folder:/container_folder\n</code></pre></p> <p>This is what a full docker command with a mounted volume looks like: <pre><code>$ docker run -v /home/$USER/read_cleanup:/work alpine:latest ls -l /work\n</code></pre></p> <p>So what if we wanted to work interactively inside the container?</p> <pre><code>$ docker run -it -v /home/$USER/read_cleanup:/work alpine:latest sh\n</code></pre> <p>Once you're in the container, you will see that the <code>/work</code> directory is mounted in the working directory.</p> <p>Any data that you add to that folder outside the container will appear INSIDE the container. And any work you do inside the container saved in that folder will be saved OUTSIDE the container as well.</p>"},{"location":"07_reproducibility_II/#docker-commands","title":"Docker Commands","text":"<p>Here is a compiled list of fundamental Docker Commands:</p> Command Usage Example <code>pull</code> Downloads an image from Docker Hub <code>docker pull hello-world:latest</code> <code>run</code> runs a container with entrypoint <code>docker run -it user/image:tag</code> <code>build</code> Builds a docker image from a Dockerfile in current working directory <code>docker build -t user/image:tag .</code> <code>images</code> List all images on the local machine <code>docker images list</code> <code>tag</code> Adds a different tag name to an image <code>docker tag hello-world:latest hello-world:new-tag-name</code> <code>login</code> Authenticate to the Docker Hub (requires username and password) <code>docker login</code> <code>push</code> Upload your new image to the Docker Hub <code>docker push user/image:tag</code> <code>inspect</code> Provide detailed information on constructs controlled by Docker <code>docker inspect containerID</code> <code>ps</code> List all containers on your system <code>docker ps -a</code> <code>rm</code> Delete a stopped or running container <code>docker rm -f &lt;container ID&gt;</code> <code>rmi</code> Delete an image from your cache <code>docker rmi hello-world:latest</code> <code>stop</code> Stop a running container <code>docker stop alpine:latest</code> <code>system</code> View system details, remove old images and containers with <code>prune</code> <code>docker system prune</code> <code>push</code> Uploads an image to the Docker Hub (or other private registry) <code>docker push username/image:tag</code>"},{"location":"07_reproducibility_II/#self-assessment","title":"Self Assessment","text":"A Docker container with the tagname <code>latest</code> ensures old code and data will work on a new computer setup? <p>Answer</p> <p>Never use the <code>latest</code> tag for a publication or archival. </p> <p>The <code>latest</code> version is always being updated and should be considered \"cutting edge\".</p> <p><code>latest</code> is the default tag name of all Docker images</p> <p><code>latest</code> versions MAY have backward compatibility with older code and data, but this is not always a given</p> When are containers the right solution? <p>Success</p> <p>Containers are valuable when you need to run an analyses on a remote platform, and you need it to work every time.</p> <p>Failure</p> <p>You need to do some simple text file editing </p> <p>You need to run a web service</p> True or False: Docker containers allow for reproducibility across all computing platforms <p>False</p> <p>While Docker allows you to quickly run software from other people, it may not work across every platform.</p> <p>There are different CPU architectures (<code>arm</code>, <code>amd64</code>, <code>x64</code>, <code>x86</code>) deployed across cloud, computer workstations, laptops, and cellular phones. </p> <p>Docker containers and their software can be cross-compiled across architectures, but this must be done by the creators.</p> When is it advisable to not trust a Docker image? <p>When you cannot view its Dockerfile</p> <p>Featured and Verified Docker images can be trusted, in general.</p> <p>User generated images should not be trusted unless you can view their Dockerfile, or build logs to determine what is actually in the container you are attempting to run.</p>"},{"location":"07_reproducibility_II/#additional-resources","title":"Additional Resources","text":"<p>Deeper Exploration of Containers and how to create them can be found here</p> <p>The Carpentries have an incubator workshop on Docker Containers</p>"},{"location":"08_reproducibility_III/","title":"Reproducibility III: Building Docker Containers","text":"<p>Learning Objectives</p> <p>After this lesson, you should be able to:</p> <ul> <li>Understand the Dockerfile structure and fields </li> <li>Build, execute and push your own Docker image</li> </ul> <p>In Reproducibility II we saw how we can access and execute Docker containers. In this lesson, we continue to explore containerization, covering how we can create our own container and the various commands necessary in order to create them.</p> <p> </p>"},{"location":"08_reproducibility_III/#images-vs-containers","title":"Images vs Containers","text":"Image Container What A snapshot of an application  containing code, libraries, dependencides  and files needed for the application to run A runtime instance of the Docker image When Created through a Dockerfile Runtime executed after Image is created Why Reproducibility and consistency! Reproducibility and consistency! Where Stored in an online registry (e.g., Docker Hub) Executed on your machine"},{"location":"08_reproducibility_III/#general-workflow","title":"General Workflow","text":"<p>  The container's life cycle. Figure source: Tutorialspoint. </p> <p> </p>"},{"location":"08_reproducibility_III/#run-an-example-container","title":"Run an Example Container","text":"<p>The example container is located in the following Github repository https://github.com/jeffgillan/r-script-containerized. The docker container launches Rstudio where a user can run an R script to convert a point cloud to a canopy height model (CHM).</p> <p>  Rstudio running in a container</p> <p></p>"},{"location":"08_reproducibility_III/#1-launch-codespaces-from-the-r-script-containerized-repository","title":"1. Launch Codespaces from the <code>r-script-containerized</code> repository","text":"<p>  Launch CodeSpaces from the <code>r-script-containerized</code> repository </p> <p> </p>"},{"location":"08_reproducibility_III/#2-on-the-codespaces-terminal-run-the-following-command-to-run-the-docker-container","title":"2. On the codespaces terminal, run the following command to run the docker container:","text":"<pre><code>docker run --rm -ti -e DISABLE_AUTH=true -v $(pwd):/home/rstudio/data -p 8787:8787 jeffgillan/pointcloud_to_chm:amd64\n</code></pre> Dissecting the Docker Run Command <p>Within the command we are doing the following:</p> Flag/Option Explanation <code>--rm</code> Automatically remove the container when it exits <code>-ti</code> Allocate a pseudo-TTY (terminal) connected to the container\u2019s stdin. It gives you an interactive terminal session in the container, allowing you to run commands in the container just as you would in a regular terminal window. <code>-e DISABLE_AUTH=true</code> Disable authentication for the Rstudio server <code>-v $(pwd):/home/rstudio/data</code> Mount the current working directory to the <code>/home/rstudio/data directory</code> in the container. This allows us to access the data on our local machine (in this case Codespaces) from within the container. The directory is where you should have pointcloud <code>.laz</code> files. <code>-p 8787:8787</code> Expose port 8787 on the container to port 8787 on the host machine. This allows us to access the Rstudio server from our web browser. <code>jeffgillan/pointcloud_to_chm:amd64</code> The name and version number of the docker image we want to run. In this case, we are running the <code>pointcloud_to_chm</code> image from the <code>jeffgillan</code> repository in Docker Hub. <p> <code>docker run</code> command</p> <p> </p>"},{"location":"08_reproducibility_III/#3-view-rstudio-in-a-browser","title":"3. View Rstudio in a Browser","text":"<p>Open a new browser tab and navigate to <code>localhost:8787</code> to access the Rstudio server running in the container. In Codespaces you can click on Ports and then Open Browser to access the Rstudio server.</p> <p>  Rstudio running in a container</p> <p> </p>"},{"location":"08_reproducibility_III/#4-run-the-script","title":"4. Run the Script","text":"<p>Open the script <code>pointcloud_to_DTM.R</code></p> <p>Highlight all of the code and click Run</p> <p></p> <p> </p> <p>Upon completing the code, you should have a 2D plot of the tree</p> <p></p> <p>You should also have a new file called <code>chm.tif</code> in the mounted <code>data</code> folder. The <code>chm.tif</code> has been written to your local machine!</p> <p></p> <p> </p> <p></p>"},{"location":"08_reproducibility_III/#building-docker-images","title":"Building Docker Images","text":"<p>  Docker Images are just like cakes: both are made of layers! </p>"},{"location":"08_reproducibility_III/#writing-a-dockerfile","title":"Writing a Dockerfile","text":"<p>Create a file called <code>Dockerfile</code>, and add content to it as described below, e.g.</p> <pre><code>$ touch Dockerfile\n</code></pre> <p>Or, since we are using Codespaces, you can click the Create File button  and name it <code>Dockerfile</code></p> <p> </p> <p>What is a Dockerfile?</p> <p>A Dockerfile is a text file that contains a list of commands, known as instructions used by Docker to build an image. </p> <p>If a Docker Image is a cake, the Dockerfile is the recipe!</p> <pre><code># Tells the Dockerfile which image to start from\nFROM rocker/geospatial:4.2.3             \n\n# Sets the initial working directory inside the container                               \nWORKDIR /home/rstudio                   \n\n# Copies the R script file from your localdirectory to the container                                   \nCOPY pointcloud_to_DTM.R .              \n\n# Installs an R package                                  \nRUN R -e \"install.packages('RCSF', dependencies=TRUE, repos='http://cran.rstudio.com/')\"  \n\n#Declare the port Rstudio will run on                                        \nEXPOSE 8787\n\n# Starts the Rstudio server\nCMD [\"/init\"]      \n</code></pre> <p> </p>"},{"location":"08_reproducibility_III/#dockerfile-statements","title":"Dockerfile Statements","text":"ARG <p>The only command that can come before a <code>FROM</code> statement is <code>ARG</code></p> <p><code>ARG</code> can be used to set arguments for later in the build, e.g.,</p> <pre><code>ARG VERSION=latest\n\nFROM ubuntu:$VERSION\n</code></pre> FROM <p>A valid <code>Dockerfile</code> must start with a <code>FROM</code> statement which initializes a new build stage and sets the base image for subsequent layers.</p> <p>We\u2019ll start by specifying our base image, using the FROM statement</p> <pre><code>FROM ubuntu:latest\n</code></pre> <p>If you are building on an <code>arm64</code> or Windows system you can also give the optional <code>--platform</code> flag, e.g.,</p> <pre><code>FROM --platform=linux/amd64 ubuntu:latest\n</code></pre> When to use a multi-stage build pattern? <p>Docker has the ability to build container images from one image, and run that \"builder\" image from a second \"base\" image, in what is called a \"builder pattern\".</p> <p>Build patterns are useful if you're compiling code from (proprietary) source code and only want to feature the binary code as an executed function in the container at run time. </p> <p>Build patterns can greatly reduce the size of your container.</p> <p>You can use multiple <code>FROM</code> commands as build stages. The <code>AS</code> statement follows the <code>image:tag</code> as a psuedo argument. </p> <pre><code># build stage\nFROM golang:latest AS build-env\nWORKDIR /go/src/app\nADD . /go/src/app\nRUN go mod init\nRUN cd /go/src/app &amp;&amp; go build -o hello\n\n# final stage\nFROM alpine:latest\nWORKDIR /app\nCOPY --from=build-env /go/src/app /app/\nENTRYPOINT ./hello\n</code></pre> LABEL <p>You can create labels which are then tagged as  JSON metadata to the image</p> <pre><code>LABEL author=\"your-name\" \nLABEL email=\"your@email-address\"\nLABEL version=\"v1.0\"\nLABEL description=\"This is your first Dockerfile\"\nLABEL date_created=\"2022-05-13\"\n</code></pre> <p>You can also add labels to a container when it is run:</p> <pre><code>$ docker run --label description=\"this label came later\" ubuntu:latest\n\n$ docker ps -a\n\n$ docker inspect ###\n</code></pre> RUN <p>Different than the <code>docker run</code> command is the <code>RUN</code> build function. <code>RUN</code> is used to create new layers atop the \"base image\"</p> <p>Here, we are going to install some games and programs into our base image:</p> <pre><code>RUN apt-get update &amp;&amp; apt-get install -y fortune cowsay lolcat\n</code></pre> <p>Here we've installed <code>fortune</code> <code>cowsay</code> and <code>lolcat</code> as new programs into our base image.</p> <p>Best practices for building new layers</p> <p>Ever time you use the <code>RUN</code> command it is a good idea to use the <code>apt-get update</code> or <code>apt update</code> command to make sure your layer is up-to-date. This can become a problem though if you have a very large container with a large number of <code>RUN</code> layers. </p> ENV <p>In our new container, we need to change and update some of the environment flags. We can do this using the <code>ENV</code> command</p> <pre><code>ENV PATH=/usr/games:${PATH}\n\nENV LC_ALL=C\n</code></pre> <p>Here we are adding the <code>/usr/games</code> directory to the <code>PATH</code> so that when we run the new container it will find our newly installed game commands</p> <p>We are also updating the \"locales\" to set the language of the container.</p> COPY <p>The <code>COPY</code> command will copy files from the directory where <code>Dockerfile</code> is kept into the new image. You must specify where to copy the files or directories</p> <pre><code>COPY . /app\n</code></pre> When to use <code>COPY</code> vs <code>ADD</code> <p><code>COPY</code> is more basic and is good for files</p> <p><code>ADD</code> has some extra features like <code>.tar</code> extraction and URL support</p> CMD <p>The <code>CMD</code> command is used to run software in your image. In general use the [\"command\"] syntax:</p> <pre><code>CMD [\"executable\", \"parameter1\", \"parameter2\"]\n</code></pre> ENTRYPOINT <p>ENTRYPOINT works similarly to <code>CMD</code> but is designed to allow you to run your container as an executable.</p> <pre><code>ENTRYPOINT fortune | cowsay | lolcat\n</code></pre> <p>The default <code>ENTRYPOINT</code> of most images is <code>/bin/sh -c</code> which executes a <code>shell</code> command.</p> <p><code>ENTRYPOINT</code> supports both the <code>ENTRYPOINT [\"command\"]</code> syntax and the <code>ENTRYPOINT command</code> syntax</p> What is an entrypoint? <p>An entrypoint is the initial command(s) executed upon starting the Docker container. It is listed in the <code>Dockerfile</code> as <code>ENTRYPOINT</code> and can take 2 forms: as commands followed by parameters (<code>ENTRYPOINT command param1 param2</code>)  or as an executable (<code>ENTRYPOINT [\u201cexecutable\u201d, \u201cparam1\u201d, \u201cparam2\u201d]</code>)</p> What is the difference in the <code>ENTRYPOINT</code> and <code>CMD</code> <p>The CMD instruction is used to define what is execute when the container is run.</p> <p>The ENTRYPOINT instruction cannot be overridden, instead it is appended to when a new command is given to the <code>docker run container:tag new-cmd</code> statement </p> <p>the executable is defined with ENTRYPOINT, while CMD specifies the default parameter</p> USER <p>Most containers are run as <code>root</code> meaning that they have super-user privileges within themselves</p> <p>Typically, a new user is necessary in a container that is used interactively or may be run on a remote system.</p> <p>During the build of the container, you can create a new user with the <code>adduser</code> command and set up a <code>/home/</code> directory for them. This new user would have something like 1000:1000 <code>uid:gid</code> permissions without <code>sudo</code> privileges.</p> <p>As a last step, the container is run as the new <code>USER</code>, e.g., </p> <pre><code>ARG VERSION=18.04\n\nFROM ubuntu:$VERSION\n\nRUN useradd ubuntu &amp;&amp; \\\n    chown -R ubuntu:ubuntu /home/ubuntu\n\nUSER ubuntu\n</code></pre> EXPOSE <p>You can open ports using the <code>EXPOSE</code> command.</p> <pre><code>EXPOSE 8888\n</code></pre> <p>The above command will expose port 8888.</p> <p>Note</p> <p>Running multiple containers using the same port is not trivial and would require the usage of a web server such as NGINX. However, you can have multiple containers interact with each other using Docker Compose.</p> <p></p>"},{"location":"08_reproducibility_III/#summary-of-instructions","title":"Summary of Instructions","text":"Instruction Command Description <code>ARG</code> Sets environmental variables during image building <code>FROM</code> Instructs to use a specific Docker image <code>LABEL</code> Adds metadata to the image <code>RUN</code> Executes a specific command <code>ENV</code> Sets environmental variables <code>COPY</code> Copies a file from a specified location to the image <code>CMD</code> Sets a command to be executed when running a container <code>ENTRYPOINT</code> Configures and run a container as an executable <code>USER</code> Used to set User specific information <code>EXPOSE</code> exposes a specific port"},{"location":"08_reproducibility_III/#building-the-image","title":"Building the Image","text":"<p>Once the Dockerfile has been created, we can build the image using the <code>docker build</code> command. At the codespaces terminal, run the following command:</p> <pre><code>docker build -t &lt;dockerhub username&gt;/pointcloud_to_chm:amd64 .\n</code></pre> <p>Example:</p> <pre><code>docker build -t jeffgillan/pointcloud_to_chm:amd64 .\n</code></pre> Dissecting the Docker Build Command <ul> <li>The <code>-t</code> flag allows us to tag the image with a name and version number.  </li> <li>In the command you need to add your own DockerHub username instead of <code>&lt;dockerhub username&gt;</code>, which acts as the address to your own DockerHub Repository; <code>pointcloud_to_chm</code> is the name of the image, and <code>amd64</code> is the version tag.    </li> <li>The <code>.</code> at the end of the command tells docker to look in the current directory for the dockerfile.</li> </ul> <p> </p>"},{"location":"08_reproducibility_III/#executable-images","title":"Executable Images","text":"<pre><code> _____________________________\n&lt; Avoid reality at all costs. &gt;\n -----------------------------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n</code></pre> <p>Thus far we have worked using interactive containers such as RStudio. Not all containers are interactive, many (if not most of) are executables: containerized software that can take the raw input and output data without requiring further work from the user.</p> <p>Executable containers are usually called with </p> <pre><code>docker run &lt;repository&gt;/&lt;image&gt;:&lt;tag&gt; &lt;potential arguments/options&gt; &lt;input file/folder&gt;\n</code></pre> <p>An easy to reproduce example is Lolcow, which builds a small executable that outputs a \"quote of the day\". It does not require any input and will output to the terminal directly.</p> <p>You can run a prebuilt Lolcow with </p> <pre><code>docker run cosimichele/lolcow:f24\n</code></pre> <p>Here is the minimal recipie required to build Lolcow: </p> <pre><code>FROM --platform=linux/amd64 ubuntu:22.04\n\nRUN apt-get update &amp;&amp; apt-get install -y fortune cowsay lolcat\n\nENV PATH=/usr/games:${PATH}\n\nENV LC_ALL=C\n\nENTRYPOINT fortune | cowsay | lolcat\n</code></pre> <p>Once built, you can execute it with <code>docker &lt;image ID/name&gt;</code> for something to brighten your day!</p>"},{"location":"08_reproducibility_III/#pushing-to-a-registry-with-docker-push","title":"Pushing to a Registry with  docker push","text":"<p>By default <code>docker push</code> will upload your local container image to the Docker Hub.</p> <p>Also, make sure that your container has the appropriate tag.</p> <p>First, make sure to log into the Docker Hub, this will allow you to download private images, to upload private/public images:</p> <pre><code>docker login\n</code></pre> <p>Alternately, you can link GitHub / GitLab accounts to the Docker Hub.</p> <p>To push the image to the Docker Hub:</p> <pre><code>docker push username/imagename:tag \n</code></pre> <p> </p>"},{"location":"08_reproducibility_III/#exercises-and-additional-dockerfiles","title":"Exercises and Additional Dockerfiles","text":"<p>We have a number of pre-written Dockerfiles that you can access in our Intro 2 Docker Repository.</p> <p>It contains:</p> <ul> <li>Alpine: a minimal Linux distribution </li> <li>Cowsay: will output wise messages when executed</li> <li>Jupyter/minimal-notebook: Jupyter Notebook accessible from your browser</li> <li>rstudio/verse: RStudio containing the Tidyverse data science packages </li> <li>Ubuntu</li> </ul> <p>Clone our example repository, or work directly on the repository using Codespaces.</p> <p>Clone command:</p> <pre><code>$ cd /workspaces\n\n$ git clone https://github.com/cyverse-education/intro2docker\n\n$ cd intro2docker/\n</code></pre>"},{"location":"09_remote_computing_cyverse/","title":"Remote Computing with Cyverse","text":""},{"location":"09_remote_computing_cyverse/#get-off-your-own-machine","title":"Get off your own machine","text":"<p>More and more work is being done somewhere other than a personal computer. This could be an HPC cluster at a university or a cloud computing provider. \"Cloud\" just means somebody else is handling the computers, and you get to use them when you need to, typically for a price. Some 'cloud' options include: Binder, Colab, and Cyverse VICE and Github Codespace. </p> <p>The take home message on Cloud is that it is a great way to make your work more reproducible, as you can share a link to your work, and anyone can run it without having to install anything.</p>"},{"location":"10_reproducibility_IV/","title":"Remote Computing with High Performance Computer (HPC)","text":"<p>  Singularity &gt; Apptainer and working with the SLURM workload manager (HPC scheduler). </p> <p>Expected Outcomes</p> <ul> <li>Being able to log onto the HPC and start an interactive node</li> <li>Know basic HPC related commands</li> <li>Execute containerized code through Singularity/Apptainer</li> <li>Being able to search and load specific software</li> <li>Execute NextFlow scripts on the HPC</li> </ul> <p>Through FOSS and FOSS+ we have learned about container technology and how it can affect reproducibility by wrapping all the necessary components that allow a specific software to be executed. </p> <p>Similar to Docker, Singularity/Apptainer is a powerful tool that enables researchers to package entire environments, including software dependencies and libraries, into a single executable file.</p> <p>Unlike other containerization platforms, Singularity/Apptainer is designed with HPC in mind, allowing seamless integration with cluster computing environments.</p> <p>The biggest difference between Docker and Singularity/Apptainer, is that with the latter you do not require sudo priviledges. Exciting!</p> <p>In this workshop, we are going to learn how we can use Singularity/Apptainer on the UA HPC, covering orientation of the HPC, and executing Singularity/Apptainer control commands.</p>"},{"location":"10_reproducibility_IV/#a-10000ft-view-of-the-hpc","title":"A 10,000ft View of the HPC","text":"<p>Next week (Apr 04th) Chris Reidy from UITS is going to talk in more details regarding the hardware specifications of the UA HPC systems. </p> <p>Here, we are going to concentrate on HOW to operate the HPC system as a general user.</p> <p>Who is this lesson for?</p> <p>This workshop is  primarely aimed to UA students, grad students, faculty and staff as being part of the University of Arizona grants you access to the UA HPC. </p> <p>If you are not part of UA... you're still very welcome to take part of this lesson! You may not be able to execute the commands but you can still walk out of this with a good understanding of your institution's own HPC and Singularity/Apptainer. Everyone's welcome!</p>"},{"location":"10_reproducibility_IV/#logging-onto-the-hpc","title":"Logging onto the HPC","text":"<p>If you have a UA account, to connect to the HPC you need to use <code>ssh</code> (Secure Shell). Open a terminal, and type:</p> <pre><code>ssh &lt;UA username&gt;@hpc.arizona.edu\n</code></pre> <p>Type your UA password and if successful you'll be greeted with a two-factor login. Select which choice, and complete the authentification. Once you are past the authentification steps, you will enter the Bastion server. This step has 2 purposes: </p> <ol> <li>Protect from attacks.</li> <li>Select what HPC system you want to use.</li> </ol> <p>Note: the Bastion server is NOT YET the HPC! Here you cannot submit jobs or run analyes. Type <code>shell</code> in order to select what system you want to use.</p> <p>The whole process (from logging to selecting the system) looks like the following:</p> <pre><code>ssh cosi@hpc.arizona.edu\n(cosi@hpc.arizona.edu) Password: \n(cosi@hpc.arizona.edu) Duo two-factor login for cosi\n\nEnter a passcode or select one of the following options:\n\n 1. Duo Push to XXX-XXX-8418\n 2. SMS passcodes to XXX-XXX-8418\n\nPasscode or option (1-2): 1\nSuccess. Logging you in...\nLast login: Tue Mar 26 14:52:39 2024 from dhcp-10-132-212-1.uawifi.arizona.edu\nThis is a bastion host used to access the rest of the RT/HPC environment.\n\nType \"shell\" to access the job submission hosts for all environments\n-----------------------------------------\n\n[cosi@gatekeeper ~]$ shell\nLast login: Wed Mar 20 10:30:25 2024 from gatekeeper.hpc.arizona.edu\n***\nThe default cluster for job submission is Puma\n***\nShortcut commands change the target cluster\n-----------------------------------------\nPuma:\n$ puma\n(puma) $\nOcelote:\n$ ocelote\n(ocelote) $\nElGato:\n$ elgato\n(elgato) $\n-----------------------------------------\n\n[cosi@wentletrap ~]$ ocelote\n(ocelote) [cosi@wentletrap ~]$\n</code></pre> <p>At this point you are in the Login Node, where you can submit jobs or ask for an interactive node.</p> <p>  A representation of what the HPC structure and its various nodes. Source. </p>"},{"location":"10_reproducibility_IV/#choosing-a-system","title":"Choosing a System","text":"<p>In the example above, we chose the Ocelote system. Notice how there are 2 other choices: Puma and El Gato. Without going in  too much detail, here are some of the statistics regarding the 3 HPC systems at the UA HPC.</p> System Year of Aquisition Processors RAM GPU Puma 2020 2x AMD Zen2 48 CPU (94 cores total) 512GB 6x Nvidia V100S Ocelote 2016 2x Xeon E5-2695v3 14-core (28 cores total) 192GB 46x Nvidia P100 El Gato 2013 2x Xeon E5-2650v2 8-core (16 core total) 64GB removed as obsolete <p>Find the full systems specs at the official UA HPC documentatio resources page.</p> <p>El Gato is the oldest system, and potentially not useful for heavy research. Puma is the newest and most requested, whislt Ocelote is the \"middle child\": not as popular but still able to pack a punch. </p> <p>Depending on what your work is, your best bet would be Puma for heavy computation (if you are ok with waiting long queues); However, if your jobs aren't as taxing, then Ocelote could easily be a safe choice.</p> <p>For this workshop, we are going to be using Ocelote.</p>"},{"location":"10_reproducibility_IV/#checking-available-resources","title":"Checking Available Resources","text":""},{"location":"10_reproducibility_IV/#allocations","title":"Allocations","text":"<p>Once past the Bastion server and logged into the Ocelote login node, you are able to submit jobs or request an interactive node. Before you do so, it is wise to check your available resources. These resources are the ones made available to you by your PI or working group.</p> <p>In order for you to check your resources, type <code>va</code>.</p> <pre><code>(ocelote) [cosi@wentletrap ~]$ va\nWindfall: Unlimited\n\nPI: parent_1743 Total time: 100000:00:00\n    Total used*: 1:00:00\n    Total encumbered: 0:00:00\n    Total remaining: 99999:00:00\n    Group: datalab Time used: 1:00:00 Time encumbered: 0:00:00\n\n\n*Usage includes all subgroups, some of which may not be displayed here\n</code></pre> <p><code>va</code> allows you to view all of the resources available from all the groups you are part of.</p>"},{"location":"10_reproducibility_IV/#storage","title":"Storage","text":"<p>There are a number of ways one can approach storage on the HPC:</p> <ul> <li>Your own folder (in <code>/home/</code>): 50GB limit</li> <li>Your group (in <code>/groups/</code>): 500GB limit</li> <li>Your PI research (in <code>/xdisk/</code>): 20TB</li> </ul> <p>Four the purpose of this workshop, we can access the datalab group storage in <code>/groups/cosi</code> (we will try and rename it in the future).</p>"},{"location":"10_reproducibility_IV/#queues-and-submissions","title":"Queues and Submissions","text":"<p>One can check queue times and sumbissions by executing the SLURM command <code>squeue</code>. This will display the job id, submission type (standard, windfall, high priority), name of submission, user, status (queued, running), time elapsed, number of used nodes, and nodelist.</p> <pre><code>(ocelote) [cosi@wentletrap ~]$ squeue\n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n2875825_[432-1000]  standard    qchem snanayak PD       0:00      1 (AssocGrpCPUMinutesLimit)\n           2890485  standard R92L_Met krishnag PD       0:00      1 (Dependency)\n           2890484  standard R92L_Met krishnag PD       0:00      1 (Dependency)\n           2890483  standard R92L_Met krishnag PD       0:00      1 (Dependency)\n           2881573  standard R92W_Met krishnag PD       0:00      1 (Dependency)\n           2881572  standard R92W_Met krishnag PD       0:00      1 (Dependency)\n           2802511  standard    eigen krishnag PD       0:00      1 (Dependency)\n           2949224  standard brutefor theronir PD       0:00      1 (None)\n           2898419  standard start_so mmartino PD       0:00      1 (Dependency)\n           2898418  standard make_sor mmartino PD       0:00      1 (Dependency)\n           2898416  standard start_so mmartino PD       0:00      1 (Dependency)\n           2898415  standard make_sor mmartino PD       0:00      1 (Dependency)\n           2898410  standard start_so mmartino PD       0:00      1 (Dependency)\n           2898409  standard make_sor mmartino PD       0:00      1 (Dependency)\n              .         .        .        .     .       .         .   .\n              .         .        .        .     .       .         .   .\n              .         .        .        .     .       .         .   .\n           2884142  windfall li_d_t_6    bubin  R 2-06:58:50      1 i5n14\n           2884107  windfall li_d_t_4    bubin  R 2-07:00:26      1 i6n8\n           2884098  windfall li_d_t_7    bubin  R 2-07:00:50      1 i6n5\n           2880486  windfall   be_10b   teodar  R 4-22:35:44      1 i16n5\n           2880487  windfall    be_9b   teodar  R 4-22:35:44      1 i16n6\n           2880488  windfall    be_7b   teodar  R 4-22:35:44      1 i16n12\n           2880489  windfall    be_2b   teodar  R 4-22:35:44      1 i16n16\n</code></pre> <p>Likely, this will output 100s of lines, therefore if you want to check on your own job, you could use the CLI and <code>grep</code> to select the running submission (e.g., <code>squeue | grep &lt;username&gt;</code> or <code>squeue --user $NETID</code>).</p>"},{"location":"10_reproducibility_IV/#hpc-slurm-and-jobs-submissions","title":"HPC, SLURM and Jobs Submissions","text":"SLURM not Slurm.  <p>All of the UA HPC systems run on a workload manager and job scheduler named SLURM (Simple Linux Utility for Resource Management). It's designed to manage and schedule computing resources such as CPUs, GPUs, memory, and storage across a cluster of interconnected nodes.</p> <p>You can learn more on SLURM and HPC system commands here. </p>"},{"location":"10_reproducibility_IV/#job-submissions","title":"Job Submissions","text":"<p>There are 2 ways one can submit jobs onto the HPC system. The first is to run a batch job, which is the more popular submission type, whilst the other is by requesting an interactive node.</p>"},{"location":"10_reproducibility_IV/#batch-jobs","title":"Batch jobs","text":"<p>As we are not going to be using batch submissions, we are not going to be going into too much detail. However, here is what you need to know. For more details on running batch jobs, visit the official documentation page on batch jobs.</p> <p>Writing a Batch Script</p> <p>Batch scripts require a number of job directives. These are similar to the Dockerfile instructions, but instead of telling Docker how to build the image, these instead tell the SLURM system what to do with the job. The essential directives are the following:</p> Directive Purpose <code>#SBATCH --account=group_name</code> Specify the account where hours are charged. <code>#SBATCH --partition=partition_name</code> Set the job partition. This determines your job's priority and the hours charged. <code>#SBATCH --time=DD-HH:MM:SS</code> Set the job's runtime limit in days, hours, minutes, and seconds. A single job cannot exceed 10 days or 240 hours. <code>#SBATCH --nodes=N</code> Allocate N nodes to your job. <code>#SBATCH --cpus-per-task=M</code>  and  <code>#SBATCH --ntasks=N</code> ntasks specifies the number of tasks (or processes) the job will run. By default, you will be allocated one CPU/task. This can be increased by including the additional directive --cpus-per-task. <code>#SBATCH --mem=Ngb</code> Select N gb of memory per node. If \"gb\" is not included, this value defaults to MB. <p>After setting your directives, you can instruct the HPC to do what you require similar to a bash script.</p> <p>Here's an example of a batch job:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=blast_job          # Job name\n#SBATCH --partition=standard          # Sets the job priority to standard\n#SBATCH --nodes=1                     # Number of nodes\n#SBATCH --ntasks=1                    # Number of tasks (processes) per node\n#SBATCH --cpus-per-task=4             # Number of CPU cores per task\n#SBATCH --mem=8G                      # Memory per node (in this case, 8GB)\n#SBATCH --time=02:00:00               # Time limit (HH:MM:SS)\n\n# Load necessary modules\nmodule load blast/2.12.0              # Load BLAST module (adjust version as needed)\n\n# Change to the directory where the job will run\ncd $SLURM_SUBMIT_DIR\n\n# Define input and output files\nquery_file=\"query.fasta\"              # Input query file (FASTA format)\ndatabase_file=\"database.fasta\"        # BLAST database file (FASTA format)\noutput_file=\"blast_results.out\"       # Output file for BLAST results\n\n# Run BLAST command\nblastp -query $query_file -db $database_file -out $output_file -evalue 0.001 -num_threads $SLURM_CPUS_PER_TASK\n</code></pre> <p>Submitting a Batch Script</p> <ul> <li>To submit jobs you need to use <code>sbatch</code>, such as <code>sbatch script.slurm</code></li> <li>To cancel your job you do <code>scancel</code>, such as <code>scancel $JOBID</code> or <code>scancel -u $NETID</code></li> </ul> <p>This will submit your job to the queue. Execution will depend on your submission type (partition).</p>"},{"location":"10_reproducibility_IV/#launching-an-interactive-node","title":"Launching an Interactive Node","text":"<p>An interactive node, unlike batch jobs which are run asynchronously, allows immediate access to compute. Similar to batch jobs, interactive nodes are submitted to the queue, but once available, you will receive a prompt for a node with the selected resources. Read more on how to launch interactive jobs in the official documentation.</p> <p>The Quick and Dirty</p> <p>Don't need a lot of resources and just want access to the compute?</p> <p>Just type <code>interactive</code>. </p> <p>Disclaimer: you may require to wait longer as your job is going to fall in the <code>windfall</code> queue.</p> <p>Following are a list of useful flags (options) for setting up the interactive node.</p> Flag Default value Description Example <code>-n</code> 1 Number of CPUs requested per node interactive -n 8 <code>-m</code> 4GB Memory per CPU interactive -m 5GB <code>-a</code> none Account (group) to charge interactive -a datalab <code>--partition=</code> windfall Partition to determine CPU time charges and is set to windfall when no account is specified, and is set to standard when an account is provided. interactive --partition=windfall <code>-t</code> 01:00:00 Time allocated to session. interactive -t 08:00:00 <code>-N</code> 1 Number of nodes. There is no reason to exceed 1 node unless the number of CPUs requested is greater than the number of CPUs per node on a given cluster. <p>An example for an interactive node is:</p> <pre><code>interactive -n 8 -m 16GB -a datalab -t 02:00:00 \n</code></pre> <p>The above example will request an interactive node with 8 cores, 16GB RAM, \"charging\" the datalab, running for 2 hours. Try it!  </p> <p>Modules</p> <p>There are 100s of tools installed on the HPC, few of which are available on the login screen. These tools are available only during a batch job submission or within interactive jobs.</p> <p>To see what tools are already running, or which are available, you will need to use the <code>module</code> command.</p> <p>Helpful <code>module</code> commands</p> Command Purpose <code>module list</code> Lists loaded modules <code>module avail</code> Lists available modules <code>module spider</code> Lists ALL modules <code>module load</code> Loads a module <code>module help</code> Help command!"},{"location":"10_reproducibility_IV/#singularityapptainer","title":"Singularity/Apptainer","text":"<p>In 2021, the Sylabs, the developers behind the original Singularity, made a fork of the original project and renamed it SingularityCE (Community Edition). This would allow for the SingularityCE to be compliat with FOSS and allowing for the community to contribute to the builds. The Singularity team then joined the Linux Foundation and decided to rename their effor to Apptainer. </p> <p>The technology behind Singularity/Apptainer is similar to the one of Docker, but, as mentioned before, it was created with the HPC in mind, and therefore bypasses the requirement of sudo.</p> <p>Note</p> <p>Until now we have used Singularity/Apptainer to refer to the same software. Onwards, you can decide whether to use Singularity OR Apptainer; in order to keep up with the latest release, we are going to be executing apptainer commands. </p> Docker vs SingularityCE &amp; Apptainer in the blink of an eye <p> Apptainer and SingularityCE are 100% compatible with Docker but they do have some distinct differences</p> <p> Docker</p> <p> Docker containers run as <code>root</code></p> <ul> <li>This privilege is almost never supported by administrators of High Performance Computing (HPC) centers. Meaning Docker is not, and will likely never be, installed natively on your HPC cluster.</li> </ul> <p> uses compressed layers to create one image</p> <p> SingularityCE &amp; Apptainer:</p> <p>  Same user and group identity inside as outside the container</p> <p>  User only has <code>root</code> privileges if elevated with <code>sudo</code> when the container is run</p> <p>  Can run and modify any existing Docker image</p> <ul> <li>These key differences allow Singularity to be installed on most HPC centers. Because you can run virtually all Docker containers in Singularity, you can effectively run Docker on an HPC. </li> </ul>"},{"location":"10_reproducibility_IV/#general-executable-commands","title":"General Executable Commands","text":"<p>Resources:</p> <ul> <li>https://cc.cyverse.org/singularity/intro/</li> <li>https://cc.cyverse.org/singularity/hpc/</li> <li>https://cc.cyverse.org/singularity/advanced/</li> </ul> <p>Apptainer\u2019s command line interface allows you to build and interact with containers transparently. You can run programs inside a container as if they were running on your host system. You can easily redirect IO, use pipes, pass arguments, and access files, sockets, and ports on the host system from within a container.</p>"},{"location":"10_reproducibility_IV/#help","title":"help","text":"<p>The <code>help</code> command gives an overview of Apptainer options and subcommands as follows:</p> <pre><code> $ apptainer help pull\nPull an image from a URI\n\nUsage:\n  apptainer pull [pull options...] [output file] &lt;URI&gt;\n\nDescription:\n  The 'pull' command allows you to download or build a container from a given\n  URI. Supported URIs include:\n\n  library: Pull an image from the currently configured library\n      library://user/collection/container[:tag]\n\n  docker: Pull a Docker/OCI image from Docker Hub, or another OCI registry.\n      docker://user/image:tag\n\n  shub: Pull an image from Singularity Hub\n      shub://user/image:tag\n\n  oras: Pull a SIF image from an OCI registry that supports ORAS.\n      oras://registry/namespace/image:tag\n\n  http, https: Pull an image using the http(s?) protocol\n      https://example.com/alpine.sif\n\nOptions:\n      --arch string           architecture to pull from library (default\n                              \"amd64\")\n      --arch-variant string   architecture variant to pull from library\n      --dir string            download images to the specific directory\n      --disable-cache         do not use or create cached images/blobs\n      --docker-host string    specify a custom Docker daemon host\n      --docker-login          login to a Docker Repository interactively\n  -F, --force                 overwrite an image file if it exists\n  -h, --help                  help for pull\n      --library string        download images from the provided library\n      --no-cleanup            do NOT clean up bundle after failed build,\n                              can be helpful for debugging\n      --no-https              use http instead of https for docker://\n                              oras:// and library://&lt;hostname&gt;/... URIs\n\n\nExamples:\n  From a library\n  $ apptainer pull alpine.sif library://alpine:latest\n\n  From Docker\n  $ apptainer pull tensorflow.sif docker://tensorflow/tensorflow:latest\n  $ apptainer pull --arch arm --arch-variant 6 alpine.sif docker://alpine:latest\n\n  From Shub\n  $ apptainer pull apptainer-images.sif shub://vsoch/apptainer-images\n\n  From supporting OCI registry (e.g. Azure Container Registry)\n  $ apptainer pull image.sif oras://&lt;username&gt;.azurecr.io/namespace/image:tag\n\n\nFor additional help or support, please visit https://apptainer.org/help/\n</code></pre>"},{"location":"10_reproducibility_IV/#search","title":"search","text":"<p>Just like with Docker, you can <code>search</code> the Apptainer container registries for images.</p> <pre><code>$ apptainer search tensorflow\n</code></pre>"},{"location":"10_reproducibility_IV/#pull","title":"pull","text":"<p>The easiest way to use a Apptainer is to <code>pull</code> an existing container from one of the Registries.</p> <pre><code>$ apptainer pull library://lolcow\n</code></pre> <p>Not only you can pull fromt the Apptainer registries/libraries, but you can pull from Docker.</p> <pre><code>$ apptainer pull docker://alpine\n</code></pre> <p>In my humble opinion...</p> <p>This is whre Apptainer shines: you can pull from Docker and run Docker built images on the HPC! These are automatically converted to Apptainer images (<code>.sif</code>) and executable on the HPC!</p> <p>... so where are the Apptainer <code>.sif</code> images stored?</p> <p>Right where in the directory you are pulling them to. Check with <code>cd</code>!</p>"},{"location":"10_reproducibility_IV/#obtaining-images","title":"Obtaining Images","text":"<p>As metioned earlier, you can use the <code>pull</code> command to download pre-built images from a number of Container Registries, here we'll be focusing on the DockerHub.</p> <p>Container Registries:</p> <ul> <li><code>library://</code> - images hosted on Sylabs Cloud</li> <li><code>docker://</code> - images hosted on Docker Hub</li> <li><code>localimage://</code> - images saved on your machine</li> <li><code>yum://</code> - yum based systems such as CentOS and Scientific Linux</li> <li><code>debootstrap://</code> - apt based systems such as Debian and Ubuntu</li> <li><code>arch://</code> - Arch Linux</li> <li><code>busybox://</code> - BusyBox</li> <li><code>zypper://</code> - zypper based systems such as Suse and OpenSuse</li> <li><code>shub://</code> - (archived) images hosted on Singularity Hub, no longer maintained</li> </ul>"},{"location":"10_reproducibility_IV/#pulling-an-image-from-singularity-hub","title":"Pulling an image from Singularity Hub","text":"<p>Similar to previous example, in this example I am pulling a base Ubuntu container from Singularity-Hub:</p> <pre><code>$ apptainer pull shub://singularityhub/ubuntu\nINFO:    Downloading shub image\n88.6MiB / 88.6MiB [=============================================================================] 100 % 39.1 MiB/s 0s\n</code></pre> <p>Re/naming</p> <p>You can give the  the container using the <code>--name</code> flag: such as <code>apptainer pull --name my-own-ubuntu-pulled-image.sif shub://singularityhub/ubuntu</code></p>"},{"location":"10_reproducibility_IV/#pulling-an-image-from-docker-hub","title":"Pulling an image from Docker Hub","text":"<p>This example pulls an <code>ubuntu:22.04</code> image from DockerHub and saves it to the working directory.</p> <pre><code>$ apptainer pull docker://ubuntu:22.04\nINFO:    Converting OCI blobs to SIF format\nINFO:    Starting build...\nGetting image source signatures\nCopying blob bccd10f490ab done\nCopying config ca2b0f2696 done\nWriting manifest to image destination\nStoring signatures\n2024/03/27 20:14:50  info unpack layer: sha256:bccd10f490ab0f3fba61b193d1b80af91b17ca9bdca9768a16ed05ce16552fcb\nINFO:    Creating SIF file...\n</code></pre>"},{"location":"10_reproducibility_IV/#interacting-with-images","title":"Interacting with Images","text":"<p>You can interact with images in several ways such as <code>run</code>, <code>shell</code> and <code>exec</code>.</p> <p>For these examples we will use a <code>cowsay_latest.sif</code> image that can be pulled from the Docker Hub.</p> <pre><code>$ apptainer pull docker://tswetnam/cowsay\nINFO:    Converting OCI blobs to SIF format\nINFO:    Starting build...\nGetting image source signatures\nCopying blob 05e030abce7b done\nCopying blob b4624b3efe06 done\nCopying blob 6cf436f81810 done\nCopying blob 987088a85b96 done\nCopying blob d42beb8ded59 done\nCopying config ee9e20351a done\nWriting manifest to image destination\nStoring signatures\n2024/03/27 20:16:29  info unpack layer: sha256:6cf436f81810f067c6d4ffca6793eae7cb6d38456715b0707d8a5a2d1acccf12\n2024/03/27 20:16:29  warn rootless{dev/full} creating empty file in place of device 1:7\n2024/03/27 20:16:29  warn rootless{dev/null} creating empty file in place of device 1:3\n2024/03/27 20:16:29  warn rootless{dev/ptmx} creating empty file in place of device 5:2\n2024/03/27 20:16:29  warn rootless{dev/random} creating empty file in place of device 1:8\n2024/03/27 20:16:29  warn rootless{dev/tty} creating empty file in place of device 5:0\n2024/03/27 20:16:29  warn rootless{dev/urandom} creating empty file in place of device 1:9\n2024/03/27 20:16:29  warn rootless{dev/zero} creating empty file in place of device 1:5\n2024/03/27 20:16:30  info unpack layer: sha256:987088a85b9606eb474a365eb210db765ff0d011ee099a6e3de5087435c6f966\n2024/03/27 20:16:30  info unpack layer: sha256:b4624b3efe0617e59ed3998407eafdbe1cb6451346a6cabd066b6e253f50efb1\n2024/03/27 20:16:30  info unpack layer: sha256:d42beb8ded595df5627ad4ef31bf528a6fdbfbd11d82f9023152738d6b05a7fa\n2024/03/27 20:16:30  info unpack layer: sha256:05e030abce7b562606031bcc54646a868984685f4c89c7c354f34f1f6e502917\nINFO:    Creating SIF file..\n\n$ ls\nalpine_latest.sif  lolcow_latest.sif  ubuntu_22.04.sif  cowsay_latest.sif\n</code></pre>"},{"location":"10_reproducibility_IV/#run","title":"run","text":"<p>Apptainer containers contain runscripts. These are user defined scripts that define the actions a container should perform when someone runs it. The runscript can be triggered with the <code>run</code> command, or simply by calling the container as though it were an executable.</p> <pre><code>$ apptainer run cowsay_latest.sif\nINFO:    underlay of /etc/localtime required more than 50 (76) bind mounts\n ____________________________________\n/ Q: Do you know what the death rate \\\n\\ around here is? A: One per person. /\n ------------------------------------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n</code></pre>"},{"location":"10_reproducibility_IV/#shell","title":"shell","text":"<p>The <code>shell</code> command allows you to spawn a new shell within your container and interact with it as though it were a small virtual machine.</p> <pre><code>$ apptainer shell cowsay_latest.sif\nINFO:    underlay of /etc/localtime required more than 50 (76) bind mounts\n(ocelote) Apptainer&gt;\n</code></pre> <p>The change in prompt indicates that you have entered the container (though you should not rely on that to determine whether you are in container or not).</p> <p>Once inside of a Apptainer container, you are the same user as you are on the host system.</p> <pre><code>(ocelote) Apptainer&gt; whoami\ncosi\n</code></pre> <p>Type <code>exit</code> to exit the container.</p> <p>The more you know </p> <p><code>shell</code> also works with the <code>library://</code>, <code>docker://</code>, and <code>shub://</code> URIs. This creates an ephemeral container* that disappears when the shell is exited.</p> <p>Ephemeral container*: a short-lived container instance that is created dynamically to perform a specific task or process and then terminated once the task is complete. These containers are typically used for one-off jobs, temporary operations, or short-duration tasks within a larger computing environment.</p>"},{"location":"10_reproducibility_IV/#exec","title":"exec","text":"<p>The exec command allows you to execute a custom command within a container by specifying the image file. For instance, to execute the <code>cowsay</code> program within the <code>cowsay_latest.sif</code> container:</p> <pre><code>$ apptainer exec cowsay_latest.sif cowsay whoaaaa the grass is soooo green inside the HPC!\nINFO:    underlay of /etc/localtime required more than 50 (76) bind mounts\n _________________________________________\n/ whoaaaa the grass is soooo green inside \\\n\\ the HPC!                                /\n -----------------------------------------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n</code></pre> <p>This  also creates an ephemeral container that executes a command and disappears.</p>"},{"location":"10_reproducibility_IV/#inspect","title":"inspect","text":"<p>The <code>inspect</code> command will provide information about labels, metadata, and environmental variables.</p> <pre><code>$ apptainer inspect cowsay_latest.sif\norg.label-schema.build-arch: amd64\norg.label-schema.build-date: Wednesday_27_March_2024_20:16:32_MST\norg.label-schema.schema-version: 1.0\norg.label-schema.usage.apptainer.version: 1.2.5-1.el7\norg.label-schema.usage.singularity.deffile.bootstrap: docker\norg.label-schema.usage.singularity.deffile.from: tswetnam/cowsay\n</code></pre>"},{"location":"11_sql_duckdb/","title":"Exploring SQL Databases with DuckDB","text":""},{"location":"11_sql_duckdb/#database","title":"Database","text":"<ul> <li>A database is a structured collection of data.</li> <li>It allows for the storage, retrieval, modification, and deletion of data in an organized manner.</li> <li>Databases come in various types, including relational and NoSQL. Relational databases organize data into tables, which are interconnected.</li> <li>Each table represents a related data collection and is organized into rows and columns.</li> </ul>"},{"location":"11_sql_duckdb/#sql-stands-for-structured-query-language","title":"SQL stands for Structured Query Language.","text":"<p>It's a programming language that stores and processes information in relational databases.</p>"},{"location":"11_sql_duckdb/#types-of-sql-statements","title":"Types of SQL Statements","text":"<ul> <li>DDL (Data Definition Language): DDL statements are used to define, modify, and remove database structures, but not the data within them. Common DDL statements include CREATE, ALTER, and DROP.</li> <li>DML (Data Manipulation Language): DML statements manage data within schema objects. They include SELECT, INSERT, UPDATE, and DELETE.</li> </ul>"},{"location":"11_sql_duckdb/#duckdb","title":"DuckDB","text":"<ul> <li>An in-memory, columnar database management system optimized for analytical queries.\"</li> <li>Open-source and designed for simplicity, speed, and efficiency in processing analytical workloads.\"</li> <li>Supports SQL standards for easy integration with existing tools and workflows.</li> </ul>"},{"location":"11_sql_duckdb/#install-duckdb","title":"Install DuckDB","text":""},{"location":"11_sql_duckdb/#with-python-set-up-you-can-now-install-duckdb-using-pip-in-your-terminal-or-command-line-execute","title":"With Python set up, you can now install DuckDB using pip. In your terminal or command line, execute:","text":"<pre><code>pip install duckdb\n</code></pre>"},{"location":"11_sql_duckdb/#to-ensure-duckdb-is-installed-correctly-launch-your-jupyter-notebook-and-try-importing-the-duckdb-module","title":"To ensure DuckDB is installed correctly, launch your jupyter Notebook and try importing the DuckDB module:","text":"<pre><code>pip install duckdb\n</code></pre>"},{"location":"11_sql_duckdb/#if-no-errors-occur-duckdb-is-successfully-installed-and-ready-to-use","title":"If no errors occur, DuckDB is successfully installed and ready to use.","text":""},{"location":"11_sql_duckdb/#in-your-jupyter-notebook-import-duckdb-by-running","title":"In your Jupyter Notebook, import duckdb by running","text":"<pre><code>import duckdb\n</code></pre>"},{"location":"11_sql_duckdb/#for-this-tutorial-we-will-be-using-a-pre-configured-duckdb-database","title":"For this tutorial, we will be using a pre-configured Duckdb Database.","text":""},{"location":"11_sql_duckdb/#lets-download-the-database-file","title":"Let's download the database file:","text":"<pre><code>!wget --content-disposition https://arizona.box.com/shared/static/uozg0z86rtdjupwpc7i971xwzuzhp42o.duckdb\n</code></pre>"},{"location":"11_sql_duckdb/#connect-to-the-database-using","title":"Connect to the database using:","text":"<pre><code>conn = duckdb.connect(database='/content/my_database.duckdb', read_only=True)\n</code></pre>"},{"location":"11_sql_duckdb/#viewing-which-tables-are-available-inside-the-database","title":"Viewing which tables are available inside the database","text":"<pre><code>conn.sql(\"SHOW TABLES;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       name        \u2502\n\u2502      varchar      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 allergies         \u2502\n\u2502 careplans         \u2502\n\u2502 conditions        \u2502\n\u2502 devices           \u2502\n\u2502 encounters        \u2502\n\u2502 imaging_studies   \u2502\n\u2502 immunizations     \u2502\n\u2502 medications       \u2502\n\u2502 observations      \u2502\n\u2502 organizations     \u2502\n\u2502 patients          \u2502\n\u2502 payer_transitions \u2502\n\u2502 payers            \u2502\n\u2502 procedures        \u2502\n\u2502 providers         \u2502\n\u2502 supplies          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      16 rows      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"11_sql_duckdb/#before-running-any-query-we-need-to-know-the-columns-inside-particular-tables","title":"Before running any query, we need to know the columns inside particular tables","text":"<p><pre><code>conn.sql(\"DESCRIBE patients;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     column_name     \u2502 column_type \u2502  null   \u2502   key   \u2502 default \u2502 extra \u2502\n\u2502       varchar       \u2502   varchar   \u2502 varchar \u2502 varchar \u2502 varchar \u2502 int32 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Id                  \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 BIRTHDATE           \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 DEATHDATE           \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 SSN                 \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 DRIVERS             \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 PASSPORT            \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 PREFIX              \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 FIRST               \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 LAST                \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 SUFFIX              \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502   \u00b7                 \u2502    \u00b7        \u2502  \u00b7      \u2502  \u00b7      \u2502  \u00b7      \u2502    \u00b7  \u2502\n\u2502   \u00b7                 \u2502    \u00b7        \u2502  \u00b7      \u2502  \u00b7      \u2502  \u00b7      \u2502    \u00b7  \u2502\n\u2502   \u00b7                 \u2502    \u00b7        \u2502  \u00b7      \u2502  \u00b7      \u2502  \u00b7      \u2502    \u00b7  \u2502\n\u2502 BIRTHPLACE          \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 ADDRESS             \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 CITY                \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 STATE               \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 COUNTY              \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 ZIP                 \u2502 DOUBLE      \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 LAT                 \u2502 DOUBLE      \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 LON                 \u2502 DOUBLE      \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 HEALTHCARE_EXPENSES \u2502 DOUBLE      \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 HEALTHCARE_COVERAGE \u2502 DOUBLE      \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 25 rows (20 shown)                                            6 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>conn.sql(\"DESCRIBE medications;\")\n</code></pre> <pre><code>conn.sql(\"DESCRIBE medications;\")\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    column_name    \u2502 column_type \u2502  null   \u2502   key   \u2502 default \u2502 extra \u2502\n\u2502      varchar      \u2502   varchar   \u2502 varchar \u2502 varchar \u2502 varchar \u2502 int32 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 START             \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 STOP              \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 PATIENT           \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 PAYER             \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 ENCOUNTER         \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 CODE              \u2502 BIGINT      \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 DESCRIPTION       \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 BASE_COST         \u2502 DOUBLE      \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 PAYER_COVERAGE    \u2502 DOUBLE      \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 DISPENSES         \u2502 BIGINT      \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 TOTALCOST         \u2502 DOUBLE      \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 REASONCODE        \u2502 DOUBLE      \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 REASONDESCRIPTION \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 13 rows                                                     6 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>conn.sql(\"DESCRIBE immunizations;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 column_name \u2502 column_type \u2502  null   \u2502   key   \u2502 default \u2502 extra \u2502\n\u2502   varchar   \u2502   varchar   \u2502 varchar \u2502 varchar \u2502 varchar \u2502 int32 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 DATE        \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 PATIENT     \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 ENCOUNTER   \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 CODE        \u2502 BIGINT      \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 DESCRIPTION \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 BASE_COST   \u2502 DOUBLE      \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#querying-data","title":"Querying Data","text":""},{"location":"11_sql_duckdb/#select-the-select-statement-selects-data-from-a-database","title":"SELECT - The SELECT statement selects data from a database.","text":"<p>E.g.: Query the patients table and display patient first name, last name, gender, and the city they live in.</p> <p><pre><code>conn.sql(\"SELECT FIRST, LAST, GENDER, CITY FROM patients;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      FIRST      \u2502      LAST      \u2502 GENDER  \u2502    CITY     \u2502\n\u2502     varchar     \u2502    varchar     \u2502 varchar \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Jacinto644      \u2502 Kris249        \u2502 M       \u2502 Springfield \u2502\n\u2502 Alva958         \u2502 Krajcik437     \u2502 F       \u2502 Walpole     \u2502\n\u2502 Jimmie93        \u2502 Harris789      \u2502 F       \u2502 Pembroke    \u2502\n\u2502 Gregorio366     \u2502 Auer97         \u2502 M       \u2502 Boston      \u2502\n\u2502 Karyn217        \u2502 Mueller846     \u2502 F       \u2502 Colrain     \u2502\n\u2502 Jayson808       \u2502 Fadel536       \u2502 M       \u2502 Chicopee    \u2502\n\u2502 Jos\u00e9 Eduardo181 \u2502 G\u00f3mez206       \u2502 M       \u2502 Chicopee    \u2502\n\u2502 Milo271         \u2502 Feil794        \u2502 M       \u2502 Somerville  \u2502\n\u2502 Karyn217        \u2502 Metz686        \u2502 F       \u2502 Medfield    \u2502\n\u2502 Jeffrey461      \u2502 Greenfelder433 \u2502 M       \u2502 Springfield \u2502\n\u2502     \u00b7           \u2502     \u00b7          \u2502 \u00b7       \u2502    \u00b7        \u2502\n\u2502     \u00b7           \u2502     \u00b7          \u2502 \u00b7       \u2502    \u00b7        \u2502\n\u2502     \u00b7           \u2502     \u00b7          \u2502 \u00b7       \u2502    \u00b7        \u2502\n\u2502 Raymond398      \u2502 Kuvalis369     \u2502 M       \u2502 Hingham     \u2502\n\u2502 Gearldine455    \u2502 Boyer713       \u2502 F       \u2502 Boston      \u2502\n\u2502 Nichol11        \u2502 Gleichner915   \u2502 F       \u2502 Lynn        \u2502\n\u2502 Louvenia131     \u2502 Marks830       \u2502 F       \u2502 Springfield \u2502\n\u2502 Raymon366       \u2502 Beer512        \u2502 M       \u2502 Springfield \u2502\n\u2502 Camelia346      \u2502 Stamm704       \u2502 F       \u2502 Dedham      \u2502\n\u2502 William805      \u2502 Pacocha935     \u2502 M       \u2502 Brockton    \u2502\n\u2502 Guillermo498    \u2502 T\u00e9llez750      \u2502 M       \u2502 Somerville  \u2502\n\u2502 Milton509       \u2502 Bailey598      \u2502 M       \u2502 Hull        \u2502\n\u2502 Cecilia788      \u2502 Wisozk929      \u2502 F       \u2502 Worcester   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 20 shown)                  4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#count-the-number-of-rows-in-patients-table","title":"Count the number of rows in patients table","text":""},{"location":"11_sql_duckdb/#this-query-will-count-the-total-number-of-rows-in-the-patients-table-effectively-giving-you-the-total-number-of-patients","title":"This query will count the total number of rows in the patients table, effectively giving you the total number of patients.","text":"<p><pre><code>conn.sql(\"SELECT COUNT(*) FROM patients;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 count_star() \u2502\n\u2502    int64     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502       124150 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#count-and-distinct","title":"COUNT and DISTINCT","text":"<p>If you want to count distinct values of a specific column, for example, distinct cities, you can modify the query as follows: <pre><code>conn.sql(\"SELECT COUNT(DISTINCT CITY) FROM patients;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 count(DISTINCT CITY) \u2502\n\u2502        int64         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                  351 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#filtering-data-based-on-a-condition","title":"Filtering data based on a condition","text":"<p>The WHERE clause filters records that fulfill a specified condition. e.g: Patients in City = 'Springfield';</p> <p><pre><code>conn.sql(\"SELECT FIRST, LAST, GENDER, CITY, PASSPORT FROM patients WHERE city = 'Springfield';\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    FIRST     \u2502      LAST      \u2502 GENDER  \u2502    CITY     \u2502  PASSPORT  \u2502\n\u2502   varchar    \u2502    varchar     \u2502 varchar \u2502   varchar   \u2502  varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Jacinto644   \u2502 Kris249        \u2502 M       \u2502 Springfield \u2502 NULL       \u2502\n\u2502 Jeffrey461   \u2502 Greenfelder433 \u2502 M       \u2502 Springfield \u2502 NULL       \u2502\n\u2502 Sabina296    \u2502 Flatley871     \u2502 F       \u2502 Springfield \u2502 X85058581X \u2502\n\u2502 Theodora872  \u2502 Johnson679     \u2502 F       \u2502 Springfield \u2502 X21164602X \u2502\n\u2502 Lavera253    \u2502 Anderson154    \u2502 F       \u2502 Springfield \u2502 X83686992X \u2502\n\u2502 Golden321    \u2502 Pollich983     \u2502 F       \u2502 Springfield \u2502 NULL       \u2502\n\u2502 Georgiann138 \u2502 Greenfelder433 \u2502 F       \u2502 Springfield \u2502 X58134116X \u2502\n\u2502 Fausto876    \u2502 Bechtelar572   \u2502 M       \u2502 Springfield \u2502 NULL       \u2502\n\u2502 Talisha682   \u2502 Brakus656      \u2502 F       \u2502 Springfield \u2502 X53645004X \u2502\n\u2502 Golden321    \u2502 Durgan499      \u2502 F       \u2502 Springfield \u2502 X49016634X \u2502\n\u2502    \u00b7         \u2502    \u00b7           \u2502 \u00b7       \u2502      \u00b7      \u2502     \u00b7      \u2502\n\u2502    \u00b7         \u2502    \u00b7           \u2502 \u00b7       \u2502      \u00b7      \u2502     \u00b7      \u2502\n\u2502    \u00b7         \u2502    \u00b7           \u2502 \u00b7       \u2502      \u00b7      \u2502     \u00b7      \u2502\n\u2502 Carla633     \u2502 Ter\u00e1n294       \u2502 F       \u2502 Springfield \u2502 X50212869X \u2502\n\u2502 \u00c1ngela136    \u2502 Mu\u00f1iz642       \u2502 F       \u2502 Springfield \u2502 NULL       \u2502\n\u2502 Marceline716 \u2502 Kuhlman484     \u2502 F       \u2502 Springfield \u2502 X70432308X \u2502\n\u2502 Ana Mar\u00eda762 \u2502 Cotto891       \u2502 F       \u2502 Springfield \u2502 X4604857X  \u2502\n\u2502 Josefina523  \u2502 Vanegas191     \u2502 F       \u2502 Springfield \u2502 X85396222X \u2502\n\u2502 Ester635     \u2502 Sevilla788     \u2502 F       \u2502 Springfield \u2502 X50601786X \u2502\n\u2502 Tom\u00e1s404     \u2502 Galarza986     \u2502 M       \u2502 Springfield \u2502 X76790663X \u2502\n\u2502 Arturo47     \u2502 Delafuente833  \u2502 M       \u2502 Springfield \u2502 X45087804X \u2502\n\u2502 Gilberto712  \u2502 Mart\u00ednez540    \u2502 M       \u2502 Springfield \u2502 X89729075X \u2502\n\u2502 Juanita470   \u2502 Connelly992    \u2502 F       \u2502 Springfield \u2502 X71156217X \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2814 rows (20 shown)                                     5 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#multiple-conditions-in-selection","title":"Multiple conditions in Selection","text":"<p>e.g 1: Female Patients in City = 'Springfield'; <pre><code>conn.sql(\"SELECT FIRST, LAST, GENDER, CITY FROM patients WHERE city = 'Springfield' AND gender = 'F';\")\n</code></pre> <pre><code>conn.sql(\"SELECT FIRST, LAST, GENDER, CITY FROM patients WHERE city = 'Springfield' AND gender = 'F';\")\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    FIRST     \u2502      LAST      \u2502 GENDER  \u2502    CITY     \u2502\n\u2502   varchar    \u2502    varchar     \u2502 varchar \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Sabina296    \u2502 Flatley871     \u2502 F       \u2502 Springfield \u2502\n\u2502 Theodora872  \u2502 Johnson679     \u2502 F       \u2502 Springfield \u2502\n\u2502 Lavera253    \u2502 Anderson154    \u2502 F       \u2502 Springfield \u2502\n\u2502 Golden321    \u2502 Pollich983     \u2502 F       \u2502 Springfield \u2502\n\u2502 Georgiann138 \u2502 Greenfelder433 \u2502 F       \u2502 Springfield \u2502\n\u2502 Talisha682   \u2502 Brakus656      \u2502 F       \u2502 Springfield \u2502\n\u2502 Golden321    \u2502 Durgan499      \u2502 F       \u2502 Springfield \u2502\n\u2502 Jerrie417    \u2502 Gislason620    \u2502 F       \u2502 Springfield \u2502\n\u2502 Venus149     \u2502 Hodkiewicz467  \u2502 F       \u2502 Springfield \u2502\n\u2502 Refugia211   \u2502 Wintheiser220  \u2502 F       \u2502 Springfield \u2502\n\u2502    \u00b7         \u2502     \u00b7          \u2502 \u00b7       \u2502      \u00b7      \u2502\n\u2502    \u00b7         \u2502     \u00b7          \u2502 \u00b7       \u2502      \u00b7      \u2502\n\u2502    \u00b7         \u2502     \u00b7          \u2502 \u00b7       \u2502      \u00b7      \u2502\n\u2502 Tisha655     \u2502 Renner328      \u2502 F       \u2502 Springfield \u2502\n\u2502 Mona85       \u2502 Senger904      \u2502 F       \u2502 Springfield \u2502\n\u2502 Isabel214    \u2502 Camacho176     \u2502 F       \u2502 Springfield \u2502\n\u2502 Carla633     \u2502 Ter\u00e1n294       \u2502 F       \u2502 Springfield \u2502\n\u2502 \u00c1ngela136    \u2502 Mu\u00f1iz642       \u2502 F       \u2502 Springfield \u2502\n\u2502 Marceline716 \u2502 Kuhlman484     \u2502 F       \u2502 Springfield \u2502\n\u2502 Ana Mar\u00eda762 \u2502 Cotto891       \u2502 F       \u2502 Springfield \u2502\n\u2502 Josefina523  \u2502 Vanegas191     \u2502 F       \u2502 Springfield \u2502\n\u2502 Ester635     \u2502 Sevilla788     \u2502 F       \u2502 Springfield \u2502\n\u2502 Juanita470   \u2502 Connelly992    \u2502 F       \u2502 Springfield \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1351 rows (20 shown)                        4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#nested-selection","title":"Nested selection","text":"<p>e.g. Female patients from City Springfield or Boston <pre><code>conn.sql(\"SELECT FIRST, LAST, GENDER, CITY FROM patients WHERE gender = 'F' AND (city = 'Springfield' OR city = 'Boston');\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    FIRST     \u2502      LAST      \u2502 GENDER  \u2502    CITY     \u2502\n\u2502   varchar    \u2502    varchar     \u2502 varchar \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Sabina296    \u2502 Flatley871     \u2502 F       \u2502 Springfield \u2502\n\u2502 Theodora872  \u2502 Johnson679     \u2502 F       \u2502 Springfield \u2502\n\u2502 Lavera253    \u2502 Anderson154    \u2502 F       \u2502 Springfield \u2502\n\u2502 Golden321    \u2502 Pollich983     \u2502 F       \u2502 Springfield \u2502\n\u2502 Georgiann138 \u2502 Greenfelder433 \u2502 F       \u2502 Springfield \u2502\n\u2502 Talisha682   \u2502 Brakus656      \u2502 F       \u2502 Springfield \u2502\n\u2502 Golden321    \u2502 Durgan499      \u2502 F       \u2502 Springfield \u2502\n\u2502 Jerrie417    \u2502 Gislason620    \u2502 F       \u2502 Springfield \u2502\n\u2502 Venus149     \u2502 Hodkiewicz467  \u2502 F       \u2502 Springfield \u2502\n\u2502 Refugia211   \u2502 Wintheiser220  \u2502 F       \u2502 Springfield \u2502\n\u2502     \u00b7        \u2502    \u00b7           \u2502 \u00b7       \u2502   \u00b7         \u2502\n\u2502     \u00b7        \u2502    \u00b7           \u2502 \u00b7       \u2502   \u00b7         \u2502\n\u2502     \u00b7        \u2502    \u00b7           \u2502 \u00b7       \u2502   \u00b7         \u2502\n\u2502 Freida957    \u2502 Hand679        \u2502 F       \u2502 Boston      \u2502\n\u2502 Clora637     \u2502 Rempel203      \u2502 F       \u2502 Boston      \u2502\n\u2502 Bonny428     \u2502 Turner526      \u2502 F       \u2502 Boston      \u2502\n\u2502 Tien590      \u2502 Gaylord332     \u2502 F       \u2502 Boston      \u2502\n\u2502 Arlyne429    \u2502 Deckow585      \u2502 F       \u2502 Boston      \u2502\n\u2502 Doreen575    \u2502 Johnson679     \u2502 F       \u2502 Boston      \u2502\n\u2502 Kym935       \u2502 Hayes766       \u2502 F       \u2502 Boston      \u2502\n\u2502 Julia241     \u2502 Nev\u00e1rez403     \u2502 F       \u2502 Boston      \u2502\n\u2502 Ja391        \u2502 Murray856      \u2502 F       \u2502 Boston      \u2502\n\u2502 Creola518    \u2502 Spinka232      \u2502 F       \u2502 Boston      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 7191 rows (20 shown)                        4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#alternative","title":"Alternative","text":"<p><pre><code>conn.sql(\"SELECT FIRST, LAST, GENDER, CITY FROM patients WHERE gender = 'F' AND (city IN ('Springfield','Boston'));\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    FIRST     \u2502      LAST      \u2502 GENDER  \u2502    CITY     \u2502\n\u2502   varchar    \u2502    varchar     \u2502 varchar \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Sabina296    \u2502 Flatley871     \u2502 F       \u2502 Springfield \u2502\n\u2502 Theodora872  \u2502 Johnson679     \u2502 F       \u2502 Springfield \u2502\n\u2502 Lavera253    \u2502 Anderson154    \u2502 F       \u2502 Springfield \u2502\n\u2502 Golden321    \u2502 Pollich983     \u2502 F       \u2502 Springfield \u2502\n\u2502 Georgiann138 \u2502 Greenfelder433 \u2502 F       \u2502 Springfield \u2502\n\u2502 Talisha682   \u2502 Brakus656      \u2502 F       \u2502 Springfield \u2502\n\u2502 Golden321    \u2502 Durgan499      \u2502 F       \u2502 Springfield \u2502\n\u2502 Jerrie417    \u2502 Gislason620    \u2502 F       \u2502 Springfield \u2502\n\u2502 Venus149     \u2502 Hodkiewicz467  \u2502 F       \u2502 Springfield \u2502\n\u2502 Refugia211   \u2502 Wintheiser220  \u2502 F       \u2502 Springfield \u2502\n\u2502     \u00b7        \u2502    \u00b7           \u2502 \u00b7       \u2502   \u00b7         \u2502\n\u2502     \u00b7        \u2502    \u00b7           \u2502 \u00b7       \u2502   \u00b7         \u2502\n\u2502     \u00b7        \u2502    \u00b7           \u2502 \u00b7       \u2502   \u00b7         \u2502\n\u2502 Freida957    \u2502 Hand679        \u2502 F       \u2502 Boston      \u2502\n\u2502 Clora637     \u2502 Rempel203      \u2502 F       \u2502 Boston      \u2502\n\u2502 Bonny428     \u2502 Turner526      \u2502 F       \u2502 Boston      \u2502\n\u2502 Tien590      \u2502 Gaylord332     \u2502 F       \u2502 Boston      \u2502\n\u2502 Arlyne429    \u2502 Deckow585      \u2502 F       \u2502 Boston      \u2502\n\u2502 Doreen575    \u2502 Johnson679     \u2502 F       \u2502 Boston      \u2502\n\u2502 Kym935       \u2502 Hayes766       \u2502 F       \u2502 Boston      \u2502\n\u2502 Julia241     \u2502 Nev\u00e1rez403     \u2502 F       \u2502 Boston      \u2502\n\u2502 Ja391        \u2502 Murray856      \u2502 F       \u2502 Boston      \u2502\n\u2502 Creola518    \u2502 Spinka232      \u2502 F       \u2502 Boston      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 7191 rows (20 shown)                        4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#filter-on-missing-data","title":"Filter on missing data","text":"<ul> <li>Filtering on missing data is crucial for maintaining data integrity and ensuring accurate analysis by identifying and handling incomplete records effectively.</li> <li>Retrieve the first name, last name, gender, and city for all patients who are from Springfield and have a passport number recorded (i.e., the passport field is not empty).</li> </ul> <p><pre><code>conn.sql(\"SELECT FIRST, LAST, GENDER, CITY, PASSPORT FROM patients WHERE city = 'Springfield' AND PASSPORT IS NOT NULL;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    FIRST     \u2502      LAST      \u2502 GENDER  \u2502    CITY     \u2502  PASSPORT  \u2502\n\u2502   varchar    \u2502    varchar     \u2502 varchar \u2502   varchar   \u2502  varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Sabina296    \u2502 Flatley871     \u2502 F       \u2502 Springfield \u2502 X85058581X \u2502\n\u2502 Theodora872  \u2502 Johnson679     \u2502 F       \u2502 Springfield \u2502 X21164602X \u2502\n\u2502 Lavera253    \u2502 Anderson154    \u2502 F       \u2502 Springfield \u2502 X83686992X \u2502\n\u2502 Georgiann138 \u2502 Greenfelder433 \u2502 F       \u2502 Springfield \u2502 X58134116X \u2502\n\u2502 Talisha682   \u2502 Brakus656      \u2502 F       \u2502 Springfield \u2502 X53645004X \u2502\n\u2502 Golden321    \u2502 Durgan499      \u2502 F       \u2502 Springfield \u2502 X49016634X \u2502\n\u2502 Ty725        \u2502 Schmeler639    \u2502 M       \u2502 Springfield \u2502 X22960735X \u2502\n\u2502 Pilar644     \u2502 Pouros728      \u2502 F       \u2502 Springfield \u2502 X21434326X \u2502\n\u2502 Georgette866 \u2502 Stark857       \u2502 F       \u2502 Springfield \u2502 X84034866X \u2502\n\u2502 Annika454    \u2502 Gutmann970     \u2502 F       \u2502 Springfield \u2502 X3275916X  \u2502\n\u2502     \u00b7        \u2502     \u00b7          \u2502 \u00b7       \u2502      \u00b7      \u2502     \u00b7      \u2502\n\u2502     \u00b7        \u2502     \u00b7          \u2502 \u00b7       \u2502      \u00b7      \u2502     \u00b7      \u2502\n\u2502     \u00b7        \u2502     \u00b7          \u2502 \u00b7       \u2502      \u00b7      \u2502     \u00b7      \u2502\n\u2502 Isabel214    \u2502 Camacho176     \u2502 F       \u2502 Springfield \u2502 X52173808X \u2502\n\u2502 Carla633     \u2502 Ter\u00e1n294       \u2502 F       \u2502 Springfield \u2502 X50212869X \u2502\n\u2502 Marceline716 \u2502 Kuhlman484     \u2502 F       \u2502 Springfield \u2502 X70432308X \u2502\n\u2502 Ana Mar\u00eda762 \u2502 Cotto891       \u2502 F       \u2502 Springfield \u2502 X4604857X  \u2502\n\u2502 Josefina523  \u2502 Vanegas191     \u2502 F       \u2502 Springfield \u2502 X85396222X \u2502\n\u2502 Ester635     \u2502 Sevilla788     \u2502 F       \u2502 Springfield \u2502 X50601786X \u2502\n\u2502 Tom\u00e1s404     \u2502 Galarza986     \u2502 M       \u2502 Springfield \u2502 X76790663X \u2502\n\u2502 Arturo47     \u2502 Delafuente833  \u2502 M       \u2502 Springfield \u2502 X45087804X \u2502\n\u2502 Gilberto712  \u2502 Mart\u00ednez540    \u2502 M       \u2502 Springfield \u2502 X89729075X \u2502\n\u2502 Juanita470   \u2502 Connelly992    \u2502 F       \u2502 Springfield \u2502 X71156217X \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2221 rows (20 shown)                                     5 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#filter-and-select-in-numeric-range","title":"Filter and select in numeric range","text":"<p>Patients in City = 'Springfield' where the HEALTHCARE_EXPENSES between 1.5M and 2M</p> <p><pre><code>conn.sql(\"SELECT FIRST, LAST, GENDER, CITY FROM patients WHERE city = 'Springfield' AND HEALTHCARE_EXPENSES BETWEEN 1500000 AND 2000000;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    FIRST     \u2502      LAST      \u2502 GENDER  \u2502    CITY     \u2502\n\u2502   varchar    \u2502    varchar     \u2502 varchar \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Talisha682   \u2502 Brakus656      \u2502 F       \u2502 Springfield \u2502\n\u2502 Jerold208    \u2502 Harber290      \u2502 M       \u2502 Springfield \u2502\n\u2502 Dean966      \u2502 Tillman293     \u2502 M       \u2502 Springfield \u2502\n\u2502 Orval846     \u2502 Cartwright189  \u2502 M       \u2502 Springfield \u2502\n\u2502 Jacinto644   \u2502 Abernathy524   \u2502 M       \u2502 Springfield \u2502\n\u2502 Bethel526    \u2502 Satterfield305 \u2502 F       \u2502 Springfield \u2502\n\u2502 Dorene845    \u2502 Botsford977    \u2502 F       \u2502 Springfield \u2502\n\u2502 Lula998      \u2502 Langosh790     \u2502 F       \u2502 Springfield \u2502\n\u2502 Deeanna316   \u2502 Koss676        \u2502 F       \u2502 Springfield \u2502\n\u2502 Loriann967   \u2502 Torp761        \u2502 F       \u2502 Springfield \u2502\n\u2502    \u00b7         \u2502    \u00b7           \u2502 \u00b7       \u2502      \u00b7      \u2502\n\u2502    \u00b7         \u2502    \u00b7           \u2502 \u00b7       \u2502      \u00b7      \u2502\n\u2502    \u00b7         \u2502    \u00b7           \u2502 \u00b7       \u2502      \u00b7      \u2502\n\u2502 Ashley34     \u2502 Murazik203     \u2502 M       \u2502 Springfield \u2502\n\u2502 Ulysses632   \u2502 Donnelly343    \u2502 M       \u2502 Springfield \u2502\n\u2502 Horace32     \u2502 Hammes673      \u2502 M       \u2502 Springfield \u2502\n\u2502 Roman389     \u2502 Lubowitz58     \u2502 M       \u2502 Springfield \u2502\n\u2502 Jerald662    \u2502 Grady603       \u2502 M       \u2502 Springfield \u2502\n\u2502 Damien170    \u2502 Hoppe518       \u2502 M       \u2502 Springfield \u2502\n\u2502 Charley358   \u2502 Vandervort697  \u2502 M       \u2502 Springfield \u2502\n\u2502 Carla633     \u2502 Ter\u00e1n294       \u2502 F       \u2502 Springfield \u2502\n\u2502 Ana Mar\u00eda762 \u2502 Cotto891       \u2502 F       \u2502 Springfield \u2502\n\u2502 Juanita470   \u2502 Connelly992    \u2502 F       \u2502 Springfield \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 241 rows (20 shown)                         4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#limit","title":"LIMIT","text":"<ul> <li>LIMIT specifies the maximum number of records the query will return.</li> </ul> <p><pre><code>conn.sql(\"SELECT FIRST, LAST, GENDER, CITY FROM patients LIMIT 20;\")\n</code></pre> <pre><code>conn.sql(\"SELECT FIRST, LAST, GENDER, CITY FROM patients LIMIT 20;\")\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      FIRST      \u2502      LAST      \u2502 GENDER  \u2502    CITY     \u2502\n\u2502     varchar     \u2502    varchar     \u2502 varchar \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Jacinto644      \u2502 Kris249        \u2502 M       \u2502 Springfield \u2502\n\u2502 Alva958         \u2502 Krajcik437     \u2502 F       \u2502 Walpole     \u2502\n\u2502 Jimmie93        \u2502 Harris789      \u2502 F       \u2502 Pembroke    \u2502\n\u2502 Gregorio366     \u2502 Auer97         \u2502 M       \u2502 Boston      \u2502\n\u2502 Karyn217        \u2502 Mueller846     \u2502 F       \u2502 Colrain     \u2502\n\u2502 Jayson808       \u2502 Fadel536       \u2502 M       \u2502 Chicopee    \u2502\n\u2502 Jos\u00e9 Eduardo181 \u2502 G\u00f3mez206       \u2502 M       \u2502 Chicopee    \u2502\n\u2502 Milo271         \u2502 Feil794        \u2502 M       \u2502 Somerville  \u2502\n\u2502 Karyn217        \u2502 Metz686        \u2502 F       \u2502 Medfield    \u2502\n\u2502 Jeffrey461      \u2502 Greenfelder433 \u2502 M       \u2502 Springfield \u2502\n\u2502 Mariana775      \u2502 Gulgowski816   \u2502 F       \u2502 Lowell      \u2502\n\u2502 Leann224        \u2502 Deckow585      \u2502 F       \u2502 Needham     \u2502\n\u2502 Isabel214       \u2502 Hinojosa147    \u2502 F       \u2502 Fall River  \u2502\n\u2502 Christal240     \u2502 Brown30        \u2502 F       \u2502 Boston      \u2502\n\u2502 Carmelia328     \u2502 Konopelski743  \u2502 F       \u2502 Ashland     \u2502\n\u2502 Raye931         \u2502 Wyman904       \u2502 F       \u2502 Quincy      \u2502\n\u2502 Lisbeth69       \u2502 Rowe323        \u2502 F       \u2502 Malden      \u2502\n\u2502 Amada498        \u2502 Spinka232      \u2502 F       \u2502 Foxborough  \u2502\n\u2502 Cythia210       \u2502 Reichel38      \u2502 F       \u2502 Peabody     \u2502\n\u2502 Mar\u00eda Soledad68 \u2502 Aparicio848    \u2502 F       \u2502 Boston      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 20 rows                                        4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#order-by-and-asc","title":"ORDER BY and ASC","text":"<p>This query returns the first 20 patients from the patients table, ordered alphabetically by their last name. <pre><code>conn.sql(\"SELECT FIRST, LAST, GENDER, CITY FROM patients ORDER BY LAST ASC LIMIT 20;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     FIRST      \u2502   LAST    \u2502 GENDER  \u2502     CITY     \u2502\n\u2502    varchar     \u2502  varchar  \u2502 varchar \u2502   varchar    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Jc393          \u2502 Abbott774 \u2502 M       \u2502 Westfield    \u2502\n\u2502 Lloyd546       \u2502 Abbott774 \u2502 M       \u2502 Northampton  \u2502\n\u2502 Charles364     \u2502 Abbott774 \u2502 M       \u2502 Brockton     \u2502\n\u2502 Lelia627       \u2502 Abbott774 \u2502 F       \u2502 Gloucester   \u2502\n\u2502 Devorah937     \u2502 Abbott774 \u2502 F       \u2502 Cambridge    \u2502\n\u2502 Warren653      \u2502 Abbott774 \u2502 M       \u2502 Tyngsborough \u2502\n\u2502 Rhona164       \u2502 Abbott774 \u2502 F       \u2502 Stoneham     \u2502\n\u2502 Jackqueline794 \u2502 Abbott774 \u2502 F       \u2502 Randolph     \u2502\n\u2502 Willa615       \u2502 Abbott774 \u2502 F       \u2502 Dartmouth    \u2502\n\u2502 Cyril535       \u2502 Abbott774 \u2502 M       \u2502 Millis       \u2502\n\u2502 Lorette239     \u2502 Abbott774 \u2502 F       \u2502 Dennis       \u2502\n\u2502 Jimmy858       \u2502 Abbott774 \u2502 M       \u2502 Lowell       \u2502\n\u2502 Laine739       \u2502 Abbott774 \u2502 F       \u2502 Agawam       \u2502\n\u2502 Bernetta267    \u2502 Abbott774 \u2502 F       \u2502 Ware         \u2502\n\u2502 Lauri399       \u2502 Abbott774 \u2502 F       \u2502 Springfield  \u2502\n\u2502 Miesha237      \u2502 Abbott774 \u2502 F       \u2502 Stoneham     \u2502\n\u2502 Darrin898      \u2502 Abbott774 \u2502 M       \u2502 Newton       \u2502\n\u2502 Grant908       \u2502 Abbott774 \u2502 M       \u2502 Arlington    \u2502\n\u2502 Arden380       \u2502 Abbott774 \u2502 M       \u2502 Worcester    \u2502\n\u2502 German382      \u2502 Abbott774 \u2502 M       \u2502 Taunton      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 20 rows                                   4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#order-by-and-desc","title":"ORDER BY and DESC","text":"<p>This query returns the first 20 patients from the patients table, ordered reverse alphabetically by their first name. <pre><code>conn.sql(\"SELECT FIRST, LAST, GENDER, CITY FROM patients ORDER BY FIRST DESC LIMIT 20;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  FIRST   \u2502      LAST      \u2502 GENDER  \u2502    CITY    \u2502\n\u2502 varchar  \u2502    varchar     \u2502 varchar \u2502  varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u00d3scar156 \u2502 Ballesteros368 \u2502 M       \u2502 Taunton    \u2502\n\u2502 \u00d3scar156 \u2502 Curiel392      \u2502 M       \u2502 Swampscott \u2502\n\u2502 \u00d3scar156 \u2502 Zelaya592      \u2502 M       \u2502 Lynn       \u2502\n\u2502 \u00d3scar156 \u2502 Puente961      \u2502 M       \u2502 Greenfield \u2502\n\u2502 \u00d3scar156 \u2502 Olivas524      \u2502 M       \u2502 Norwell    \u2502\n\u2502 \u00d3scar156 \u2502 Rivero165      \u2502 M       \u2502 Lancaster  \u2502\n\u2502 \u00d3scar156 \u2502 Canales95      \u2502 M       \u2502 Hamilton   \u2502\n\u2502 \u00d3scar156 \u2502 Romero158      \u2502 M       \u2502 Boston     \u2502\n\u2502 \u00d3scar156 \u2502 Garza151       \u2502 M       \u2502 Longmeadow \u2502\n\u2502 \u00d3scar156 \u2502 Delgado712     \u2502 M       \u2502 Haverhill  \u2502\n\u2502 \u00d3scar156 \u2502 Ure\u00f1a88        \u2502 M       \u2502 Bedford    \u2502\n\u2502 \u00d3scar156 \u2502 Henr\u00edquez109   \u2502 M       \u2502 Boxborough \u2502\n\u2502 \u00d3scar156 \u2502 Guerrero997    \u2502 M       \u2502 Boston     \u2502\n\u2502 \u00d3scar156 \u2502 Ojeda263       \u2502 M       \u2502 Boston     \u2502\n\u2502 \u00d3scar156 \u2502 Mel\u00e9ndez48     \u2502 M       \u2502 Newton     \u2502\n\u2502 \u00d3scar156 \u2502 Muro989        \u2502 M       \u2502 Boston     \u2502\n\u2502 \u00d3scar156 \u2502 Rend\u00f3n540      \u2502 M       \u2502 Wilbraham  \u2502\n\u2502 \u00d3scar156 \u2502 Santacruz647   \u2502 M       \u2502 Winthrop   \u2502\n\u2502 \u00d3scar156 \u2502 Santacruz647   \u2502 M       \u2502 Boston     \u2502\n\u2502 \u00d3scar156 \u2502 Otero621       \u2502 M       \u2502 Boston     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 20 rows                                4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#aggregating-data-using-group-by","title":"Aggregating Data using GROUP BY","text":""},{"location":"11_sql_duckdb/#counting-patients-by-city","title":"Counting Patients by City","text":"<p><pre><code>conn.sql(\"SELECT CITY, COUNT(*) AS patient_count FROM patients GROUP BY CITY;\") ## each run gives random order\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    CITY     \u2502 patient_count \u2502\n\u2502   varchar   \u2502     int64     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Dartmouth   \u2502           656 \u2502\n\u2502 Fitchburg   \u2502           743 \u2502\n\u2502 Plymouth    \u2502           972 \u2502\n\u2502 Worcester   \u2502          3263 \u2502\n\u2502 Beverly     \u2502           778 \u2502\n\u2502 Westfield   \u2502           781 \u2502\n\u2502 Hingham     \u2502           431 \u2502\n\u2502 Rochester   \u2502           103 \u2502\n\u2502 Sandwich    \u2502           387 \u2502\n\u2502 Watertown   \u2502           534 \u2502\n\u2502    \u00b7        \u2502             \u00b7 \u2502\n\u2502    \u00b7        \u2502             \u00b7 \u2502\n\u2502    \u00b7        \u2502             \u00b7 \u2502\n\u2502 Ashfield    \u2502            29 \u2502\n\u2502 Pelham      \u2502            26 \u2502\n\u2502 Hancock     \u2502            22 \u2502\n\u2502 Monterey    \u2502            13 \u2502\n\u2502 Richmond    \u2502            23 \u2502\n\u2502 Hinsdale    \u2502            30 \u2502\n\u2502 Middlefield \u2502            11 \u2502\n\u2502 Westhampton \u2502            14 \u2502\n\u2502 Sandisfield \u2502            12 \u2502\n\u2502 Monroe      \u2502             2 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     351 rows (20 shown)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#counting-patients-by-city-and-sorting-them-highest-to-lowest","title":"Counting Patients by City and sorting them highest to lowest","text":"<p><pre><code>conn.sql(\"SELECT CITY, COUNT(*) AS patient_count FROM patients GROUP BY CITY ORDER BY patient_count DESC;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    CITY     \u2502 patient_count \u2502\n\u2502   varchar   \u2502     int64     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Boston      \u2502         11496 \u2502\n\u2502 Worcester   \u2502          3263 \u2502\n\u2502 Springfield \u2502          2814 \u2502\n\u2502 Cambridge   \u2502          2044 \u2502\n\u2502 Lowell      \u2502          2027 \u2502\n\u2502 Brockton    \u2502          1833 \u2502\n\u2502 Lynn        \u2502          1714 \u2502\n\u2502 New Bedford \u2502          1706 \u2502\n\u2502 Quincy      \u2502          1698 \u2502\n\u2502 Newton      \u2502          1695 \u2502\n\u2502   \u00b7         \u2502             \u00b7 \u2502\n\u2502   \u00b7         \u2502             \u00b7 \u2502\n\u2502   \u00b7         \u2502             \u00b7 \u2502\n\u2502 Blandford   \u2502            10 \u2502\n\u2502 Heath       \u2502             8 \u2502\n\u2502 Tolland     \u2502             7 \u2502\n\u2502 Hawley      \u2502             6 \u2502\n\u2502 Alford      \u2502             5 \u2502\n\u2502 New Ashford \u2502             4 \u2502\n\u2502 Aquinnah    \u2502             4 \u2502\n\u2502 Tyringham   \u2502             3 \u2502\n\u2502 Monroe      \u2502             2 \u2502\n\u2502 Gosnold     \u2502             1 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     351 rows (20 shown)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#total-number-of-patients-by-gender-in-each-city","title":"Total Number of Patients by Gender in Each City","text":"<p><pre><code>conn.sql(\"SELECT CITY, GENDER, COUNT(*) AS total_patients FROM patients GROUP BY CITY, GENDER ORDER BY total_patients DESC LIMIT 10;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    CITY     \u2502 GENDER  \u2502 total_patients \u2502\n\u2502   varchar   \u2502 varchar \u2502     int64      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Boston      \u2502 F       \u2502           5840 \u2502\n\u2502 Boston      \u2502 M       \u2502           5656 \u2502\n\u2502 Worcester   \u2502 M       \u2502           1694 \u2502\n\u2502 Worcester   \u2502 F       \u2502           1569 \u2502\n\u2502 Springfield \u2502 M       \u2502           1463 \u2502\n\u2502 Springfield \u2502 F       \u2502           1351 \u2502\n\u2502 Cambridge   \u2502 M       \u2502           1023 \u2502\n\u2502 Cambridge   \u2502 F       \u2502           1021 \u2502\n\u2502 Lowell      \u2502 F       \u2502           1015 \u2502\n\u2502 Lowell      \u2502 M       \u2502           1012 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 10 rows                      3 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Lets look at other Tables - observations and  immunizations <pre><code>conn.sql(\"SELECT PATIENT,ENCOUNTER,CODE, DESCRIPTION, VALUE  from observations;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       PATIENT        \u2502      ENCOUNTER       \u2502  CODE   \u2502                  DESCRIPTION                  \u2502    VALUE     \u2502\n\u2502       varchar        \u2502       varchar        \u2502 varchar \u2502                    varchar                    \u2502   varchar    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1ff7f10f-a204-4bb1\u2026  \u2502 52051c30-c6c3-45fe\u2026  \u2502 8302-2  \u2502 Body Height                                   \u2502 82.7         \u2502\n\u2502 1ff7f10f-a204-4bb1\u2026  \u2502 52051c30-c6c3-45fe\u2026  \u2502 72514-3 \u2502 Pain severity - 0-10 verbal numeric rating \u2026  \u2502 2.0          \u2502\n\u2502 1ff7f10f-a204-4bb1\u2026  \u2502 52051c30-c6c3-45fe\u2026  \u2502 29463-7 \u2502 Body Weight                                   \u2502 11.5         \u2502\n\u2502 1ff7f10f-a204-4bb1\u2026  \u2502 52051c30-c6c3-45fe\u2026  \u2502 77606-2 \u2502 Weight-for-length Per age and sex             \u2502 47.0         \u2502\n\u2502 1ff7f10f-a204-4bb1\u2026  \u2502 52051c30-c6c3-45fe\u2026  \u2502 9843-4  \u2502 Head Occipital-frontal circumference          \u2502 46.9         \u2502\n\u2502 1ff7f10f-a204-4bb1\u2026  \u2502 52051c30-c6c3-45fe\u2026  \u2502 8462-4  \u2502 Diastolic Blood Pressure                      \u2502 76.0         \u2502\n\u2502 1ff7f10f-a204-4bb1\u2026  \u2502 52051c30-c6c3-45fe\u2026  \u2502 8480-6  \u2502 Systolic Blood Pressure                       \u2502 107.0        \u2502\n\u2502 1ff7f10f-a204-4bb1\u2026  \u2502 52051c30-c6c3-45fe\u2026  \u2502 8867-4  \u2502 Heart rate                                    \u2502 68.0         \u2502\n\u2502 1ff7f10f-a204-4bb1\u2026  \u2502 52051c30-c6c3-45fe\u2026  \u2502 9279-1  \u2502 Respiratory rate                              \u2502 13.0         \u2502\n\u2502 1ff7f10f-a204-4bb1\u2026  \u2502 52051c30-c6c3-45fe\u2026  \u2502 72166-2 \u2502 Tobacco smoking status NHIS                   \u2502 Never smoker \u2502\n\u2502          \u00b7           \u2502          \u00b7           \u2502   \u00b7     \u2502              \u00b7                                \u2502  \u00b7           \u2502\n\u2502          \u00b7           \u2502          \u00b7           \u2502   \u00b7     \u2502              \u00b7                                \u2502  \u00b7           \u2502\n\u2502          \u00b7           \u2502          \u00b7           \u2502   \u00b7     \u2502              \u00b7                                \u2502  \u00b7           \u2502\n\u2502 87537cb1-92e1-4a11\u2026  \u2502 69e8eaf0-7714-4c20\u2026  \u2502 2160-0  \u2502 Creatinine [Mass/volume] in Serum or Plasma   \u2502 2.9          \u2502\n\u2502 87537cb1-92e1-4a11\u2026  \u2502 69e8eaf0-7714-4c20\u2026  \u2502 17861-6 \u2502 Calcium [Mass/volume] in Serum or Plasma      \u2502 9.2          \u2502\n\u2502 87537cb1-92e1-4a11\u2026  \u2502 69e8eaf0-7714-4c20\u2026  \u2502 2951-2  \u2502 Sodium [Moles/volume] in Serum or Plasma      \u2502 143.8        \u2502\n\u2502 87537cb1-92e1-4a11\u2026  \u2502 69e8eaf0-7714-4c20\u2026  \u2502 2823-3  \u2502 Potassium [Moles/volume] in Serum or Plasma   \u2502 4.3          \u2502\n\u2502 87537cb1-92e1-4a11\u2026  \u2502 69e8eaf0-7714-4c20\u2026  \u2502 2075-0  \u2502 Chloride [Moles/volume] in Serum or Plasma    \u2502 106.4        \u2502\n\u2502 87537cb1-92e1-4a11\u2026  \u2502 69e8eaf0-7714-4c20\u2026  \u2502 2028-9  \u2502 Carbon dioxide  total [Moles/volume] in Ser\u2026  \u2502 22.9         \u2502\n\u2502 87537cb1-92e1-4a11\u2026  \u2502 69e8eaf0-7714-4c20\u2026  \u2502 33914-3 \u2502 Glomerular filtration rate/1.73 sq M.predic\u2026  \u2502 9.9          \u2502\n\u2502 87537cb1-92e1-4a11\u2026  \u2502 69e8eaf0-7714-4c20\u2026  \u2502 2885-2  \u2502 Protein [Mass/volume] in Serum or Plasma      \u2502 5.7          \u2502\n\u2502 87537cb1-92e1-4a11\u2026  \u2502 69e8eaf0-7714-4c20\u2026  \u2502 1751-7  \u2502 Albumin [Mass/volume] in Serum or Plasma      \u2502 5.2          \u2502\n\u2502 87537cb1-92e1-4a11\u2026  \u2502 69e8eaf0-7714-4c20\u2026  \u2502 1975-2  \u2502 Bilirubin.total [Mass/volume] in Serum or P\u2026  \u2502 14.2         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 20 shown)                                                                              5 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#average-heart-rate-by-patient","title":"Average Heart Rate by Patient","text":"<p><pre><code>conn.sql(\"SELECT PATIENT, ROUND(AVG(CAST(VALUE AS DECIMAL(10,6))), 2) AS average_heart_rate FROM observations WHERE DESCRIPTION LIKE '%Heart rate%' GROUP BY PATIENT ORDER BY average_heart_rate DESC LIMIT 20;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               PATIENT                \u2502 average_heart_rate \u2502\n\u2502               varchar                \u2502       double       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ff2209f2-a4c9-4737-9aa7-adc8d71b6961 \u2502              200.0 \u2502\n\u2502 8cea2d7e-6227-4924-a340-18eafb8564ac \u2502              200.0 \u2502\n\u2502 6ec823e7-839e-4491-8b6f-6b275951b456 \u2502              200.0 \u2502\n\u2502 0191f8aa-96dc-41e6-b718-312686a7a867 \u2502              200.0 \u2502\n\u2502 c10db4e1-de51-495f-98ab-8322c6d9550a \u2502              200.0 \u2502\n\u2502 46ea7226-63f6-404f-bbed-904ea39f706d \u2502              199.9 \u2502\n\u2502 ec1ce32c-57a3-44c4-8f64-e050f2f94e03 \u2502              199.9 \u2502\n\u2502 a05e3bd1-1c51-453a-9969-646cb0168d23 \u2502              199.9 \u2502\n\u2502 9cc52681-4446-4e4a-80be-63418dd06e66 \u2502              199.9 \u2502\n\u2502 b0112890-a24a-4564-b2b3-9b77879e5e79 \u2502              199.9 \u2502\n\u2502 18f53179-2449-47af-b4da-a9e51095076f \u2502              199.9 \u2502\n\u2502 c3d165d2-597e-45a8-8331-f3338ce19fdf \u2502              199.9 \u2502\n\u2502 04dd3439-2116-4f9a-b40e-a84395cf6f21 \u2502              199.9 \u2502\n\u2502 371e14a1-31bd-4407-bdbb-4078781fde05 \u2502              199.8 \u2502\n\u2502 3e5c63bf-65fe-48bb-8361-6b21a909888a \u2502              199.8 \u2502\n\u2502 423f79cf-f7b8-41cd-bb3c-8459084f88eb \u2502              199.8 \u2502\n\u2502 2d4f57ee-4001-44f8-9a94-c1885f26b408 \u2502              199.8 \u2502\n\u2502 bd6784c0-3529-4a12-87bd-746affb17739 \u2502              199.8 \u2502\n\u2502 ef43848b-a4f1-4c45-a106-5928e29b72f2 \u2502              199.7 \u2502\n\u2502 1d050245-097c-44a5-b29b-6a18a22731e9 \u2502              199.7 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 20 rows                                         2 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#count-of-heart-rate-records-by-patient","title":"Count of Heart Rate Records by Patient","text":"<p><pre><code>conn.sql(\"SELECT PATIENT, COUNT(*) AS heart_rate_records FROM observations WHERE DESCRIPTION LIKE '%Heart rate%' GROUP BY PATIENT ORDER BY heart_rate_records DESC LIMIT 20;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               PATIENT                \u2502 heart_rate_records \u2502\n\u2502               varchar                \u2502       int64        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 3e21a156-da54-4fb7-815e-550fdf4afbbd \u2502                 33 \u2502\n\u2502 ffbf0392-1643-4b05-819f-489072c8c4d4 \u2502                 30 \u2502\n\u2502 b9ef6005-438e-4b47-afaf-9dba32184adf \u2502                 30 \u2502\n\u2502 f8080701-2b5c-4128-9a7f-9a098b737b27 \u2502                 30 \u2502\n\u2502 a2172279-3d63-4d14-867d-1a39d9280690 \u2502                 30 \u2502\n\u2502 01a5a5a6-ef7b-42ba-899c-de66e1b1e27e \u2502                 30 \u2502\n\u2502 62572c44-a802-40d1-8d60-d02bc287d548 \u2502                 30 \u2502\n\u2502 445953fd-15fa-424e-9926-f93ebf1bca7a \u2502                 30 \u2502\n\u2502 c3ea3c46-f8d1-4abe-8fb2-8fc8f86b4ef4 \u2502                 29 \u2502\n\u2502 bd18ba0d-2e65-4427-98f1-cbfc09dbaa33 \u2502                 29 \u2502\n\u2502 5736b489-0e15-4693-b9d6-05192a702a2d \u2502                 29 \u2502\n\u2502 b5a0b060-96ae-44d5-bd10-f532a445009b \u2502                 29 \u2502\n\u2502 ee9b44a1-36c6-456e-b77c-cd200611ca0f \u2502                 29 \u2502\n\u2502 0d5290dd-a3e3-4a81-91d5-6e722e58ec3e \u2502                 29 \u2502\n\u2502 54ec8b8e-fe2a-4cf5-a087-1a65df1ab1b8 \u2502                 29 \u2502\n\u2502 e658626d-0f72-4570-8071-2dd63827a24c \u2502                 29 \u2502\n\u2502 ec3f3da2-09a1-43c7-8cae-ed34847d2534 \u2502                 28 \u2502\n\u2502 c7bd54b1-e036-4702-9062-acfa3677a6e8 \u2502                 28 \u2502\n\u2502 8b6ee161-eb5f-413a-8e86-f5b3adb3f5ff \u2502                 28 \u2502\n\u2502 03c1210e-d145-4aed-9522-14cff41b3c28 \u2502                 28 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 20 rows                                         2 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#total-cost-of-vaccinations-per-patient","title":"Total Cost of Vaccinations per Patient","text":"<p><pre><code>conn.sql(\"SELECT PATIENT, SUM(BASE_COST) AS total_cost FROM immunizations GROUP BY PATIENT ORDER BY total_cost DESC;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               PATIENT                \u2502 total_cost \u2502\n\u2502               varchar                \u2502   double   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 8eacdc17-de2f-4024-88bd-976401b30979 \u2502     2810.4 \u2502\n\u2502 bb14de6a-c77d-44bb-a3a8-338a6a246520 \u2502     2810.4 \u2502\n\u2502 a5b60d43-9776-4811-badf-67d49edbc175 \u2502     2810.4 \u2502\n\u2502 1c8a4026-5dbe-478a-b647-ecb605775977 \u2502     2810.4 \u2502\n\u2502 3e38e20b-6dd8-44fe-9ed3-81e1e3d8e2ab \u2502     2810.4 \u2502\n\u2502 e23c7c68-0319-41f5-90d9-1db160321a94 \u2502     2810.4 \u2502\n\u2502 49e7d878-93a6-4e71-971b-213abacf2235 \u2502     2810.4 \u2502\n\u2502 7ded4116-1783-4a93-9bb2-7a65370f55f5 \u2502     2810.4 \u2502\n\u2502 594660e4-6a02-4e3c-a8b9-2c61d4d4af60 \u2502     2810.4 \u2502\n\u2502 fee1edbd-277d-4b12-901e-60b6135cf877 \u2502     2810.4 \u2502\n\u2502                  \u00b7                   \u2502        \u00b7   \u2502\n\u2502                  \u00b7                   \u2502        \u00b7   \u2502\n\u2502                  \u00b7                   \u2502        \u00b7   \u2502\n\u2502 594d1ecb-b1a4-4bad-9ccd-5cebceebd6f5 \u2502     281.04 \u2502\n\u2502 456fa9f9-7eb7-4316-a74b-5a9ff87f8fc5 \u2502     281.04 \u2502\n\u2502 52568520-7163-429d-bc90-fc245debb697 \u2502     281.04 \u2502\n\u2502 30a16a19-ee93-4bfd-b1ed-bba90de36266 \u2502     281.04 \u2502\n\u2502 0ef633b0-2996-44c5-936c-600820310223 \u2502     281.04 \u2502\n\u2502 613319c8-2b76-494b-86b8-e776a2ee5e0b \u2502     281.04 \u2502\n\u2502 4dceeb57-4fe3-4c32-a748-621df5ce3c30 \u2502     281.04 \u2502\n\u2502 93d590e8-9f3e-4741-bee2-9b8e9e8b21e7 \u2502     281.04 \u2502\n\u2502 bad20ffc-48f9-4a7d-a2be-39a50fa4e0ac \u2502     281.04 \u2502\n\u2502 3cf75ec3-5e1c-4783-bb20-282a8cf66f30 \u2502     281.04 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 20 shown)           2 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#top-10-most-common-vaccine-administered","title":"Top 10 Most Common Vaccine Administered","text":"<p><pre><code>conn.sql(\"SELECT DESCRIPTION, COUNT(*) AS count FROM immunizations GROUP BY DESCRIPTION ORDER BY count DESC LIMIT 10;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DESCRIPTION                     \u2502 count  \u2502\n\u2502                      varchar                       \u2502 int64  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Influenza  seasonal  injectable  preservative free \u2502 106564 \u2502\n\u2502 Td (adult) preservative free                       \u2502   9815 \u2502\n\u2502 Pneumococcal conjugate PCV 13                      \u2502   5747 \u2502\n\u2502 DTaP                                               \u2502   5735 \u2502\n\u2502 IPV                                                \u2502   4962 \u2502\n\u2502 meningococcal MCV4P                                \u2502   4010 \u2502\n\u2502 Hib (PRP-OMP)                                      \u2502   3615 \u2502\n\u2502 HPV  quadrivalent                                  \u2502   3494 \u2502\n\u2502 Hep B  adolescent or pediatric                     \u2502   3490 \u2502\n\u2502 zoster                                             \u2502   3469 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 10 rows                                           2 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#joins","title":"JOINS","text":""},{"location":"11_sql_duckdb/#sql-joins-are-used-to-combine-rows-from-two-or-more-tables-based-on-a-related-column-between-them-there-are-several-types-of-joins-in-sql-each-serving-different-purposes-depending-on-how-you-want-to-combine-your-data","title":"SQL joins are used to combine rows from two or more tables, based on a related column between them. There are several types of joins in SQL, each serving different purposes depending on how you want to combine your data.","text":"<p>  - credit: educba.com</p> <p>For the following examples: Left table: Patients and Right Table: Immunizations</p> <p>__</p>"},{"location":"11_sql_duckdb/#inner-join","title":"INNER JOIN","text":"<ul> <li> <p>The Inner join returns rows when there is at least one match in both tables. If there is no match, the rows are not returned.</p> </li> <li> <p>Find Matching Records: Question: Which medical treatments have been administered to patients, including the patient's name and the cost of each treatment? <pre><code>conn.sql(\"SELECT patients.FIRST, patients.LAST, immunizations.DESCRIPTION, immunizations.BASE_COST FROM immunizations INNER JOIN patients ON immunizations.PATIENT = patients.Id ORDER BY patients.FIRST ASC;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  FIRST   \u2502     LAST      \u2502                    DESCRIPTION                     \u2502 BASE_COST \u2502\n\u2502 varchar  \u2502    varchar    \u2502                      varchar                       \u2502  double   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Aaron697 \u2502 Cummings51    \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697 \u2502 Crooks415     \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697 \u2502 Anderson154   \u2502 Pneumococcal conjugate PCV 13                      \u2502    140.52 \u2502\n\u2502 Aaron697 \u2502 Hartmann983   \u2502 Hep B  adolescent or pediatric                     \u2502    140.52 \u2502\n\u2502 Aaron697 \u2502 Thompson596   \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697 \u2502 Rodriguez71   \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697 \u2502 Deckow585     \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697 \u2502 Swaniawski813 \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697 \u2502 Beer512       \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697 \u2502 Ullrich385    \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502    \u00b7     \u2502     \u00b7         \u2502                         \u00b7                          \u2502       \u00b7   \u2502\n\u2502    \u00b7     \u2502     \u00b7         \u2502                         \u00b7                          \u2502       \u00b7   \u2502\n\u2502    \u00b7     \u2502     \u00b7         \u2502                         \u00b7                          \u2502       \u00b7   \u2502\n\u2502 Ariel183 \u2502 Schuster709   \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Ariel183 \u2502 Mohr916       \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Ariel183 \u2502 Waters156     \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Ariel183 \u2502 Will178       \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Ariel183 \u2502 Leffler128    \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Ariel183 \u2502 Bode78        \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Ariel183 \u2502 Grady603      \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Ariel183 \u2502 Funk324       \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Ariel183 \u2502 McGlynn426    \u2502 Td (adult) preservative free                       \u2502    140.52 \u2502\n\u2502 Ariel183 \u2502 Boehm581      \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 20 shown)                                                   4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> </li> </ul>"},{"location":"11_sql_duckdb/#left-join","title":"LEFT JOIN","text":"<ul> <li>It returns all rows from the left table, and the matched rows from the right table. The result is NULL from the right side, if there is no match. Question: For all patients, what treatments have they received, if any? <pre><code>conn.sql(\"SELECT patients.FIRST, patients.LAST, immunizations.DESCRIPTION, immunizations.BASE_COST FROM patients LEFT JOIN immunizations ON patients.Id = immunizations.PATIENT ORDER BY patients.FIRST ASC;\")\n</code></pre> <pre><code>conn.sql(\"SELECT patients.FIRST, patients.LAST, immunizations.DESCRIPTION, immunizations.BASE_COST FROM patients LEFT JOIN immunizations ON patients.Id = immunizations.PATIENT ORDER BY patients.FIRST ASC;\")\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   FIRST   \u2502    LAST     \u2502                    DESCRIPTION                     \u2502 BASE_COST \u2502\n\u2502  varchar  \u2502   varchar   \u2502                      varchar                       \u2502  double   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Aaron697  \u2502 Legros616   \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Deckow585   \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Thompson596 \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Auer97      \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Crooks415   \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Crooks415   \u2502 Td (adult) preservative free                       \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Volkman526  \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Hartmann983 \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Orn563      \u2502 NULL                                               \u2502      NULL \u2502\n\u2502 Aaron697  \u2502 Hartmann983 \u2502 IPV                                                \u2502    140.52 \u2502\n\u2502    \u00b7      \u2502     \u00b7       \u2502  \u00b7                                                 \u2502       \u00b7   \u2502\n\u2502    \u00b7      \u2502     \u00b7       \u2502  \u00b7                                                 \u2502       \u00b7   \u2502\n\u2502    \u00b7      \u2502     \u00b7       \u2502  \u00b7                                                 \u2502       \u00b7   \u2502\n\u2502 Antonia30 \u2502 Goodwin327  \u2502 HPV  quadrivalent                                  \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 Funk324     \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 West559     \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 Lowe577     \u2502 NULL                                               \u2502      NULL \u2502\n\u2502 Antonia30 \u2502 D'Amore443  \u2502 Pneumococcal conjugate PCV 13                      \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 Montes106   \u2502 meningococcal MCV4P                                \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 Gonz\u00e1lez124 \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 Franecki195 \u2502 zoster                                             \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 Rojo930     \u2502 Pneumococcal conjugate PCV 13                      \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 Puente961   \u2502 HPV  quadrivalent                                  \u2502    140.52 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 20 shown)                                                  4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></li> </ul>"},{"location":"11_sql_duckdb/#right-join","title":"RIGHT JOIN","text":"<ul> <li>It returns all rows from the right table, and the matched rows from the left table. The result is NULL from the left side, if there is no match. Question: For all Immunizations recorded, which patients received them, if identifiable?</li> </ul> <p><pre><code>conn.sql(\"SELECT patients.FIRST, patients.LAST, immunizations.DESCRIPTION, immunizations.BASE_COST FROM patients RIGHT JOIN immunizations ON patients.Id = immunizations.PATIENT ORDER BY immunizations.DESCRIPTION;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     FIRST      \u2502     LAST     \u2502 DESCRIPTION  \u2502 BASE_COST \u2502\n\u2502    varchar     \u2502   varchar    \u2502   varchar    \u2502  double   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Shantay950     \u2502 Quitzon246   \u2502 DTaP         \u2502    140.52 \u2502\n\u2502 Cleveland582   \u2502 VonRueden376 \u2502 DTaP         \u2502    140.52 \u2502\n\u2502 Flo729         \u2502 Quigley282   \u2502 DTaP         \u2502    140.52 \u2502\n\u2502 Flo729         \u2502 Quigley282   \u2502 DTaP         \u2502    140.52 \u2502\n\u2502 Werner409      \u2502 Schaden604   \u2502 DTaP         \u2502    140.52 \u2502\n\u2502 Pasty639       \u2502 Ortiz186     \u2502 DTaP         \u2502    140.52 \u2502\n\u2502 Pasty639       \u2502 Ortiz186     \u2502 DTaP         \u2502    140.52 \u2502\n\u2502 Angelica442    \u2502 Kovacek682   \u2502 DTaP         \u2502    140.52 \u2502\n\u2502 Cathie710      \u2502 Hegmann834   \u2502 DTaP         \u2502    140.52 \u2502\n\u2502 Pasty639       \u2502 Ortiz186     \u2502 DTaP         \u2502    140.52 \u2502\n\u2502   \u00b7            \u2502    \u00b7         \u2502  \u00b7           \u2502       \u00b7   \u2502\n\u2502   \u00b7            \u2502    \u00b7         \u2502  \u00b7           \u2502       \u00b7   \u2502\n\u2502   \u00b7            \u2502    \u00b7         \u2502  \u00b7           \u2502       \u00b7   \u2502\n\u2502 Art115         \u2502 Roberts511   \u2502 Hep A  adult \u2502    140.52 \u2502\n\u2502 Christopher407 \u2502 Davis923     \u2502 Hep A  adult \u2502    140.52 \u2502\n\u2502 Michiko564     \u2502 Dooley940    \u2502 Hep A  adult \u2502    140.52 \u2502\n\u2502 Celine582      \u2502 Sipes176     \u2502 Hep A  adult \u2502    140.52 \u2502\n\u2502 Darci883       \u2502 Miller503    \u2502 Hep A  adult \u2502    140.52 \u2502\n\u2502 Ethan766       \u2502 Morar593     \u2502 Hep A  adult \u2502    140.52 \u2502\n\u2502 Georgiann138   \u2502 Heathcote539 \u2502 Hep A  adult \u2502    140.52 \u2502\n\u2502 Herbert830     \u2502 Wolff180     \u2502 Hep A  adult \u2502    140.52 \u2502\n\u2502 Ismael683      \u2502 King743      \u2502 Hep A  adult \u2502    140.52 \u2502\n\u2502 Ellsworth48    \u2502 Mertz280     \u2502 Hep A  adult \u2502    140.52 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 20 shown)                  4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#full-outer-join","title":"FULL OUTER JOIN","text":"<ul> <li>It returns rows when there is a match in one of the tables. It effectively combines the results of both LEFT JOIN and RIGHT JOIN. Question: What is the complete list of patients and their Immunizations, including those without recorded treatments or identifiable patients?</li> </ul> <p><pre><code>conn.sql(\"SELECT patients.FIRST, patients.LAST, immunizations.DESCRIPTION, immunizations.BASE_COST FROM patients FULL OUTER JOIN immunizations ON patients.Id = immunizations.PATIENT ORDER BY patients.FIRST ASC;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   FIRST   \u2502    LAST     \u2502                    DESCRIPTION                     \u2502 BASE_COST \u2502\n\u2502  varchar  \u2502   varchar   \u2502                      varchar                       \u2502  double   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Aaron697  \u2502 Legros616   \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Deckow585   \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Thompson596 \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Auer97      \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Crooks415   \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Crooks415   \u2502 Td (adult) preservative free                       \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Volkman526  \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Hartmann983 \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Aaron697  \u2502 Orn563      \u2502 NULL                                               \u2502      NULL \u2502\n\u2502 Aaron697  \u2502 Hartmann983 \u2502 IPV                                                \u2502    140.52 \u2502\n\u2502    \u00b7      \u2502     \u00b7       \u2502  \u00b7                                                 \u2502       \u00b7   \u2502\n\u2502    \u00b7      \u2502     \u00b7       \u2502  \u00b7                                                 \u2502       \u00b7   \u2502\n\u2502    \u00b7      \u2502     \u00b7       \u2502  \u00b7                                                 \u2502       \u00b7   \u2502\n\u2502 Antonia30 \u2502 Goodwin327  \u2502 HPV  quadrivalent                                  \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 Funk324     \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 West559     \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 Lowe577     \u2502 NULL                                               \u2502      NULL \u2502\n\u2502 Antonia30 \u2502 D'Amore443  \u2502 Pneumococcal conjugate PCV 13                      \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 Montes106   \u2502 meningococcal MCV4P                                \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 Gonz\u00e1lez124 \u2502 Influenza  seasonal  injectable  preservative free \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 Franecki195 \u2502 zoster                                             \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 Rojo930     \u2502 Pneumococcal conjugate PCV 13                      \u2502    140.52 \u2502\n\u2502 Antonia30 \u2502 Puente961   \u2502 HPV  quadrivalent                                  \u2502    140.52 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 20 shown)                                                  4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#cross-join","title":"CROSS JOIN","text":"<ul> <li>It returns a Cartesian product of the two tables, i.e., it returns rows combining each row from the first table with each row from the second table. Question: What are all possible combinations of patients and immunizations? <pre><code>conn.sql(\"SELECT patients.FIRST, patients.LAST, immunizations.DESCRIPTION FROM patients CROSS JOIN immunizations;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   FIRST   \u2502    LAST     \u2502                    DESCRIPTION                     \u2502\n\u2502  varchar  \u2502   varchar   \u2502                      varchar                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Tammy740  \u2502 Ernser583   \u2502 Influenza  seasonal  injectable  preservative free \u2502\n\u2502 Tammy740  \u2502 Ernser583   \u2502 Hep A  ped/adol  2 dose                            \u2502\n\u2502 Tammy740  \u2502 Ernser583   \u2502 Influenza  seasonal  injectable  preservative free \u2502\n\u2502 Tammy740  \u2502 Ernser583   \u2502 Influenza  seasonal  injectable  preservative free \u2502\n\u2502 Tammy740  \u2502 Ernser583   \u2502 meningococcal MCV4P                                \u2502\n\u2502 Tammy740  \u2502 Ernser583   \u2502 Hep B  adolescent or pediatric                     \u2502\n\u2502 Tammy740  \u2502 Ernser583   \u2502 Hep B  adolescent or pediatric                     \u2502\n\u2502 Tammy740  \u2502 Ernser583   \u2502 Hib (PRP-OMP)                                      \u2502\n\u2502 Tammy740  \u2502 Ernser583   \u2502 rotavirus  monovalent                              \u2502\n\u2502 Tammy740  \u2502 Ernser583   \u2502 IPV                                                \u2502\n\u2502    \u00b7      \u2502     \u00b7       \u2502  \u00b7                                                 \u2502\n\u2502    \u00b7      \u2502     \u00b7       \u2502  \u00b7                                                 \u2502\n\u2502    \u00b7      \u2502     \u00b7       \u2502  \u00b7                                                 \u2502\n\u2502 Iliana226 \u2502 Schmeler639 \u2502 Influenza  seasonal  injectable  preservative free \u2502\n\u2502 Iliana226 \u2502 Schmeler639 \u2502 zoster                                             \u2502\n\u2502 Iliana226 \u2502 Schmeler639 \u2502 Influenza  seasonal  injectable  preservative free \u2502\n\u2502 Iliana226 \u2502 Schmeler639 \u2502 Influenza  seasonal  injectable  preservative free \u2502\n\u2502 Iliana226 \u2502 Schmeler639 \u2502 Influenza  seasonal  injectable  preservative free \u2502\n\u2502 Iliana226 \u2502 Schmeler639 \u2502 Influenza  seasonal  injectable  preservative free \u2502\n\u2502 Iliana226 \u2502 Schmeler639 \u2502 Influenza  seasonal  injectable  preservative free \u2502\n\u2502 Iliana226 \u2502 Schmeler639 \u2502 Influenza  seasonal  injectable  preservative free \u2502\n\u2502 Iliana226 \u2502 Schmeler639 \u2502 Influenza  seasonal  injectable  preservative free \u2502\n\u2502 Iliana226 \u2502 Schmeler639 \u2502 Influenza  seasonal  injectable  preservative free \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 20 shown)                                      3 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></li> </ul>"},{"location":"11_sql_duckdb/#self-join","title":"SELF JOIN","text":"<ul> <li>It is not a different type of join, but it's a regular join used to join a table to itself. It's useful for queries where you need to compare rows within the same table. Question: Which pair of patients are from the same city? <pre><code>conn.sql(\"SELECT A.FIRST AS FirstPatient, B.FIRST AS SecondPatient, A.CITY FROM patients A, patients B WHERE A.CITY = B.CITY AND A.Id != B.Id ORDER BY A.CITY ASC;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 FirstPatient \u2502 SecondPatient \u2502   CITY   \u2502\n\u2502   varchar    \u2502    varchar    \u2502 varchar  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Susan422     \u2502 Stefani254    \u2502 Abington \u2502\n\u2502 Jennell254   \u2502 Lionel365     \u2502 Abington \u2502\n\u2502 Robbie31     \u2502 Antonio44     \u2502 Abington \u2502\n\u2502 Joe656       \u2502 Antonio44     \u2502 Abington \u2502\n\u2502 Susan422     \u2502 Stevie682     \u2502 Abington \u2502\n\u2502 Shaun461     \u2502 Stevie682     \u2502 Abington \u2502\n\u2502 Shaun461     \u2502 Weston546     \u2502 Abington \u2502\n\u2502 Susan422     \u2502 Elwood28      \u2502 Abington \u2502\n\u2502 Susan422     \u2502 Daria61       \u2502 Abington \u2502\n\u2502 Shaun461     \u2502 Lita714       \u2502 Abington \u2502\n\u2502    \u00b7         \u2502    \u00b7          \u2502    \u00b7     \u2502\n\u2502    \u00b7         \u2502    \u00b7          \u2502    \u00b7     \u2502\n\u2502    \u00b7         \u2502    \u00b7          \u2502    \u00b7     \u2502\n\u2502 Elane105     \u2502 Conrad619     \u2502 Abington \u2502\n\u2502 Logan497     \u2502 Conrad619     \u2502 Abington \u2502\n\u2502 Sherlene302  \u2502 Conrad619     \u2502 Abington \u2502\n\u2502 Milan77      \u2502 Conrad619     \u2502 Abington \u2502\n\u2502 Frankie174   \u2502 Seema671      \u2502 Abington \u2502\n\u2502 Elane105     \u2502 Josefina523   \u2502 Abington \u2502\n\u2502 Lisha487     \u2502 Shawanna357   \u2502 Abington \u2502\n\u2502 Marleen824   \u2502 Marcelino726  \u2502 Abington \u2502\n\u2502 Sandi885     \u2502 Lionel365     \u2502 Abington \u2502\n\u2502 Morton637    \u2502 Viva686       \u2502 Abington \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      ? rows (&gt;9999 rows, 20 shown)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></li> </ul>"},{"location":"11_sql_duckdb/#introduction-to-subqueries-and-nested-selects","title":"Introduction to Subqueries and Nested Selects","text":"<ul> <li>Subqueries, also known as inner queries or nested queries, are SQL queries nested inside a larger query. They allow you to perform operations that usually require multiple steps in a single query, making your data retrieval process more efficient and concise. Nested selects are a type of subquery used specifically within the SELECT, FROM, or WHERE clauses to provide a dataset for the outer query to process.</li> <li>Subqueries can return a single value, a single row, multiple rows, or a table. They are used for comparison, as a condition, or to provide a list of values for the outer query. The main distinction between correlated and non-correlated subqueries is that correlated subqueries reference column(s) from the outer query, thus running once for each row selected by the outer query, while non-correlated subqueries run independently of the outer query and can be run as standalone queries.</li> </ul>"},{"location":"11_sql_duckdb/#types-of-subqueries","title":"Types of subqueries","text":"<ul> <li>Single-Row Subqueries: Single-row subqueries return only one row and are used with single row comparison operators like =, &gt;, &lt;, &gt;=, &lt;=. They are often used in the WHERE clause to compare a column value against the result of the subquery.</li> <li>Multi-Row Subqueries: Multi-row subqueries return more than one row and are used with operators like IN, ANY, ALL, which allow comparison against multiple values. They're useful for filtering based on a set of criteria returned by the subquery.</li> <li>Correlated Subqueries: Correlated subqueries reference column(s) from the outer query, making them dependent on the outer query. They are executed once for each row processed by the outer query, often leading to performance considerations.</li> </ul>"},{"location":"11_sql_duckdb/#use-subqueries-to-find-patients-based-on-specific-criteria","title":"Use subqueries to find patients based on specific criteria.","text":""},{"location":"11_sql_duckdb/#find-all-patients-who-have-been-prescribed-medication-with-a-base-cost-higher-than-the-average-base-cost-of-all-medications","title":"Find all patients who have been prescribed medication with a base cost higher than the average base cost of all medications.","text":"<p><pre><code>query = \"\"\"SELECT p.FIRST, p.LAST\nFROM patients p\nWHERE p.Id IN ( SELECT m.PATIENT FROM medications m WHERE m.BASE_COST &gt; (SELECT AVG(BASE_COST) FROM medications));\n\"\"\"\nconn.sql(query)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    FIRST    \u2502    LAST     \u2502\n\u2502   varchar   \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Dewitt635   \u2502 Reichel38   \u2502\n\u2502 Anisa442    \u2502 Purdy2      \u2502\n\u2502 Ross213     \u2502 Mayert710   \u2502\n\u2502 Jim478      \u2502 Mueller846  \u2502\n\u2502 Maria750    \u2502 Schimmel440 \u2502\n\u2502 Ignacio928  \u2502 Gorczany269 \u2502\n\u2502 Kip442      \u2502 Zboncak558  \u2502\n\u2502 Jean712     \u2502 Kuhlman484  \u2502\n\u2502 Mac103      \u2502 Moen819     \u2502\n\u2502 Dianna917   \u2502 Goldner995  \u2502\n\u2502     \u00b7       \u2502    \u00b7        \u2502\n\u2502     \u00b7       \u2502    \u00b7        \u2502\n\u2502     \u00b7       \u2502    \u00b7        \u2502\n\u2502 Cameron381  \u2502 Bogan287    \u2502\n\u2502 Andrew29    \u2502 Donnelly343 \u2502\n\u2502 Charis952   \u2502 Littel644   \u2502\n\u2502 Lyndon118   \u2502 Swift555    \u2502\n\u2502 Edward499   \u2502 Zieme486    \u2502\n\u2502 Myron933    \u2502 Ritchie586  \u2502\n\u2502 Yolonda722  \u2502 Champlin946 \u2502\n\u2502 Alayna598   \u2502 Kozey370    \u2502\n\u2502 Kristian973 \u2502 Ledner144   \u2502\n\u2502 Sydney660   \u2502 Zulauf375   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows          2 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#correlated-subqueries","title":"Correlated Subqueries","text":"<p>Learn how to use correlated subqueries to perform row-specific comparisons. Find patients whose healthcare expenses are higher than the average expenses in their county. <pre><code>query = \"\"\"SELECT\n    p.FIRST,\n    p.LAST,\n    p.COUNTY,\n    p.HEALTHCARE_EXPENSES,\n    ROUND(AVG_EXPENSES.COUNTY_AVG_EXPENSES, 2) AS ROUNDED_AVG_HEALTHCARE_EXPENSES\nFROM\n    patients p\nINNER JOIN (\n    SELECT\n        COUNTY,\n        AVG(CAST(HEALTHCARE_EXPENSES AS DECIMAL(20,6))) AS COUNTY_AVG_EXPENSES\n    FROM\n        patients\n    GROUP BY\n        COUNTY\n) AS AVG_EXPENSES ON p.COUNTY = AVG_EXPENSES.COUNTY\nWHERE\n    p.HEALTHCARE_EXPENSES &gt; (\n        SELECT AVG(p2.HEALTHCARE_EXPENSES)\n        FROM patients p2\n        WHERE p2.COUNTY = p.COUNTY\n    );\n\"\"\"\nconn.sql(query)\n</code></pre> <pre><code>query = \"\"\"SELECT\n    p.FIRST,\n    p.LAST,\n    p.COUNTY,\n    p.HEALTHCARE_EXPENSES,\n    ROUND(AVG_EXPENSES.COUNTY_AVG_EXPENSES, 2) AS ROUNDED_AVG_HEALTHCARE_EXPENSES\nFROM\n    patients p\nINNER JOIN (\n    SELECT\n\u2026        FROM patients p2\n        WHERE p2.COUNTY = p.COUNTY\n    );\n\"\"\"\nconn.sql(query)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   FIRST    \u2502     LAST      \u2502      COUNTY       \u2502 HEALTHCARE_EXPENSES \u2502 ROUNDED_AVG_HEALTHCARE_EXPENSES \u2502\n\u2502  varchar   \u2502    varchar    \u2502      varchar      \u2502       double        \u2502             double              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Tammy740   \u2502 Ernser583     \u2502 Bristol County    \u2502          1546025.67 \u2502                       793296.73 \u2502\n\u2502 Iliana226  \u2502 Schmeler639   \u2502 Barnstable County \u2502          1407960.93 \u2502                       949155.23 \u2502\n\u2502 Anthony633 \u2502 Yundt842      \u2502 Essex County      \u2502          1575731.48 \u2502                        814437.7 \u2502\n\u2502 Jim478     \u2502 Mueller846    \u2502 Bristol County    \u2502          1112473.78 \u2502                       793296.73 \u2502\n\u2502 Sina65     \u2502 Howell947     \u2502 Middlesex County  \u2502          1479425.58 \u2502                       841491.73 \u2502\n\u2502 Maria750   \u2502 Schimmel440   \u2502 Plymouth County   \u2502           952814.55 \u2502                        856778.1 \u2502\n\u2502 Lorenzo669 \u2502 Vandervort697 \u2502 Middlesex County  \u2502           873001.47 \u2502                       841491.73 \u2502\n\u2502 David908   \u2502 Carter549     \u2502 Worcester County  \u2502           834576.02 \u2502                       804752.74 \u2502\n\u2502 Noah480    \u2502 O'Reilly797   \u2502 Essex County      \u2502            915110.6 \u2502                        814437.7 \u2502\n\u2502 Kip442     \u2502 Zboncak558    \u2502 Middlesex County  \u2502  1704103.7200000002 \u2502                       841491.73 \u2502\n\u2502   \u00b7        \u2502     \u00b7         \u2502       \u00b7           \u2502               \u00b7     \u2502                           \u00b7     \u2502\n\u2502   \u00b7        \u2502     \u00b7         \u2502       \u00b7           \u2502               \u00b7     \u2502                           \u00b7     \u2502\n\u2502   \u00b7        \u2502     \u00b7         \u2502       \u00b7           \u2502               \u00b7     \u2502                           \u00b7     \u2502\n\u2502 Tinisha932 \u2502 Zulauf375     \u2502 Bristol County    \u2502          1035244.36 \u2502                       793296.73 \u2502\n\u2502 Mario764   \u2502 Estrada938    \u2502 Suffolk County    \u2502           1380401.5 \u2502                       664340.79 \u2502\n\u2502 Glenn0     \u2502 Schulist381   \u2502 Barnstable County \u2502           1357123.8 \u2502                       949155.23 \u2502\n\u2502 Porter490  \u2502 Schulist381   \u2502 Bristol County    \u2502          1534216.57 \u2502                       793296.73 \u2502\n\u2502 Darius626  \u2502 Hackett68     \u2502 Essex County      \u2502          1715140.52 \u2502                        814437.7 \u2502\n\u2502 Leonel449  \u2502 Kunze215      \u2502 Essex County      \u2502          1492352.86 \u2502                        814437.7 \u2502\n\u2502 Tyrell880  \u2502 Kassulke119   \u2502 Hampden County    \u2502          1053520.21 \u2502                       725636.71 \u2502\n\u2502 Arlen68    \u2502 Gusikowski974 \u2502 Worcester County  \u2502           1363289.9 \u2502                       804752.74 \u2502\n\u2502 Ashli227   \u2502 Huel628       \u2502 Worcester County  \u2502           813730.02 \u2502                       804752.74 \u2502\n\u2502 Loriann967 \u2502 Mertz280      \u2502 Norfolk County    \u2502          1618397.57 \u2502                       874351.83 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 20 shown)                                                                5 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Identify patients who have not been prescribed any medication. <pre><code>query = \"\"\"\nSELECT p.FIRST, p.LAST\nFROM patients p\nWHERE NOT EXISTS (\n    SELECT 1 FROM medications m WHERE m.PATIENT = p.Id\n);\n\"\"\"\n\nconn.sql(query)\n</code></pre> <pre><code>query = \"\"\"\nSELECT p.FIRST, p.LAST\nFROM patients p\nWHERE NOT EXISTS (\n    SELECT 1 FROM medications m WHERE m.PATIENT = p.Id\n);\n\"\"\"\n\nconn.sql(query)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   FIRST    \u2502     LAST      \u2502\n\u2502  varchar   \u2502    varchar    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Iliana226  \u2502 Schmeler639   \u2502\n\u2502 Toshiko149 \u2502 Swaniawski813 \u2502\n\u2502 Heath320   \u2502 Streich926    \u2502\n\u2502 Rana586    \u2502 Langworth352  \u2502\n\u2502 Dorathy429 \u2502 Yost751       \u2502\n\u2502 Deon400    \u2502 Littel644     \u2502\n\u2502 Emerson869 \u2502 D'Amore443    \u2502\n\u2502 Alec433    \u2502 Sanford861    \u2502\n\u2502 Roselyn270 \u2502 McLaughlin530 \u2502\n\u2502 Claudia969 \u2502 Smith67       \u2502\n\u2502   \u00b7        \u2502    \u00b7          \u2502\n\u2502   \u00b7        \u2502    \u00b7          \u2502\n\u2502   \u00b7        \u2502    \u00b7          \u2502\n\u2502 Lou594     \u2502 Gleason633    \u2502\n\u2502 Hank686    \u2502 Russel238     \u2502\n\u2502 Earl438    \u2502 Block661      \u2502\n\u2502 Mariano761 \u2502 Heller342     \u2502\n\u2502 Sandra485  \u2502 Fisher429     \u2502\n\u2502 Claire652  \u2502 Murray856     \u2502\n\u2502 Doreen575  \u2502 Graham902     \u2502\n\u2502 Fausto876  \u2502 Kuhn96        \u2502\n\u2502 Vernon254  \u2502 Gutmann970    \u2502\n\u2502 Ernest565  \u2502 Block661      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows           2 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Find patients whose healthcare coverage is above the average of their respective city. <pre><code>query = \"\"\"\nSELECT\n    p.FIRST,\n    p.LAST,\n    p.CITY,\n    ROUND(p.HEALTHCARE_COVERAGE,2) AS INDIVIDUAL_COVERAGE,\n    ROUND(c.AVG_COVERAGE,2) AS CITY_AVERAGE_COVERAGE\nFROM\n    patients p\nINNER JOIN (\n    SELECT\n        CITY,\n        AVG(HEALTHCARE_COVERAGE) AS AVG_COVERAGE\n    FROM\n        patients\n    GROUP BY\n        CITY\n) AS c ON p.CITY = c.CITY\nWHERE\n    p.HEALTHCARE_COVERAGE &gt; (\n        SELECT AVG(HEALTHCARE_COVERAGE)\n        FROM patients\n        WHERE CITY = p.CITY\n    );\n\"\"\"\nconn.sql(query)\n</code></pre> <pre><code>query = \"\"\"\nSELECT\n    p.FIRST,\n    p.LAST,\n    p.CITY,\n    ROUND(p.HEALTHCARE_COVERAGE,2) AS INDIVIDUAL_COVERAGE,\n    ROUND(c.AVG_COVERAGE,2) AS CITY_AVERAGE_COVERAGE\nFROM\n    patients p\nINNER JOIN (\n\u2026        SELECT AVG(HEALTHCARE_COVERAGE)\n        FROM patients\n        WHERE CITY = p.CITY\n    );\n\"\"\"\nconn.sql(query)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    FIRST     \u2502      LAST      \u2502     CITY      \u2502 INDIVIDUAL_COVERAGE \u2502 CITY_AVERAGE_COVERAGE \u2502\n\u2502   varchar    \u2502    varchar     \u2502    varchar    \u2502       double        \u2502        double         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Anisa442     \u2502 Purdy2         \u2502 Methuen       \u2502            34393.57 \u2502              12949.31 \u2502\n\u2502 Sina65       \u2502 Howell947      \u2502 Sudbury       \u2502            15481.43 \u2502              15385.85 \u2502\n\u2502 Maria750     \u2502 Schimmel440    \u2502 Plymouth      \u2502            14231.22 \u2502              10826.53 \u2502\n\u2502 Kip442       \u2502 Zboncak558     \u2502 Hopkinton     \u2502           155478.44 \u2502              15439.17 \u2502\n\u2502 Hans694      \u2502 Wilkinson796   \u2502 Framingham    \u2502            13729.73 \u2502              11988.99 \u2502\n\u2502 Jean712      \u2502 Kuhlman484     \u2502 Boxford       \u2502            11421.48 \u2502               8660.53 \u2502\n\u2502 Lorette239   \u2502 Abbott774      \u2502 Dennis        \u2502            78740.23 \u2502              14918.28 \u2502\n\u2502 Tobi258      \u2502 Bernier607     \u2502 Wilmington    \u2502             13889.6 \u2502               9411.52 \u2502\n\u2502 Rosia390     \u2502 Reichel38      \u2502 Rochester     \u2502            16234.29 \u2502               9736.74 \u2502\n\u2502 Florencia449 \u2502 Mercado213     \u2502 Wilbraham     \u2502            11427.25 \u2502              10468.26 \u2502\n\u2502   \u00b7          \u2502    \u00b7           \u2502    \u00b7          \u2502                \u00b7    \u2502                  \u00b7    \u2502\n\u2502   \u00b7          \u2502    \u00b7           \u2502    \u00b7          \u2502                \u00b7    \u2502                  \u00b7    \u2502\n\u2502   \u00b7          \u2502    \u00b7           \u2502    \u00b7          \u2502                \u00b7    \u2502                  \u00b7    \u2502\n\u2502 Jc393        \u2502 Marks830       \u2502 Brockton      \u2502            16284.35 \u2502              12287.77 \u2502\n\u2502 Cedric746    \u2502 Marvin195      \u2502 Dedham        \u2502            19806.72 \u2502              13840.99 \u2502\n\u2502 Milford485   \u2502 Schmitt836     \u2502 Hubbardston   \u2502            10592.34 \u2502               8172.48 \u2502\n\u2502 Tegan755     \u2502 Ruecker817     \u2502 Waltham       \u2502            30493.65 \u2502              14495.07 \u2502\n\u2502 Lindsay928   \u2502 Lang846        \u2502 Boston        \u2502            11837.05 \u2502               10725.8 \u2502\n\u2502 Claudie965   \u2502 Hermann103     \u2502 Medford       \u2502            15420.54 \u2502              12610.05 \u2502\n\u2502 Julie245     \u2502 Nolan344       \u2502 Essex         \u2502            31903.53 \u2502              31787.13 \u2502\n\u2502 Mui729       \u2502 Stoltenberg489 \u2502 Wakefield     \u2502            21528.91 \u2502              13699.32 \u2502\n\u2502 Oliver401    \u2502 Lesch175       \u2502 Yarmouth      \u2502            27442.87 \u2502              19907.83 \u2502\n\u2502 Mi492        \u2502 Gusikowski974  \u2502 North Andover \u2502            18481.09 \u2502              17677.13 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 20 shown)                                                     5 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#functions-in-sql","title":"FUNCTIONS IN SQL","text":""},{"location":"11_sql_duckdb/#string-functions","title":"String Functions","text":""},{"location":"11_sql_duckdb/#concat-concatenates-two-or-more-strings","title":"CONCAT: Concatenates two or more strings.","text":"<p><pre><code>query = \"\"\"SELECT CONCAT(FIRST, ' ', LAST) AS FullName FROM patients LIMIT 10;\n;\"\"\"\nconn.sql(query)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         FullName          \u2502\n\u2502          varchar          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Jacinto644 Kris249        \u2502\n\u2502 Alva958 Krajcik437        \u2502\n\u2502 Jimmie93 Harris789        \u2502\n\u2502 Gregorio366 Auer97        \u2502\n\u2502 Karyn217 Mueller846       \u2502\n\u2502 Jayson808 Fadel536        \u2502\n\u2502 Jos\u00e9 Eduardo181 G\u00f3mez206  \u2502\n\u2502 Milo271 Feil794           \u2502\n\u2502 Karyn217 Metz686          \u2502\n\u2502 Jeffrey461 Greenfelder433 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          10 rows          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#datalength-returns-the-number-of-bytes-used-to-represent-any-expre","title":"DATALENGTH: Returns the number of bytes used to represent any expre","text":"<p><pre><code>query = \"\"\"\nSELECT FIRST, LENGTH(FIRST) AS LengthInBytes FROM patients LIMIT 10;\n\"\"\"\n\nconn.sql(query)\n</code></pre> <pre><code>query = \"\"\"\nSELECT FIRST, LENGTH(FIRST) AS LengthInBytes FROM patients LIMIT 10;\n\"\"\"\n\nconn.sql(query)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      FIRST      \u2502 LengthInBytes \u2502\n\u2502     varchar     \u2502     int64     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Jacinto644      \u2502            10 \u2502\n\u2502 Alva958         \u2502             7 \u2502\n\u2502 Jimmie93        \u2502             8 \u2502\n\u2502 Gregorio366     \u2502            11 \u2502\n\u2502 Karyn217        \u2502             8 \u2502\n\u2502 Jayson808       \u2502             9 \u2502\n\u2502 Jos\u00e9 Eduardo181 \u2502            15 \u2502\n\u2502 Milo271         \u2502             7 \u2502\n\u2502 Karyn217        \u2502             8 \u2502\n\u2502 Jeffrey461      \u2502            10 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 10 rows               2 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#left-returns-the-left-part-of-a-character-string-with-the-specified-number-of-characters","title":"LEFT: Returns the left part of a character string with the specified number of characters.","text":"<p><pre><code>query = \"\"\"SELECT LEFT(FIRST, 5) AS Initial FROM patients LIMIT 10;\"\"\"\nconn.sql(query)\n</code></pre> <pre><code>query = \"\"\"SELECT LEFT(FIRST, 5) AS Initial FROM patients LIMIT 10;\"\"\"\nconn.sql(query)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Initial \u2502\n\u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Jacin   \u2502\n\u2502 Alva9   \u2502\n\u2502 Jimmi   \u2502\n\u2502 Grego   \u2502\n\u2502 Karyn   \u2502\n\u2502 Jayso   \u2502\n\u2502 Jos\u00e9    \u2502\n\u2502 Milo2   \u2502\n\u2502 Karyn   \u2502\n\u2502 Jeffr   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 10 rows \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#lower-converts-all-characters-in-the-specified-string-to-lowercase","title":"LOWER: Converts all characters in the specified string to lowercase.","text":""},{"location":"11_sql_duckdb/#upper-convert-to-uppercase","title":"UPPER: Convert to uppercase","text":"<p><pre><code>query = \"\"\"\nSELECT LOWER(FIRST) AS LowercaseFirstName, UPPER(LAST) AS UppercaseLastName FROM patients LIMIT 10;\n\"\"\"\nconn.sql(query)\n</code></pre> <pre><code>query = \"\"\"\nSELECT LOWER(FIRST) AS LowercaseFirstName, UPPER(LAST) AS UppercaseLastName FROM patients LIMIT 10;\n\"\"\"\nconn.sql(query)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 LowercaseFirstName \u2502 UppercaseLastName \u2502\n\u2502      varchar       \u2502      varchar      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 jacinto644         \u2502 KRIS249           \u2502\n\u2502 alva958            \u2502 KRAJCIK437        \u2502\n\u2502 jimmie93           \u2502 HARRIS789         \u2502\n\u2502 gregorio366        \u2502 AUER97            \u2502\n\u2502 karyn217           \u2502 MUELLER846        \u2502\n\u2502 jayson808          \u2502 FADEL536          \u2502\n\u2502 jos\u00e9 eduardo181    \u2502 G\u00d3MEZ206          \u2502\n\u2502 milo271            \u2502 FEIL794           \u2502\n\u2502 karyn217           \u2502 METZ686           \u2502\n\u2502 jeffrey461         \u2502 GREENFELDER433    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 10 rows                      2 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> LTRIM: Removes leading spaces from a string. <pre><code>query = \"\"\"SELECT LTRIM(ADDRESS) AS TrimmedAddress FROM patients LIMIT 10;\"\"\"\n\nconn.sql(query)\n</code></pre> <pre><code>query = \"\"\"SELECT LTRIM(ADDRESS) AS TrimmedAddress FROM patients LIMIT 10;\"\"\"\n\nconn.sql(query)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         TrimmedAddress         \u2502\n\u2502            varchar             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 888 Hickle Ferry Suite 38      \u2502\n\u2502 1048 Skiles Trailer            \u2502\n\u2502 201 Mitchell Lodge Unit 67     \u2502\n\u2502 1050 Lindgren Extension Apt 38 \u2502\n\u2502 570 Abshire Forge Suite 32     \u2502\n\u2502 1056 Harris Lane Suite 70      \u2502\n\u2502 427 Balistreri Way Unit 19     \u2502\n\u2502 422 Farrell Path Unit 69       \u2502\n\u2502 181 Feest Passage Suite 64     \u2502\n\u2502 428 Wiza Glen Unit 91          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502            10 rows             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> REPLACE: Replaces all occurrences of a specified string value with another string value. <pre><code>query = \"\"\"SELECT FIRST, LAST,\n    ADDRESS AS LongAddress,\n    REPLACE(ADDRESS, 'Street', 'St') AS ShortAddress\nFROM\n    patients\nWHERE\n    ADDRESS LIKE '%Street%' LIMIT 10;\n\"\"\"\n\nconn.sql(query)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   FIRST    \u2502     LAST      \u2502        LongAddress        \u2502     ShortAddress      \u2502\n\u2502  varchar   \u2502    varchar    \u2502          varchar          \u2502        varchar        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Lorrie905  \u2502 Leannon79     \u2502 813 Casper Street         \u2502 813 Casper St         \u2502\n\u2502 Asa127     \u2502 Block661      \u2502 140 Rohan Street Suite 50 \u2502 140 Rohan St Suite 50 \u2502\n\u2502 Logan497   \u2502 Brekke496     \u2502 1081 Orn Street           \u2502 1081 Orn St           \u2502\n\u2502 Cletus494  \u2502 Strosin214    \u2502 1019 Haley Street         \u2502 1019 Haley St         \u2502\n\u2502 Cortney940 \u2502 Stehr398      \u2502 458 Streich Street        \u2502 458 Streich St        \u2502\n\u2502 Latoyia537 \u2502 Gaylord332    \u2502 200 Heaney Street         \u2502 200 Heaney St         \u2502\n\u2502 Clark193   \u2502 Hilll811      \u2502 202 Tromp Street Suite 0  \u2502 202 Tromp St Suite 0  \u2502\n\u2502 Jc393      \u2502 Bosco882      \u2502 792 Walsh Street          \u2502 792 Walsh St          \u2502\n\u2502 Noel608    \u2502 Swaniawski813 \u2502 155 Walter Street         \u2502 155 Walter St         \u2502\n\u2502 Sari509    \u2502 Hoppe518      \u2502 550 Lang Street Suite 65  \u2502 550 Lang St Suite 65  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 10 rows                                                              4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> RIGHT: Returns the right part of a character string with the specified number of characters. <pre><code>query = \"\"\"SELECT FIRST, RIGHT(FIRST, 6) AS LastSixChars FROM patients LIMIT 10;\n\"\"\"\n\nconn.sql(query)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      FIRST      \u2502 LastSixChars \u2502\n\u2502     varchar     \u2502   varchar    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Jacinto644      \u2502 nto644       \u2502\n\u2502 Alva958         \u2502 lva958       \u2502\n\u2502 Jimmie93        \u2502 mmie93       \u2502\n\u2502 Gregorio366     \u2502 rio366       \u2502\n\u2502 Karyn217        \u2502 ryn217       \u2502\n\u2502 Jayson808       \u2502 son808       \u2502\n\u2502 Jos\u00e9 Eduardo181 \u2502 rdo181       \u2502\n\u2502 Milo271         \u2502 ilo271       \u2502\n\u2502 Karyn217        \u2502 ryn217       \u2502\n\u2502 Jeffrey461      \u2502 rey461       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 10 rows              2 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> SUBSTRING: Returns part of a character, binary, text, or image expression in SQL Server. <pre><code>query = \"\"\"SELECT FIRST, SUBSTRING(FIRST, 1, 4) AS FirstFourChars FROM patients LIMIT 5;\n\"\"\"\n\nconn.sql(query)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    FIRST    \u2502 FirstFourChars \u2502\n\u2502   varchar   \u2502    varchar     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Jacinto644  \u2502 Jaci           \u2502\n\u2502 Alva958     \u2502 Alva           \u2502\n\u2502 Jimmie93    \u2502 Jimm           \u2502\n\u2502 Gregorio366 \u2502 Greg           \u2502\n\u2502 Karyn217    \u2502 Kary           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> REGEXP_REPLACE can use regular expressions to strip numeric characters: <pre><code>query = \"\"\"SELECT\nFIRST, REGEXP_REPLACE(FIRST, '[0-9]', '', 'g') AS FirstNameStripped, LAST, REGEXP_REPLACE(LAST, '[0-9]', '', 'g') AS LastNameStripped\nFROM patients;\n\"\"\"\n\nconn.sql(query)\n</code></pre> <pre><code>query = \"\"\"SELECT\nFIRST, REGEXP_REPLACE(FIRST, '[0-9]', '', 'g') AS FirstNameStripped, LAST, REGEXP_REPLACE(LAST, '[0-9]', '', 'g') AS LastNameStripped\nFROM patients;\n\"\"\"\n\nconn.sql(query)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      FIRST      \u2502 FirstNameStripped \u2502      LAST      \u2502 LastNameStripped \u2502\n\u2502     varchar     \u2502      varchar      \u2502    varchar     \u2502     varchar      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Jacinto644      \u2502 Jacinto           \u2502 Kris249        \u2502 Kris             \u2502\n\u2502 Alva958         \u2502 Alva              \u2502 Krajcik437     \u2502 Krajcik          \u2502\n\u2502 Jimmie93        \u2502 Jimmie            \u2502 Harris789      \u2502 Harris           \u2502\n\u2502 Gregorio366     \u2502 Gregorio          \u2502 Auer97         \u2502 Auer             \u2502\n\u2502 Karyn217        \u2502 Karyn             \u2502 Mueller846     \u2502 Mueller          \u2502\n\u2502 Jayson808       \u2502 Jayson            \u2502 Fadel536       \u2502 Fadel            \u2502\n\u2502 Jos\u00e9 Eduardo181 \u2502 Jos\u00e9 Eduardo      \u2502 G\u00f3mez206       \u2502 G\u00f3mez            \u2502\n\u2502 Milo271         \u2502 Milo              \u2502 Feil794        \u2502 Feil             \u2502\n\u2502 Karyn217        \u2502 Karyn             \u2502 Metz686        \u2502 Metz             \u2502\n\u2502 Jeffrey461      \u2502 Jeffrey           \u2502 Greenfelder433 \u2502 Greenfelder      \u2502\n\u2502     \u00b7           \u2502    \u00b7              \u2502     \u00b7          \u2502    \u00b7             \u2502\n\u2502     \u00b7           \u2502    \u00b7              \u2502     \u00b7          \u2502    \u00b7             \u2502\n\u2502     \u00b7           \u2502    \u00b7              \u2502     \u00b7          \u2502    \u00b7             \u2502\n\u2502 Raymond398      \u2502 Raymond           \u2502 Kuvalis369     \u2502 Kuvalis          \u2502\n\u2502 Gearldine455    \u2502 Gearldine         \u2502 Boyer713       \u2502 Boyer            \u2502\n\u2502 Nichol11        \u2502 Nichol            \u2502 Gleichner915   \u2502 Gleichner        \u2502\n\u2502 Louvenia131     \u2502 Louvenia          \u2502 Marks830       \u2502 Marks            \u2502\n\u2502 Raymon366       \u2502 Raymon            \u2502 Beer512        \u2502 Beer             \u2502\n\u2502 Camelia346      \u2502 Camelia           \u2502 Stamm704       \u2502 Stamm            \u2502\n\u2502 William805      \u2502 William           \u2502 Pacocha935     \u2502 Pacocha          \u2502\n\u2502 Guillermo498    \u2502 Guillermo         \u2502 T\u00e9llez750      \u2502 T\u00e9llez           \u2502\n\u2502 Milton509       \u2502 Milton            \u2502 Bailey598      \u2502 Bailey           \u2502\n\u2502 Cecilia788      \u2502 Cecilia           \u2502 Wisozk929      \u2502 Wisozk           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 20 shown)                                 4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"11_sql_duckdb/#creating-a-database-and-adding-data-to-tables","title":"Creating a database and adding data to tables","text":""},{"location":"11_sql_duckdb/#create-alter-drop-insert-commands","title":"CREATE, ALTER, DROP, INSERT commands","text":"<p>First lets have a in-memory database <pre><code>newdb = duckdb.connect()\n</code></pre> CREATE TABLE: Create a books table to mimic a library catalog system. <pre><code>query = \"\"\"CREATE TABLE books (\n    book_id INTEGER PRIMARY KEY,\n    title VARCHAR,\n    author VARCHAR,\n    published_year INTEGER\n);\n\"\"\"\n\nnewdb.sql(query)\n</code></pre> The CREATE TABLE statement defines the schema for this table: This statement creates a table with columns for the book ID, title, author, and the year of publication. The book_id column is designated as the primary key, ensuring that each record in the table is unique.</p> <p>check <pre><code>newdb.sql(\"SHOW TABLES;\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  name   \u2502\n\u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 books   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> check data <pre><code>newdb.sql(\"DESCRIBE books;\")\n</code></pre> <pre><code>newdb.sql(\"DESCRIBE books;\")\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  column_name   \u2502 column_type \u2502  null   \u2502   key   \u2502 default \u2502 extra \u2502\n\u2502    varchar     \u2502   varchar   \u2502 varchar \u2502 varchar \u2502 varchar \u2502 int32 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 book_id        \u2502 INTEGER     \u2502 NO      \u2502 PRI     \u2502 NULL    \u2502  NULL \u2502\n\u2502 title          \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 author         \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 published_year \u2502 INTEGER     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Alter Table: After creating the table, you might need to add more information. Use the ALTER TABLE statement to add a new column: <pre><code>query = \"\"\"ALTER TABLE books ADD COLUMN genre VARCHAR;\n\"\"\"\nnewdb.sql(query)\n# This adds a genre column to the books table, allowing you to categorize books.\n</code></pre> <pre><code>newdb.sql(\"DESCRIBE books;\")\n</code></pre> <pre><code>newdb.sql(\"DESCRIBE books;\")\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  column_name   \u2502 column_type \u2502  null   \u2502   key   \u2502 default \u2502 extra \u2502\n\u2502    varchar     \u2502   varchar   \u2502 varchar \u2502 varchar \u2502 varchar \u2502 int32 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 book_id        \u2502 INTEGER     \u2502 NO      \u2502 PRI     \u2502 NULL    \u2502  NULL \u2502\n\u2502 title          \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 author         \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 published_year \u2502 INTEGER     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2502 genre          \u2502 VARCHAR     \u2502 YES     \u2502 NULL    \u2502 NULL    \u2502  NULL \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> let's add another table which we will DROP later; <pre><code>query = \"\"\"CREATE TABLE authors (\n    author_id INTEGER PRIMARY KEY,\n    firstname VARCHAR,\n    lastname VARCHAR,\n    birth_year INTEGER\n);\n\"\"\"\n\nnewdb.sql(query)\n</code></pre></p> <p><pre><code>newdb.sql(\"SHOW TABLES;\")\n</code></pre> Now let's DROP the author table <pre><code>query = \"\"\"DROP TABLE IF EXISTS authors;\n\"\"\"\n\nnewdb.sql(query)\n</code></pre></p> <pre><code>newdb.sql(\"SHOW TABLES;\")\n</code></pre>"},{"location":"11_sql_duckdb/#lets-add-some-data-now","title":"Let's add some data now","text":""},{"location":"11_sql_duckdb/#insert-to-populate-the-books-table-with-data-this-inserts-10-records-into-the-books-table-providing-a-diverse-set-of-examples","title":"INSERT To populate the books table with data. This inserts 10 records into the books table, providing a diverse set of examples.","text":"<pre><code>query = \"\"\"INSERT INTO books (book_id, title, author, published_year, genre) VALUES\n(1, '1984', 'George Orwell', 1949, 'Dystopian'),\n(2, 'The Great Gatsby', 'F. Scott Fitzgerald', 1925, 'Classic'),\n(3, 'To Kill a Mockingbird', 'Harper Lee', 1960, 'Classic'),\n(4, 'Pride and Prejudice', 'Jane Austen', 1813, 'Romance'),\n(5, 'The Hobbit', 'J.R.R. Tolkien', 1937, 'Fantasy'),\n(6, 'The Catcher in the Rye', 'J.D. Salinger', 1951, 'Literary Fiction'),\n(7, 'Harry Potter and the Sorcerer\u2019s Stone', 'J.K. Rowling', 1997, 'Fantasy'),\n(8, 'The Da Vinci Code', 'Dan Brown', 2003, 'Thriller'),\n(9, 'Sapiens: A Brief History of Humankind', 'Yuval Noah Harari', 2011, 'Non-fiction'),\n(10, 'Beloved', 'Toni Morrison', 1987, 'Historical Fiction');\"\"\"\n\nnewdb.sql(query)\n</code></pre> <pre><code>query = \"\"\"SELECT title AS \"Book Title\", author AS \"Author Name\", Genre FROM books;\n\"\"\"\n\nnewdb.sql(query)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Book Title               \u2502     Author Name     \u2502       genre        \u2502\n\u2502                varchar                \u2502       varchar       \u2502      varchar       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1984                                  \u2502 George Orwell       \u2502 Dystopian          \u2502\n\u2502 The Great Gatsby                      \u2502 F. Scott Fitzgerald \u2502 Classic            \u2502\n\u2502 To Kill a Mockingbird                 \u2502 Harper Lee          \u2502 Classic            \u2502\n\u2502 Pride and Prejudice                   \u2502 Jane Austen         \u2502 Romance            \u2502\n\u2502 The Hobbit                            \u2502 J.R.R. Tolkien      \u2502 Fantasy            \u2502\n\u2502 The Catcher in the Rye                \u2502 J.D. Salinger       \u2502 Literary Fiction   \u2502\n\u2502 Harry Potter and the Sorcerer\u2019s Stone \u2502 J.K. Rowling        \u2502 Fantasy            \u2502\n\u2502 The Da Vinci Code                     \u2502 Dan Brown           \u2502 Thriller           \u2502\n\u2502 Sapiens: A Brief History of Humankind \u2502 Yuval Noah Harari   \u2502 Non-fiction        \u2502\n\u2502 Beloved                               \u2502 Toni Morrison       \u2502 Historical Fiction \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 10 rows                                                                3 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"11_sql_duckdb/#updating-data-update","title":"Updating Data: UPDATE","text":"<p>This changes the genre of the book titled '1984' to 'Science Fiction'. <pre><code>query = \"\"\"UPDATE books SET genre = 'Science Fiction' WHERE title = '1984';\n\"\"\"\n\nnewdb.sql(query)\n</code></pre></p> <pre><code>query = \"\"\"SELECT title AS \"Book Title\", author AS \"Author Name\", Genre FROM books;\n\"\"\"\n\nnewdb.sql(query)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Book Title               \u2502     Author Name     \u2502       genre        \u2502\n\u2502                varchar                \u2502       varchar       \u2502      varchar       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1984                                  \u2502 George Orwell       \u2502 Science Fiction    \u2502\n\u2502 The Great Gatsby                      \u2502 F. Scott Fitzgerald \u2502 Classic            \u2502\n\u2502 To Kill a Mockingbird                 \u2502 Harper Lee          \u2502 Classic            \u2502\n\u2502 Pride and Prejudice                   \u2502 Jane Austen         \u2502 Romance            \u2502\n\u2502 The Hobbit                            \u2502 J.R.R. Tolkien      \u2502 Fantasy            \u2502\n\u2502 The Catcher in the Rye                \u2502 J.D. Salinger       \u2502 Literary Fiction   \u2502\n\u2502 Harry Potter and the Sorcerer\u2019s Stone \u2502 J.K. Rowling        \u2502 Fantasy            \u2502\n\u2502 The Da Vinci Code                     \u2502 Dan Brown           \u2502 Thriller           \u2502\n\u2502 Sapiens: A Brief History of Humankind \u2502 Yuval Noah Harari   \u2502 Non-fiction        \u2502\n\u2502 Beloved                               \u2502 Toni Morrison       \u2502 Historical Fiction \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 10 rows                                                                3 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"11_sql_duckdb/#delete","title":"DELETE","text":"<p>e.g. To remove a book from the catalog</p> <pre><code>query = \"\"\"DELETE FROM books WHERE title = 'The Great Gatsby';\"\"\"\nnewdb.sql(query)\n</code></pre> <pre><code>query = \"\"\"SELECT title AS \"Book Title\", author AS \"Author Name\", Genre FROM books;\n\"\"\"\n\nnewdb.sql(query)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Book Title               \u2502    Author Name    \u2502       genre        \u2502\n\u2502                varchar                \u2502      varchar      \u2502      varchar       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1984                                  \u2502 George Orwell     \u2502 Science Fiction    \u2502\n\u2502 To Kill a Mockingbird                 \u2502 Harper Lee        \u2502 Classic            \u2502\n\u2502 Pride and Prejudice                   \u2502 Jane Austen       \u2502 Romance            \u2502\n\u2502 The Hobbit                            \u2502 J.R.R. Tolkien    \u2502 Fantasy            \u2502\n\u2502 The Catcher in the Rye                \u2502 J.D. Salinger     \u2502 Literary Fiction   \u2502\n\u2502 Harry Potter and the Sorcerer\u2019s Stone \u2502 J.K. Rowling      \u2502 Fantasy            \u2502\n\u2502 The Da Vinci Code                     \u2502 Dan Brown         \u2502 Thriller           \u2502\n\u2502 Sapiens: A Brief History of Humankind \u2502 Yuval Noah Harari \u2502 Non-fiction        \u2502\n\u2502 Beloved                               \u2502 Toni Morrison     \u2502 Historical Fiction \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"11_sql_duckdb/#truncate","title":"TRUNCATE","text":"<ul> <li>The TRUNCATE TABLE statement is used to delete all rows in a table without logging the individual row deletions.</li> <li>This is faster than using DELETE without a WHERE clause because TRUNCATE immediately deallocates data pages used by the table.</li> <li>Use TRUNCATE when you want to quickly remove all records from a table but keep the table structure for future use.</li> <li>Unlike DELETE, TRUNCATE does not generate a large number of transaction logs, making it more efficient for completely clearing a table.</li> </ul> <pre><code>query = \"\"\"TRUNCATE TABLE books;\"\"\"\n\nnewdb.sql(query)\n</code></pre> <pre><code>query = \"\"\"SELECT * FROM books;\n\"\"\"\n\nnewdb.sql(query)\n</code></pre>"},{"location":"11_sql_duckdb/#adding-one-more-table-named-authors","title":"Adding one more table; named 'authors'","text":"<p><pre><code>query = \"\"\"CREATE TABLE authors (\n    author_id INTEGER PRIMARY KEY,\n    name VARCHAR,\n    birth_year INTEGER,\n    nationality VARCHAR\n);\n\"\"\"\n\nnewdb.sql(query)\n</code></pre> Add information the authors table <pre><code>query = \"\"\"INSERT INTO authors (author_id, name, birth_year, nationality) VALUES\n(1, 'George Orwell', 1903, 'British'),\n(2, 'F. Scott Fitzgerald', 1896, 'American'),\n(3, 'Harper Lee', 1926, 'American'),\n(4, 'Jane Austen', 1775, 'British'),\n(5, 'J.R.R. Tolkien', 1892, 'British'),\n(6, 'J.D. Salinger', 1919, 'American'),\n(7, 'J.K. Rowling', 1965, 'British'),\n(8, 'Dan Brown', 1964, 'American'),\n(9, 'Yuval Noah Harari', 1976, 'Israeli'),\n(10, 'Toni Morrison', 1931, 'American');\n\"\"\"\n\n\nnewdb.sql(query)\n</code></pre></p> <p><pre><code>query = \"\"\"SELECT * FROM books;\n\"\"\"\n\nnewdb.sql(query)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 book_id \u2502                 title                 \u2502       author        \u2502 published_year \u2502       genre        \u2502\n\u2502  int64  \u2502                varchar                \u2502       varchar       \u2502     int64      \u2502      varchar       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502       1 \u2502 1984                                  \u2502 George Orwell       \u2502           1949 \u2502 Dystopian          \u2502\n\u2502       2 \u2502 The Great Gatsby                      \u2502 F. Scott Fitzgerald \u2502           1925 \u2502 Classic            \u2502\n\u2502       3 \u2502 To Kill a Mockingbird                 \u2502 Harper Lee          \u2502           1960 \u2502 Classic            \u2502\n\u2502       4 \u2502 Pride and Prejudice                   \u2502 Jane Austen         \u2502           1813 \u2502 Romance            \u2502\n\u2502       5 \u2502 The Hobbit                            \u2502 J.R.R. Tolkien      \u2502           1937 \u2502 Fantasy            \u2502\n\u2502       6 \u2502 The Catcher in the Rye                \u2502 J.D. Salinger       \u2502           1951 \u2502 Literary Fiction   \u2502\n\u2502       7 \u2502 Harry Potter and the Sorcerer\u2019s Stone \u2502 J.K. Rowling        \u2502           1997 \u2502 Fantasy            \u2502\n\u2502       8 \u2502 The Da Vinci Code                     \u2502 Dan Brown           \u2502           2003 \u2502 Thriller           \u2502\n\u2502       9 \u2502 Sapiens: A Brief History of Humankind \u2502 Yuval Noah Harari   \u2502           2011 \u2502 Non-fiction        \u2502\n\u2502      10 \u2502 Beloved                               \u2502 Toni Morrison       \u2502           1987 \u2502 Historical Fiction \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 10 rows                                                                                           5 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <pre><code>query = \"\"\"SELECT * FROM authors;\n\"\"\"\n\nnewdb.sql(query)\n</code></pre> <pre><code>newdb.sql(query)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 author_id \u2502        name         \u2502 birth_year \u2502 nationality \u2502\n\u2502   int32   \u2502       varchar       \u2502   int32    \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         1 \u2502 George Orwell       \u2502       1903 \u2502 British     \u2502\n\u2502         2 \u2502 F. Scott Fitzgerald \u2502       1896 \u2502 American    \u2502\n\u2502         3 \u2502 Harper Lee          \u2502       1926 \u2502 American    \u2502\n\u2502         4 \u2502 Jane Austen         \u2502       1775 \u2502 British     \u2502\n\u2502         5 \u2502 J.R.R. Tolkien      \u2502       1892 \u2502 British     \u2502\n\u2502         6 \u2502 J.D. Salinger       \u2502       1919 \u2502 American    \u2502\n\u2502         7 \u2502 J.K. Rowling        \u2502       1965 \u2502 British     \u2502\n\u2502         8 \u2502 Dan Brown           \u2502       1964 \u2502 American    \u2502\n\u2502         9 \u2502 Yuval Noah Harari   \u2502       1976 \u2502 Israeli     \u2502\n\u2502        10 \u2502 Toni Morrison       \u2502       1931 \u2502 American    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 10 rows                                          4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"11_sql_duckdb/#exporting-data-to-csv-from-sql","title":"EXPORTING Data to csv from SQL","text":"<pre><code>query = \"\"\"EXPORT DATABASE './' (FORMAT CSV, DELIMITER ',');\"\"\"\n\nnewdb.sql(query)\n</code></pre>"},{"location":"11_sql_duckdb/#thank-you","title":"Thank You!","text":""},{"location":"code_of_conduct/","title":"Code of Conduct","text":"<p>In conjunction with for using CyVerse cyberinfrastructure, this Code of Conduct applies to all Event participants and their activities while using CyVerse resources and/or attending the Event.</p> <p>CyVerse is dedicated to providing professional computational research and educational experiences for all of our users, regardless of domain focus, academic status, educational level, gender/gender identity/expression, age, sexual orientation, mental or physical ability, physical appearance, body size, race, ethnicity, religion (or lack thereof), technology choices, dietary preferences, or any other personal characteristic.</p> <p>When using CyVerse or participating at an Event, we expect you to:</p> <ul> <li>Interact with others and use CyVerse professionally and ethically by     complying with our Policies.</li> <li>Constructively critize ideas and processes, not people.</li> <li>Follow the Golden Rule (treat others as you want to be treated) when     interacting online or in-person with collaborators, trainers, and     support staff.</li> <li>Comply with this Code in spirit as much as the letter, as it is     neither exhaustive nor complete in identifying any and all possible     unacceptable conduct.</li> </ul> <p>We do not tolerate harassment of other users or staff in any form (including, but not limited to, violent threats or language, derogatory language or jokes, doxing, insults, advocating for or encouraging any of these behaviors). Sexual language and imagery are not appropriate at any time (excludes Protected Health Information in compliance with HIPAA). Any user violating this Code may be expelled from the platform and the workshop at CyVerse's sole discretion without warning.</p> <p>To report a violation of this Code, directly message a trainer via Slack or email info@cyverse.org with the following information:</p> <ul> <li>Your contact information</li> <li>Names (real, username, pseudonyms) of any individuals involved, and     or witness(es) if any.</li> <li>Your account of what occurred and if the incident is ongoing. If     there is a publicly available record (a tweet, public chat log,     etc.), please include a link or attachment.</li> <li>Any additional information that may be helpful in resolving the     issue.</li> </ul>"},{"location":"glossary/","title":"Glossary &amp; Acronyms","text":"<p>A</p> <ul> <li>action: automate a workflow in the context of CI/CD, see GitHub Actions</li> <li>agile: development methodology     for organizing a team to complete tasks organized over short periods     called 'sprints'</li> <li>allocation: portion of a resource assigned to a particular     recipient, typical unit is a core or node hour</li> <li>Anaconda: open source data science platform.     Anaconda.com</li> <li>application: also called an 'app', a software designed to help     the user to perform specific task</li> <li>awesome: a curated set of lists that provide insight into     awesome software projects on GitHub</li> <li>AVU: Attribute-Value-Unit a components for iRODS     metadata.</li> </ul> <p>B</p> <ul> <li>beta: a software version which is not yet ready for     publication but is being tested</li> <li>bash: Bash is the GNU Project's shell, the Bourne-Again     Shell</li> <li>biocontainer: a community-driven project that provides the     infrastructure and basic guidelines to create, manage and distribute     bioinformatics packages (e.g conda) and containers (e.g docker,     singularity)</li> <li>bioconda: a channel for the conda package manager specializing     in bioinformatics software</li> </ul> <p>C</p> <ul> <li>CLI: the UNIX shell command line interface,     most typically BASH</li> <li>command: a set of instructions sent to the computer, typically     in a typed interface</li> <li>conda: an installation type of the Anaconda data science     platform. Command line application for managing packages and     environments</li> <li>container: virtualization of an operating system run within an     isolated user space</li> <li>Continuous Integration: (CI) is testing automation to check that     the application is not broken whenever new commits are integrated     into the main branch</li> <li>Continuous Delivery: (CD) is an extension of 'continuous     integration' to make sure that you can release new changes in a     sustainable way</li> <li>Continuous Deployment: a step further than 'continuous     delivery', every change that passes all stages of your production     pipeline is released</li> <li>Continuous Development: a process for iterative software     development and is an umbrella over several other processes     including 'continuous integration', 'continuous testing',     'continuous delivery' and 'continuous deployment'</li> <li>Continuous Testing: a process of testing and automating software     development.</li> <li>CRAN: The Comprehensive R Archive     Network</li> <li>CyVerse tool: Software program that is integrated into the back     end of the DE for use in DE apps</li> <li>CyVerse app: graphic interface of a tool made available for use     in the DE</li> </ul> <p>D</p> <ul> <li>Debian: a free OS, base of other     Linux distributions such as Ubuntu</li> <li>Development: the environment on your computer where you write     code</li> <li>DevOps Software *Dev*elopment and information techology     *Op*erations techniques for shortening the time to change software     in relation to CI/CD</li> <li>Discovery Environment (DE): a data science workbench for running     executable, interactive, and high throughput applications in     CyVerse DE</li> <li>distribution: abbreviated as 'distro', an operating system     made from a software collection based upon the Linux kernel</li> <li>Docker: Docker is an open source     software platform to create, deploy and manage virtualized     application containers on a common operating system (OS), with an     ecosystem of allied tools. A program that runs and handles     life-cycle of containers and images</li> <li>DockerHub: an official registry of docker containers, operated     by Docker. DockerHub</li> <li>DOI: a digital object identifier. A persistant identifier     number, managed by the doi.org</li> <li>Dockerfile: a text document that contains all the commands you     would normally execute manually in order to build a Docker image.     Docker can build images automatically by reading the instructions     from a Dockerfile</li> </ul> <p>E</p> <ul> <li>environment: software that includes operating system, database     system, specific tools for analysis</li> <li>entrypoint: In a Dockerfile, an ENTRYPOINT is an optional     definition for the first part of the command to be run</li> </ul> <p>F</p> <ul> <li>FOSS: (1) Free and Open Source Software, (2)     Foundational Open Science Skills - this class!</li> <li>function: a named section of a program that performs a specific     task</li> </ul> <p>G</p> <ul> <li>git: a version control system software</li> <li>gitter: a Github based messaging service that uses markdown     gitter.im</li> <li>GitHub: a website for hosting <code>git</code> repositories - owned by     Microsoft GitHub</li> <li>GitLab: a website for hosting <code>git</code> repositories     GitLab</li> <li>GitOps: using <code>git</code> framework as a means of deploying     infrastructure on cloud using Kubernetes</li> <li>GPU: graphic processing unit</li> <li>GUI: graphical user interface</li> </ul> <p>H</p> <ul> <li>hack: a quick job that produces what is needed, but not well</li> <li>HPC: High Performance Computer, for large syncronous computation</li> <li>HTC: High Throughput Computer, for many parallel tasks</li> </ul> <p>I</p> <ul> <li>IaaS: Infrastructure as a Service.     online services that provide APIs</li> <li>iCommands: command line application for     accessing iRODS Data Store</li> <li>IDE: integrated development environment, typically a graphical     interface for working with code language or packages</li> <li>instance: a single virtul machine</li> <li>image: self-contained, read-only 'snapshot' of your applications     and packages, with all their dependencies</li> <li>iRODS: an open source integrated Rule-Oriented Data Management     System, iRODS.org</li> </ul> <p>J</p> <ul> <li>Java: programming language, class-based, object-oriented</li> <li>JavaScript: programming language</li> <li>JSON: Java Script Object Notation, data interchange format that     uses human-readable text</li> <li>Jupyter(Hub,Lab,Notebooks): an IDE, originally the     iPythonNotebook, operates in the browser Project     Jupyter</li> </ul> <p>K</p> <ul> <li>kernel: central component of most operating systems (OS)</li> <li>Kubernetes: an open source container orchestration platform     created by Google Kubernetes is often     referred to as <code>K8s</code></li> </ul> <p>L</p> <ul> <li>lib: a UNIX library</li> <li>linux: open source Unix-like operating system</li> </ul> <p>M</p> <ul> <li>makefile: a file containing a set of directives used by a make     build automation tool</li> <li>markdown: a lightweight markup language with plain text     formatting syntax</li> <li>metadata:: data about data, useful for searching and querying</li> <li>multi-thread: a process which runs on more than one CPU or GPU     core at the same time</li> <li>master node: responsible for deciding what runs on all of the     cluster's nodes. Can include scheduling workloads, like     containerized applications, and managing the workloads' lifecycle,     scaling, and upgrades. The master also manages network and storage     resources for those workloads</li> <li>Mac OS X: Apple's popular desktop OS</li> </ul> <p>N</p> <ul> <li>node: a computer, typically 1 or 2 core (with many threads)     server in a cloud or HPC center</li> </ul> <p>O</p> <ul> <li>ontology: formal naming and structural hierarchy used to     describe data, also called a knowledge     graph</li> <li>organization: a group, in the context of GitHub a place where     developers contribute code to repositories</li> <li>Operating System (OS): software that manages computer hardware,     software resources, and provides common services for computer     programs</li> <li>Open Science Grid (OSG): national, distributed computing     partnership for data-intensive research     opensciencegrid.org</li> <li>ORCID: Open Researcher and Contributor ID     (ORCiD), a persistent digital identifier that     distinguishes you from every other researcher</li> </ul> <p>P</p> <ul> <li>PaaS: Platform as Service run     and manage applications in cloud without complexity of developing it     yourself</li> <li>package: an app designed for a particular langauge</li> <li>package manager: a collection of software tools that automates     the process of installing, upgrading, configuring, and removing     computer programs for a computer's operating system in a consistent     manner</li> <li>Production: environment where users access the final code after     all of the updates and testing</li> <li>Python: interpreted, high-level, general-purpose programming     language Python.org</li> </ul> <p>Q</p> <ul> <li>QUAY.io: private Docker registry QUAY.io</li> </ul> <p>R</p> <ul> <li>R: data science programming language R Project</li> <li>recipe file: a file with installation scripts used for building     software such as containers, e.g. Dockerfile</li> <li>registry: a storage and content delivery system, such as that     used by Docker</li> <li>remote desktop: a VM with a graphic user interface accessed via     a browser</li> <li>repo(sitory): a directory structure for hosting code and data</li> <li>RST: ReStructuredText, a markdown type file</li> <li>ReadTheDocs: a web service for rendering documentation (that     this website uses) readthedocs.org and     readthedocs.com</li> <li>root: the administrative user on a linux kernel - use your     powers wisely</li> </ul> <p>S</p> <ul> <li>SaaS: Software as a Service web     based platform for using software</li> <li>schema: a metadata standard for labeling, tagging or coding for     recording &amp; cataloging information or structuring descriptive     records. see schema.org</li> <li>scrum: daily set of tasks and evalautions as part of a sprint.</li> <li>shell: is a command line interface program that runs other     programs (may be complex, technical programs or very simple programs     such as making a directory). These simple, stand-alone programs are     called commands</li> <li>Singularity: a container software, used widely on HPC, created     by SyLabs</li> <li>SLACK: Searchable Log of All Conversation and Knowledge, a team     communication tool slack.com</li> <li>sprint: set period of time during which specific work has to be     completed and made ready for review</li> <li>Singularity def file: (definition file) recipe for building a     Singualrity container</li> <li>Stage: environment that is as similar to the production     environment as can be for final testing</li> </ul> <p>T</p> <ul> <li>tar: software utility for collecting many files into one archive     file, often referred to as a tarball</li> <li>tensor: algebraic object that describes a linear mapping from     one set of algebraic objects to another</li> <li>terminal: a windowed emulator for directly enterinc commands to     a computer</li> <li>thread: a CPU process or a series of linked messages in a     discussion board</li> <li>tool: In the context of CyVerse Discovery Environment, a Docker     Container</li> <li>TPU: tensor processing unit</li> <li>Travis: Travis-CI, a continuous     integration software</li> </ul> <p>U</p> <ul> <li>Ubuntu: most popular Linux OS     distribution, based on Debian</li> <li>UNIX: operating system</li> <li>user: the profile under which applications are started and run,     <code>root</code> is the most powerful system administrator</li> </ul> <p>V</p> <ul> <li>VICE: Visual Interactive Computing     Environment -     Cyverse Data Science Workbench</li> <li>virtual machine: is a software computer that, like a physical     computer, runs an operating system and applications</li> </ul> <p>W</p> <ul> <li>waterfall: software development broken into linear sequential     phases, similar to a Gantt chart</li> <li>webGL: JavaScript API for rendering interactive 2D and 3D     graphics within any compatible web browser without the use of     plug-ins</li> <li>Windows: Microsoft's most popular desktop OS</li> <li>workspace: (vs. repo)</li> <li>worker node: A cluster typically has one or more nodes, which     are the worker machines that run your containerized applications and     other workloads. Each node is managed from the master, which     receives updates on each node's self-reported status.</li> </ul> <p>X</p> <ul> <li>XML: Extensible Markup Language, data interchange format that     uses human-readable text</li> </ul> <p>Y</p> <ul> <li>YAML: YAML Ain't Markup Language, data interchange format that     uses human-readable text</li> </ul> <p>Z</p> <ul> <li>ZenHub: team collaboration solution built directly into GitHub     that uses kanban style boards</li> <li>Zenodo: general-purpose open-access repository developed under     the European OpenAIRE program and operated by CERN</li> <li>zip: a compressed file format</li> <li>zsh: Z-Shell, now the default shell on     new Mac OS X</li> </ul>"},{"location":"installation/","title":"Pre-FOSS Setup","text":"<p>Welcome to FOSS Online, we're happy you're here! To get you ready to hit the ground running, please set up the prerequisite accounts and software listed below before the course starts.</p>"},{"location":"installation/#account-creation","title":"Account Creation","text":"<p>We will be using several services that require you to create a user account.</p> Account Notes  GitHub GitHub will be used to store lecture materials and your own work. We will use GitHub Education and its free features for hands-on.  Docker Link your GitHub account to the DockerHub.  Slack We use the <code>UA Data Science</code>  Slack organization's foss channel, you should have received an invitation via email. You can use Slack in the browser, but the desktop app is usually less buggy.  HackMD We will use HackMD in order to facilitate daily discussions, questions and general notes. Link your HackMD using your GitHub account Cyverse We will introduce you to Cyverse which is a powerful cloud computer with large data storage. <p>Link to  HackMD</p> <p>https://hackmd.io/-4TgToyFRU2eX7lmDZLRnQ?both</p> Dual Monitors vs Side-by-Side <p>We strongly recommend you have dual monitors set-up while attending virtual FOSS Zoom lessons.</p> <p>We will be doing a lot of screen-sharing, and this will make your own interactive sessions less visible, or you will have to make them less than full screen.</p> <p>If you only have one monitor, make sure to exit full screen mode on Zoom and your browser, so you can view everything side-by-side</p>"},{"location":"installation/#required-software","title":"Required Software","text":"<p>You will need to have the following software installed on your personal computer:</p> Software Notes Web Browser  Chrome or  Firefox. Text Editor  VS Code or SublimeText <p>Attention  Windows users</p> <p>Much of what we are going to be teaching is based on open-source software which operates on cloud and is incompatible with Windows OS.</p> <p>Unix-based systems such as Linux  Ubuntu and  MacOS X, as many scientific tools require a Unix Operating System (OS). </p> <p>There are a number of software that allow Windows users to execute Unix commands, however we recommend the use of  Windows Subsystem for Linux (WSL) 2.0.</p> <p> VS Code is a Microsoft product and integrates seamlessly with Unix systems, we therefore strongly encourage you to install Code on your Windows OS.</p>"},{"location":"nextflow/","title":"Nextflow","text":""},{"location":"nextflow/#automation-workflow-management-with-nextflow-and-snakemake","title":"Automation: Workflow Management with Nextflow and Snakemake","text":"<p>Workflow management is key to automation: it helps with bridging the gap between software, creating useful pipelines that help extracting information from data. Two examples of workflow management system popular (but not restricted to!) within the field of Bioinformatics are Nextflow and Snakemake. </p> <p>Both workflow managers are powerful tools that tackle reproducibility and scalability, however the two have some key differences:</p> Feature Snakemake Nextflow Language style Python-based DSL* Groovy-based DSL* Execution Model Rule-based Dataflow-driven Parallelization and Resource Management Implicit parallelization, limited resource management Explicit parallelization, more flexible resource management Integration seamless with Python seamless with Java** <p>* = Domain Specific Langauge  ** = No, it does not mean you need to learn Java</p> <p>Although there are differences between the two workflow managers, there are a number of features which both share:</p> <ul> <li>Available on all OS</li> <li>Well integrated with Conda</li> <li>Support the use of Containers</li> <li>Deployable on HPC systems</li> <li>Integrated error reporting</li> <li>Well established communities***</li> </ul> <p>*** = It should be noted that Nextflow has a community driven repository, nf-core, where people can upload their Nextflow pipelines for others to use. Power to the people!</p> <p>Both are incredibly powerful when it comes to creating pipelines, ultimately the choice on which to use depends on you (and the goal of your project). </p> <p>Here are a couple of script examples for each workflow manager. Although different, the examples try to </p> <ol> <li>Download a genome</li> <li>Align reads using BWA (Burrows-Wheeler Aligner tool)</li> <li>Gather aignment statistics using Samtools (Sequence Alignment/Map)</li> </ol> <p>Snakemake:</p> <pre><code># Snakefile\n\n# Define rule for downloading reference genome\nrule download_reference_genome:\n    output:\n        \"reference_genome.fa\"\n    shell:\n        \"wget http://example.com/reference_genome.fa\"\n\n# Define rule for aligning reads to the reference genome using BWA\nrule align_reads:\n    input:\n        \"reference_genome.fa\",\n        fastq=\"data/{sample}.fastq\"\n    output:\n        \"aligned/{sample}.bam\"\n    shell:\n        \"bwa mem {input.reference_genome} {input.fastq} | samtools view -b - &gt; {output}\"\n\n# Define rule to aggregate alignment statistics\nrule aggregate_stats:\n    input:\n        expand(\"aligned/{sample}.bam\", sample=config['samples'])\n    output:\n        \"alignment_stats.txt\"\n    shell:\n        \"samtools flagstat {input} &gt; {output}\"\n\n# Define samples\nconfigfile: \"config.yaml\"\n</code></pre> <p>Notice how in the Snakefile above, there are a set number of rules that define input, output and commands.</p> <p>Nextflow:</p> <pre><code>// main.nf\n\nparams.samples = ['sample1', 'sample2', 'sample3']\n\n// Define process to download reference genome\nprocess download_reference_genome {\n    output:\n    file('reference_genome.fa')\n\n    script:\n    \"\"\"\n    wget http://example.com/reference_genome.fa -O reference_genome.fa\n    \"\"\"\n}\n\n// Define process to align reads using BWA\nprocess align_reads {\n    input:\n    file(reference_genome), file(fastq) from fastqs\n\n    output:\n    file(\"aligned/${sample}.bam\")\n\n    script:\n    \"\"\"\n    bwa mem ${reference_genome} ${fastq} | samtools view -b - &gt; aligned/${sample}.bam\n    \"\"\"\n}\n\n// Define process to aggregate alignment statistics\nprocess aggregate_stats {\n    input:\n    set file(aligned_bam) from aligned_bams\n\n    output:\n    file(\"alignment_stats.txt\")\n\n    script:\n    \"\"\"\n    samtools flagstat ${aligned_bam} &gt; alignment_stats.txt\n    \"\"\"\n}\n\n// Define workflow execution\nworkflow {\n    // Define input data\n    Channel.fromPath(\"data/*.fastq\").set { fastqs }\n\n    // Execute processes in parallel\n    download_reference_genome()\n    align_reads(fastqs)\n    aggregate_stats()\n}\n</code></pre> <p>The Nextflow file \"forces\" you to know what you are expecting prior to execution by first defining what you want processes you need before defining the workflow script. </p> <p>Although not shown here, Nextflow uses \"Channels\" to help with workflow execution. A channel can have one or more defined processes, but it can \"wait\": these processes wait until the input is ready before executing, thus creating the possibilty of an asynchronous processing pipeline (and parallel processing!). This is also what makes Nextflow able to manage resources better than Snakemake (the processes in \"inactive\" channels do not use resources until they are needed). </p>"},{"location":"nextflow/#reproducibility-tutorial","title":"Reproducibility Tutorial","text":"<p>This section is going to cover a short tutorial on reproducibility using software, tools and practices discussed today and throughout FOSS.</p> <p>OS of choice</p> <p>This tutorial will be performed using the CyVerse CLI (Command Line Interface). However, if you'd like to use your own computer feel free to! If you're on Mac or Linux, open your terminal; If you're on Windows, use the Windows Subsystem for Linux (WSL)</p> How to Scroll in Cyverse(Tmux) Cloud Shell <p>If you're using the Cyverse Cloud Shell, you can scroll up and down by pressing <code>Ctrl + b</code> and then <code>[</code> to enter scroll mode. You can then use the arrow keys to scroll up and down. Press <code>q</code> to exit scroll mode.</p> <p>Tutorial Goals</p> <ul> <li>Run a small workflow using NextFlow</li> <li>Understand best practices for reproducing a workflow</li> <li>Apply FOSS procedures in order to enable easiness of reproducibility</li> </ul>"},{"location":"nextflow/#prerequisites","title":"Prerequisites","text":"<p>What you'll be using:</p> <ul> <li>GitHub (already installed)</li> <li>Conda</li> <li>Mamba (optional, recommended)</li> </ul> <p>Installable through Conda/Mamba:</p> <ul> <li>Nextflow</li> <li>Salmon</li> <li>FastQC</li> </ul> <p>Installabe through Pip:</p> <ul> <li>MultiQC</li> </ul> What's a Conda and how do I install it? <p>Conda is a popular tool for installing software. Typically software you want to use requires other software (dependancies) to be installed. Conda can manage all of this for you. Each available Conda package is part of a \u201crecipe\u201d that includes everything you need to run your software. There are different versions of Conda, including some specific for bioinformatics like Bioconda.</p> <p>The CyVerse CLI already comes with Conda installed; Please follow these steps in order to install MiniConda (the lightweight version of Conda) on your system.</p> <p>For the appropriate installation package, visit https://docs.conda.io/en/latest/miniconda.html.  Note: If you are using the WSL, install the Linux version!!</p> <pre><code># Download conda and add right permissions\nwget https://repo.anaconda.com/miniconda/Miniconda3-py39_4.12.0-Linux-x86_64.sh     # Modify this to match the OS you're using.\nchmod +x Miniconda3-py39_4.12.0-Linux-x86_64.sh\n\n# install conda silenty (-b) and update (-u) and initial conda run\n./Miniconda3-py39_4.12.0-Linux-x86_64.sh -b -u\n~/miniconda3/bin/conda init\n\n# Restart bash so that conda is activated\nsource ~/.bashrc\n</code></pre> <p>You'll be able to tell when conda is active when next <code>(base)</code> is present next to the to the shell prompt such as</p> <pre><code>(base) user@machine\n</code></pre> <p>Conda should now be installed and can be used to install other necessary packages! </p> <p>When you start a Cyverse Cloud shell, it will start you in the directory:  <pre><code>/home/user/work \n</code></pre> Let's change to the Data-Store directory, where we will be working for the rest of the tutorial. This is the Cyverse cloud-storage directory where you can put all your data and files. </p> <p><pre><code>cd home\ncd &lt;username&gt;\n</code></pre> Create our own environment (select <code>y</code> when prompted).</p> <pre><code>conda create --name myenv\n</code></pre> <p>Activate your new environment with </p> <pre><code>conda activate myenv\n</code></pre> <p>You can see the list of environments you can activate by doing</p> <pre><code>conda env list\n</code></pre>"},{"location":"nextflow/#package-management-with-conda","title":"Package management with Conda","text":"<p>We are going to to use conda to install Mamba, NextFlow, Salmon and FastQC.</p> <pre><code># Activate Conda using \nconda activate\n\n# Install Mamba\nconda install -c conda-forge mamba\n</code></pre> <p>You can either use the anaconda website to search for packager, or use the conda search feature (but also, Google is your best friend.)</p> <p>Makes things faster with Mamba</p> <p>Mamba is a reimplemetation of Conda using the C++ language, allowing for much quicker Conda experience. The tutorial is going to use Mamba instead of Conda, but you can always replace <code>mamba</code> with <code>conda</code>!</p> <p>Conda channels</p> <p>Conda operates through channels, specififc repositories where packages are stored. Specific packages sometimes may appear in multiple channels, however it is always helpful to specify a channel with the <code>-c</code> flag.</p> <p>Install Nextflow and verify its installation with the following commands: </p> <pre><code># Install NextFlow\nmamba install -c bioconda nextflow=22.10.6     # Press y when prompted with [Y/n]!\n\n# verify the installation\nnextflow -version\n</code></pre> <p>Now that you know how to install packages with Conda/Mamba, install Salmon and FastQC.</p> Installing Packages <p>As an exercise, install Salmon and FastQC using Conda/Mamba.</p> Need a hand? <pre><code>mamba install -c bioconda salmon\nmamba install -c bioconda fastqc\n</code></pre> <p>Or you can do it with a single line (doable if packages are from the same channel)! <pre><code>mamba install -c bioconda salmon fastqc\n</code></pre></p> <p>You can view the installed conda packages by doing </p> <pre><code>conda list\n</code></pre> <p>In order to make your environment reproducible, conda allows you to export your environment.</p> <pre><code>conda env export &gt; my_conda_env.yml\n</code></pre>"},{"location":"nextflow/#package-management-with-pip","title":"Package management with Pip","text":"<p>Pip works similarly to Conda, as Pip is the package management supported by the Python Software foundation. If you use Python for your work it is likely you have installed packages using Pip.</p> <p>We only have to install a single package required for this tutorial, MultiQC. To install MultiQC using Pip, do:</p> <pre><code>pip install multiqc\n</code></pre> <p>Similar to Conda, you can export your pip environment by doing</p> <pre><code>pip3 freeze &gt; my_pip_env.txt\n</code></pre> <p>Why <code>pip3</code>?</p> <p><code>pip3 freeze &gt; my_pip_env.txt</code> is used to export the pip environment such that it is readable for Python 3. If you want to export an environment for Python 2, you can use <code>pip freeze &gt; my_pip_env.txt</code>.</p> <p>Conda exports your Pip environment as well</p> <p>Exporting your environment using Conda (<code>conda env export &gt; my_conda_env.yml</code>) will ALSO export your pip environment!</p>"},{"location":"nextflow/#workflow-tutorial-using-nextflow","title":"Workflow Tutorial using Nextflow","text":"<p>...what are we doing?</p> <p>In this tutorial (now that we have set up the environment, repository and pushed our first commit) we are going to:</p> <ul> <li>Index a transcriptome file and quantification of DNA reads (using Salmon).</li> <li>Perform quality controls (with FastQC).</li> <li>Create a MultiQC report.</li> </ul> <p>I Don't know DNA stuff, can I still do this?</p> <p>Absolutely yes! This tutorial is supposed to introduce you to the process of reproducibility using GitHub repositories, package managers and workflow managers! You do not need to understand what each file is as this is meant to show how to make your science reproducible. Focus on understanding the process and theory behind the tutorial rather than the files themselves .</p> <p>Nextflow is a workflow manager, similar to Snakemake. For this tutorial, we decided to use Nextflow as it is easier to learn, more intuitive and user friendly than Snakemake.</p> <p>Download the required files using <code>wget</code> and <code>tar</code> to decompress them</p> <pre><code>wget -O nf_foss_tut.tar.gz https://github.com/CyVerse-learning-materials/foss/blob/mkdocs/docs/assets/tutorials/nf_foss_tut.tar.gz?raw=true\ntar -xvf nf_foss_tut.tar.gz\n</code></pre> <p>We can now look at the decompressed directory structure by using <code>tree nf_foss_tut</code> (if you don not have <code>tree</code> installed, you can install it with <code>sudo apt-get tree</code> or <code>mamba install -c conda-forge tree</code>).</p> <pre><code>.\n\u251c\u2500\u2500 nf_foss_tut\n\u2502   \u251c\u2500\u2500 data\n\u2502   \u2502   \u2514\u2500\u2500 ggal\n\u2502   \u2502       \u251c\u2500\u2500 gut_1.fq\n\u2502   \u2502       \u251c\u2500\u2500 gut_2.fq\n\u2502   \u2502       \u251c\u2500\u2500 liver_1.fq\n\u2502   \u2502       \u251c\u2500\u2500 liver_2.fq\n\u2502   \u2502       \u251c\u2500\u2500 lung_1.fq\n\u2502   \u2502       \u251c\u2500\u2500 lung_2.fq\n\u2502   \u2502       \u2514\u2500\u2500 transcriptome.fa\n\u2502   \u251c\u2500\u2500 example_script.nf\n\u2502   \u251c\u2500\u2500 script1.nf\n\u2502   \u251c\u2500\u2500 script2.nf\n\u2502   \u2514\u2500\u2500 script3.nf\n\n2 directories, 11 files\n</code></pre> <p>Files information</p> <ul> <li>Scripts 1 through 3 (<code>script&lt;number&gt;.nf</code>) and <code>example_script.nf</code> are the NextFlow files</li> <li><code>&lt;file&gt;.fq</code> are fastq files, containing DNA sequences and quality scores</li> <li><code>transcriptome.fa</code> is all of the RNA data from the organism (G.gallus)</li> </ul> <p>Let's look at one of the NextFlow files (<code>.nf</code>)</p> <p>Understanding the Nextflow synthax</p> <p>Nextflow is powerful workflow manager as it can be deployed on HPCs and Clouds. However, it does require a little effort in order to understand its synthax. </p> <p>The synthax is broken down into:</p> <ul> <li>Defining parameters early</li> <li>Defining Processes to be executed</li> <li>Defining Channels (blocks that work asynchronously that encapsulate other processes)</li> </ul> <p>More complex scripts include operators (channel manipulation) and executors (to run things on the cloud and HPC); Nextflow can also be used to run and orchestrate containers.</p> <p>As a good example, let's look at <code>example_script.nf</code>: <pre><code>/*                                                                                      \n    * pipeline input parameters                                                            \n    */                                                                                      \n    params.reads = \"$baseDir/data/ggal/gut_{1,2}.fq\"                                        #\n    params.transcriptome = \"$baseDir/data/ggal/transcriptome.fa\"                            # The parameters are set early in the script\n    params.multiqc = \"$baseDir/multiqc\"                                                     #\n    params.outdir = \"results\"                                                               #\n\n    println \"\"\"\\                                                                            #\n            R N A S E Q - N F   P I P E L I N E                                             #\n            ===================================                                             #\n            transcriptome: ${params.transcriptome}                                          # Print statement that will show once the script\n            reads        : ${params.reads}                                                  # is executed\n            outdir       : ${params.outdir}                                                 #\n            \"\"\"                                                                             #\n            .stripIndent()                                                                  #\n\n    /* \n     * create a transcriptome file object given then transcriptome string parameter\n     */\n    transcriptome_file = file(params.transcriptome)                                         # Convert input file to string\n\n    /* \n     * define the `index` process that create a binary index \n     * given the transcriptome file\n     */\n    process index {                                                                         # First process, named \"index\"\n    conda \"bioconda::salmon\"                                                                # Defines what package is necessary\n                                                                                            #\n    input:                                                                                  ## \n    file transcriptome from transcriptome_file                                              ##\n                                                                                            ## Defines the input and output of the process\n    output:                                                                                 ##\n    file 'index' into index_ch                                                              ##\n                                                                                            #\n    script:                                                                                 #\n    \"\"\"                                                                                     #\n    salmon index --threads $task.cpus -t $transcriptome -i index                            # Command to execute\n    \"\"\"                                                                                     #\n    }                                                                                       #\n\n\n    Channel                                                                                 # Channels allows for scripts to work asynchronously, without waiting for received process.\n    .fromFilePairs( params.reads )                                                          # .fromFilePairs method creates a channel emitting the file pairs matching a \"glob\" pattern provided by the user. \n    .ifEmpty { error \"Cannot find any reads matching: ${params.reads}\"  }                   # .ifEmpty emits a value specified if no input is found.\n    .set { read_pairs_ch }                                                                  # .set operator assigns the channel to a variable whose name is specified as a closure parameter.\n                                                                                            #                \n    process quantification {                                                                # Second process, named \"quantification\"\n    conda \"bioconda::salmon\"                                                                # Defines what package is necessary\n    input:                                                                                  #\n    file index from index_ch                                                                ##\n    set pair_id, file(reads) from read_pairs_ch                                             ##\n                                                                                            ## Defines the input and output of the process\n    output:                                                                                 ##\n    file(pair_id) into quant_ch                                                             ##\n                                                                                            #\n    script:                                                                                 #\n    \"\"\"                                                                                                     #\n    salmon quant --threads $task.cpus --libType=U -i index -1 ${reads[0]} -2 ${reads[1]} -o $pair_id        # Command to execute\n    \"\"\"                                                                                                     #\n    }        \n</code></pre></p> <p>Nextflow has in-depth documentation that can be found here.</p> <p>The 3 scripts' tasks are:</p> <ul> <li>Script 1 creates the transcriptome index file, necessary for downstream processes.</li> <li>Script 2 collects read files by pairs (fastq files come in pairs) and performs quantification.</li> <li>Script 3 performs quality control and summarizes all findings in a single report.</li> </ul>"},{"location":"nextflow/#script-1-indexing-transcriptome","title":"Script 1: Indexing transcriptome","text":"<p>Execute script 1 <pre><code>nextflow run script1.nf\n</code></pre></p> <p>The output will be something similar to <pre><code>N E X T F L O W  ~  version 22.10.6\nLaunching `script1.nf` [admiring_banach] DSL1 - revision: 66baaf0091\nR N A S E Q - N F   P I P E L I N E    \n===================================\ntranscriptome: /home/user/work/folder/nf_foss_tut/data/ggal/transcriptome.fa\nreads        : /home/user/work/folder/nf_foss_tut/data/ggal/*_{1,2}.fq\noutdir       : results\n\nexecutor &gt;  local (1)\n[f0/0a72bc] process &gt; index [100%] 1 of 1 \u2714\n</code></pre> This is Nextflow's way of telling you that the process has been executed and completed. You should now have a new folder called <code>work</code>. Execute <code>tree work</code> to see what is inside the folder. <pre><code>work\n\u2514\u2500\u2500 f0\n    \u2514\u2500\u2500 0a72bc4d10dba1df2899b0449519e9\n        \u251c\u2500\u2500 index\n        \u2502   \u251c\u2500\u2500 duplicate_clusters.tsv\n        \u2502   \u251c\u2500\u2500 hash.bin\n        \u2502   \u251c\u2500\u2500 header.json\n        \u2502   \u251c\u2500\u2500 indexing.log\n        \u2502   \u251c\u2500\u2500 quasi_index.log\n        \u2502   \u251c\u2500\u2500 refInfo.json\n        \u2502   \u251c\u2500\u2500 rsd.bin\n        \u2502   \u251c\u2500\u2500 sa.bin\n        \u2502   \u251c\u2500\u2500 txpInfo.bin\n        \u2502   \u2514\u2500\u2500 versionInfo.json\n        \u2514\u2500\u2500 transcriptome.fa -&gt; /home/user/work/folder/nf_foss_tut/data/ggal/transcriptome.fa\n\n3 directories, 11 files\n</code></pre> These are new index files from the transcriptome provided.</p>"},{"location":"nextflow/#script-2-collecting-pairs-and-performing-quantification","title":"Script 2: collecting pairs and performing quantification","text":"<p>Execute with <pre><code>nextflow run script2.nf -resume --reads 'data/ggal/*_{1,2}.fq'\n</code></pre></p> <p>The output should look like <pre><code>N E X T F L O W  ~  version 22.10.6\nLaunching `script2.nf` [stupefied_swirles] DSL2 - revision: d3b0d0121c\nR N A S E Q - N F   P I P E L I N E    \n===================================\ntranscriptome: /home/user/work/folder/nf_foss_tut/data/ggal/transcriptome.fa\nreads        : data/ggal/*_{1,2}.fq\noutdir       : results\n\nexecutor &gt;  local(3)                                                                                \n[c1/6ece54] process &gt; index [100%] 1 of 1, cached: 1 \u2714                          \n[1b/10b8d5] process &gt; quantification (1) [100%] 3 of 3 \u2714\n</code></pre></p>"},{"location":"nextflow/#script-3-qc-and-report","title":"Script 3: QC and report","text":"<p>Execute with <pre><code>nextflow run script3.nf -resume --reads 'data/ggal/*_{1,2}.fq'\n</code></pre></p> <p>The output should look like  <pre><code>N E X T F L O W  ~  version 22.10.6\nLaunching `script3.nf` [voluminous_goodall] DSL1 - revision: d118356290\nR N A S E Q - N F   P I P E L I N E    \n===================================\ntranscriptome: /home/user/work/folder/nf_foss_tut/data/ggal/transcriptome.fa\nreads        : data/ggal/*_{1,2}.fq\noutdir       : results\n\nexecutor &gt;  local (4)\n[c1/6ece54] process &gt; index                   [100%] 1 of 1, cached: 1 \u2714\n[7a/4e9ce4] process &gt; quantification (lung)   [100%] 3 of 3, cached: 3 \u2714\n[34/d60dbb] process &gt; fastqc (FASTQC on lung) [100%] 3 of 3 \u2714\n[e9/e7c392] process &gt; multiqc                 [100%] 1 of 1 \u2714\n\nDone! Open the following report in your browser --&gt; results/multiqc_report.html\n</code></pre></p> <p>As you can notice, the report is an <code>html</code> file that can be opened with a browser. Navigate to this file in the Cyverse Data Store and open it. </p>"},{"location":"nextflow/#essential-exercise-documenting-your-work","title":"Essential Exercise: Documenting your Work","text":"<p>Document your work. You should still be in your GitHub folder. Summarize your steps and work on your README file, and push your changes! This will ensure that your work and files are saved and have a valid version that you can come back to in the future if you ever require to.</p> <p>Prerequisites</p> <p>You will require the following in case you want to add code locally.</p> Create a GitHub account <p>Navigate to the GitHub website and click Sign Up, and follow the on screen instructions.</p> <p>Installing Git</p> <p>You can follow the official guidelines here: https://github.com/git-guides/install-git. Here we recommend how to install Git on your local machine.</p> Windows <p>These instructions are for Windows users NOT using WSL2. If you do have WSL2, follow the Unix instructions.</p> <ol> <li>Navigate to the latest Git for Windows installer and download the latest version.</li> <li>Once the installer has started, follow the instructions as provided in the Git Setup wizard screen until the installation is complete.</li> <li>Search and open Git Bash. From here, you should be able to run Git commands.</li> </ol> MacOS <ol> <li>Install Homebrew (a package manager for MacOS): `/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"``</li> <li>Install Git: <code>brew install git</code></li> </ol> Unix <p>The following command will install git and all related packages on your Unix machine. <pre><code>$ sudo apt-get install -y git-all\n</code></pre></p> <p>Additionally, you can choose between Generating a Personal Access Token or using SSH keys. This is useful if you want to work locally and push your changes to GitHub. We are going to cover this further in next week's lesson on Version Control.</p> Choice A: Generate a Personal Access Token <p>You can follow the official documentation on how to generate Tokens here. We  discussed how to generate tokens in Week 0. Here's are quick steps you can follow in order to setup your account on your machine using tokens:</p> <ol> <li>On your coumputer:<ol> <li>Clone your repository (<code>git clone &lt;repository&gt;</code>)</li> <li>Make changes where necessary, and add (<code>git add &lt;changed files&gt;</code>), commit (<code>git commit -m \"&lt;message on changes&gt;\"</code>) and push your changes (<code>git push origin</code>).</li> <li>You should be prompted to logging in your GitHub account. Put your email but not your password. Instead, open your web browser and follow the steps below:</li> </ol> </li> <li>On GitHub:<ol> <li>Navigate to your GitHub Settings (You can access your account Settings from the drop down menu where your account icon is, on the top right of the screen)</li> <li>Scroll to the bottom of the left hand side menu to find Developer settings and open it.</li> <li>Click Personal access tokens &gt; Tokens (classic)</li> <li>Click Generate new token &gt; Generate new token (classic). You might need to input your Authentification code if you have enabled 2FA.</li> <li>Give it a name, and all the scopes you require (tip: select all scopes and No Expiration), then click Generate Token. Copy the new generated Token</li> </ol> </li> <li>Back on your computer:<ol> <li>If you have been following the steps above, you should still be in your shell with GitHub still asking for your password.</li> <li>Paste your Token here, and you should be logging in. Your changes should then be saved to GitHub.</li> </ol> </li> </ol> Choice B: Connecting via SSH <p>The process of connecting your computer to GitHub using an SSH key is more expedited (and probably less confusing). </p> <p>As a setup step, see if your computer is already connected to GitHub by doing <code>ssh -T git@github.com</code>. If the response message is <code>git@github.com: Permission denied (publickey).</code> it signifies that your computer is not yet linked with GitHub. To link your computer to github to the following:</p> <ol> <li>Generate an SSH key with a level of encryption that you prefer: <code>ssh-keygen -t ed25519 -C &lt;your github email&gt;</code>. This command generates an SSH key with ed25519 encryption (harder to crack!) and adds your email as \"comment\" (<code>-C</code>, will help recongizing the user adding the key). A number of additional questions are going to ask you where you'd like to save the key and whether you'd like to add a password for protection; unless you want to save it elsewhere, feel free to use the default options. Upon completion you should see something like this: <pre><code>Your identification has been saved in /c/Users/&lt;user&gt;/.ssh/id_ed25519\nYour public key has been saved in /c/Users/&lt;user&gt;/.ssh/id_ed25519.pub\nThe key fingerprint is:\nSHA256:SMSPIStNyA00KPxuYu94KpZgRAYjgt9g4BA4kFy3g1o &lt;your github email&gt;\nThe key's randomart image is:\n+--[ED25519 256]--+\n|^B== o.          |\n|%*=.*.+          |\n|+=.E =.+         |\n| .=.+.o..        |\n|....  . S        |\n|.+ o             |\n|+ =              |\n|.o.o             |\n|oo+.             |\n+----[SHA256]-----+\n</code></pre></li> <li>Upon generating the ssh key, copy it. You can reveal it by doing <code>cat ~/.ssh/id_ed25519.pub</code>.</li> <li>In GitHub, go to your settings: click your account icon on top right, and from the drop down menu, select Settings and then SSH and GPG keys. Here, click on New SSH Key, where you can then paste the newly geneated key. Add a name reflecting your machine and save changes. </li> </ol> <p>Optional: if you want to check if you successfully linked your computer to GitHub, do <code>ssh -t git@github.com</code>. You should receive the following message: `Hi ! You've successfully authenticated, but GitHub does not provide shell access. What if my files are too big? <p>You can always use a <code>.gitignore</code>, a file that within itself has defined what should be saved in GitHub when pushing a commit, and what shouldn't be saved. An alternative is to move your files outside of the respository that you're pushing (\"stashing\").</p>"},{"location":"nextflow/#github-repository-setup-and-documentation","title":"GitHub repository setup and documentation","text":"<p>Create a repository on GitHub to document your work:</p> <ul> <li>On GitHub, navigate to your account page and create a new repository (add a README to create structure!)</li> <li>Clone your repository locally with <code>git clone &lt;repository_url&gt;.git</code> (find the url under the green Code button)</li> <li>Navigate to your cloned repository with <code>cd &lt;repository_name&gt;</code>. You should now be inside your repository.</li> <li>Move your environemnt files into your repository with <code>mv ../my_conda_env.yml ../my_pip_env.txt .</code>.</li> <li>Modify your README to reflect the work so far, with meaningful comments (remember that the README is formatted with markdown, a guide to markdown here). A well documented document may look similar to:</li> </ul> <pre><code># reproducibility-tutorial\n\nThis repository contains information about the reproduciblility tutorial from [FOSS 2023 Spring](https://foss.cyverse.org/06_reproducibility_i/#reproducibility-tutorial).\n\n## Environment Setup\n\n- Download conda and add right permissions\n```\nwget https://repo.anaconda.com/miniconda/Miniconda3-py39_4.12.0-Linux-x86_64.sh\nchmod +x Miniconda3-py39_4.12.0-Linux-x86_64.sh\n```\n- Install conda silenty (-b), update (-u) and initial start\n```\n./Miniconda3-py39_4.12.0-Linux-x86_64.sh -b -u\n~/miniconda3/bin/conda init\n```\n-  Restart bash so that conda is activated\n```\nsource ~/.bashrc\n```\n- Install Mamba\n```\nconda install -c conda-forge mamba\n```\n- Use environment files in this repo to recreate tutorial env\n```\nmamba install -f &lt;my_conda_env.yml&gt;     # Will also install pip packages\n```\n\n## Obtaining tutorial files\n\nTutorial files avaiable [here](https://github.com/CyVerse-learning-materials/foss/blob/mkdocs/docs/assets/tutorials/nf_foss_tut.tar.gz?raw=true). Use `wget` to download appropriate files and decompress files with `tar -xvf`.\n```\nwget -O nf_foss_tut.tar.gz https://github.com/CyVerse-learning-materials/foss/blob/mkdocs/docs/assets/tutorials/nf_foss_tut.tar.gz?raw=true\ntar -xvf nf_foss_tut.tar.gz\n```\n\n## Workflow tutorial using Nextflow\nSteps of the nextflow tutorial will be added in future commits.\n</code></pre> <ul> <li>Add, commit and push your changes</li> </ul> <pre><code>git add .\ngit commit -m \"documenting the tutorial\"\ngit push\n</code></pre>"},{"location":"old.02_project_management/","title":"Introduction to Project Management","text":"<p>Learning Objectives</p> <p>After this lesson, you should be able to:</p> <ul> <li>Discuss different levels of project management</li> <li>Describe tools and approaches to managing collaborative projects</li> <li>Describe best practices for computational project organization</li> <li>Understand benefits of establishing project management practices from the start of a project until after it ends</li> </ul> <p>\"Project Management\" by itself may sound a bit vague and broad. </p> Definition <p>\"Project management is the use of specific knowledge, skills, tools and techniques to deliver something of value to people. The development of software for an improved business process, the construction of a building, the relief effort after a natural disaster, the expansion of sales into a new geographic market\u2014these are all examples of projects.\" - Project Management Institute </p> <p> Wikipedia definition</p> <p>Here we use the term in two different contexts.</p> <ol> <li> <p>First, we'll go over the project management of scientific labs, groups, and projects, talking about things like governance, how to develop operations manuals, laying out roles and responsibilities, planning steps and the workflows which connect them. </p> </li> <li> <p>Next, we'll go over project management as \"research objects\": making sure your data, code, and documents are well-organized. These are crucial for future topics like version control and reproducibility.</p> </li> </ol>"},{"location":"old.02_project_management/#1-classic-project-management","title":"1. Classic Project Management","text":"<p>This type of overall project management may be required for some grants, and while it may be tempting to put in the minimal effort on one of the many pieces of paperwork you're required to complete, this type of overall project planning can be very useful. </p> Traditional Organizations <p>Major research (R1) universities are organized around hierarchical frameworks, often described using an Organizational Chart.</p> <p> </p> <p>Scientific Research Projects are generally organized around a \"Principal Investigator\" with \"Co-Principal Investigators\" and \"Senior Personnel\" in supporting roles. Postdoctoral Researchers and gradaute students are often employed by research projects as part of their continued education and \"professional preparation\". </p> <p></p> <p>Given the nebulous breakdown of authority within lab groups and small research projects, the organization and governance of teams can be difficult to determine from the outside perspective. Indeed, internally team members on projects often do not know who is in charge or who reports to whom.</p> <p>The Turing Way offer a lesson on Project Design related to effective project planning and management.</p>"},{"location":"old.02_project_management/#project-governance","title":"Project Governance","text":"Definitions <p>Project Governance is the set of rules, procedures and policies that determine how projects are managed and overseen.</p> <p>\"The set of policies, regulations, functions, processes, and procedures and responsibilities that define the establishment, management and control of projects, programmes or portfolios.\" - APM (2012), open.edu</p> <p> Wikipedia Definition</p> <p>No matter how small, i.e., even single person-run projects, a good Project Governance structure can help keep work on track and headed toward a timely finish.</p> <p>Establishing a project governance document at the onset of a project is a good way of setting boundaries, roles and responsibilities, pre-registration about what deliverables are expected, and what the consequences will be for breaking trust.</p> Example Governance Documents <p>Munoz-Torres et al. 2020</p>"},{"location":"old.02_project_management/#research-collaborations","title":"Research Collaborations","text":"<p>Sahneh &amp; Balk et al. (2020) Ten simple rules to cultivate transdisciplinary collaboration in data science, discuss the interactions amongst teams of diverse researchers.</p> <p> Sahneh &amp; Balk et al. (2020) Fig 1. How the rules work together and intersect. There are multiple components in collaborations: person\u2013person interactions, person\u2013technology interactions, person\u2013data interactions, and data\u2013technology interactions. Synergy between these components results in a successful collaboration. </p>"},{"location":"old.02_project_management/#team-roles-and-responsibilities","title":"Team Roles and Responsibilities","text":"<p>It can be easy for certain tasks to slip through the cracks. Established roles and responsibilities of teams can help ensure nobody gets saddled with too much work, and reduces chances of disputes among collaborators.</p> Project Management Professional (PMP)\u00ae <p>A Project Management Professional (PMP)\u00ae certification has been embraced globally as adding value to your professional resume. </p> <p>Academia has also embraced PMP certification as part of continuing education for academic staff and faculty.</p> <p>University of Arizona PMP prep</p> Team roles and titles <p>Again, The Turing Way provide an excellent set of examples of infrastructure job titles and roles on software driven projects:</p> <p>Community Manager - \"responsibilities include establishing engagement, organising community spaces and events, supporting people through inclusive practices, developing and maintaining resources, growing and evaluating use cases and collaborating with people involved in research and scientific communities.\" (1, 2)</p> <p> This image was created by Scriberia for The Turing Way community and is used under a CC-BY 4.0 licence. </p> <p>Data Science Educator - \"... data science in education refers to the application of data science methods, while other times it refers to data science as a context for teaching and learning\" Rosenberg et al. (2020), Estrellado et al.</p> <p>Data Scientist - a professional who uses analytical, statistical, and programming skills to collect, analyze, and describe data.</p> <p>Data Steward - \"... responsible for ensuring the quality and fitness for purpose of the organization's data assets, including the metadata for those data assets.\" - Wikipedia</p> <p>Developer Advocate - sometimes called platform evangelism, advocates represent the voice of the user (in the case of open science, the scientists) internally to the project team or company, and the voice of the project or company externally to the public.</p> <p>DevOps Engineer - a combinination of software development \"Dev\" and IT operations \"Ops\", responsibilities focus on \"continuous delivery\" and agile software development</p> <p>Research Application Manager (RAM) - in some ways a combination of Community Manager and Developer Advocate,</p> <p> Fig. 94 Research Application Managers work with the research team to embed outputs into user organisations. The Turing Way Community, &amp; Scriberia. (2020, November). Illustrations from the Turing Way book dashes. Zenodo. http://doi.org/10.5281/zenodo.4323154 </p> <p>Research Software Engineer - those who regularly use expertise in programming to advance research - US Research Software Engineer (US-RSE) Association</p>"},{"location":"old.02_project_management/#open-source-research-software-maintainer","title":"Open Source Research Software Maintainer","text":"<p>Becoming an open source software maintainer is not to be taken lightly.</p> <p>  Image Credit: XKCD Dependency </p> <p>When you create a new software, library, or package, you are becoming its parent and guardian. </p>"},{"location":"old.02_project_management/#development-methodology","title":"Development Methodology","text":"the \"leaps of faith\" required in Agile vs Waterfall. Image Credit: Wikimedia Commons CC BY 4.0  <p>In software development, there are two common methologies which have similar applications to a research project:</p> <ul> <li> Agile<ul> <li>Scrum</li> <li>Kanban</li> </ul> </li> <li> Waterfall</li> </ul> <p> </p>  the effort distribtion of Agile vs Waterfall. Image Credit: Wikimedia Commons CC BY 4.0  <p>Comparisons between methodologies</p> <ul> <li> <p>LucidChart Blog: Agile vs Waterfall vs Kanban vs Scrum  </p> </li> <li> <p>Ontology of Value: Agile vs Waterfall vs Kanban vs Scrum</p> </li> </ul>"},{"location":"old.02_project_management/#breakout-discussion","title":"Breakout Discussion","text":"<p>Now we will do a breakout discussion section to talk about overall project management.</p> <p>What is an example of a poorly managed project you were involved in? What contributed to this feeling?</p> <p>Why do you think effective project management is important to Open Science?</p> <p>What are some limitations to you, your lab/group, or your domain?</p>"},{"location":"old.02_project_management/#2-research-objects","title":"2. Research Objects","text":"Definition <p>\"A workflow-centric research object bundles a workflow, the provenance of the results obtained by its enactment, other digital objects that are relevant for the experiment (papers, datasets, etc.), and annotations that semantically describe all these objects.\" - Corcho et al. 2012</p> <p>\"... semantically rich aggregations of resources, that can possess some scientific intent or support some research objective.\" - Bechhofer et al. 2010</p> <p> Wikipedia definition</p> <p>When we talk about project management in this section, we mean the way you organize data, code, images, documents, and documentation within a project. One way to think about this is in the context of \"research objects\" which condense into a single end point (think: a URL like a digital object identifier (DOI)) where others can come to reproduce your research. </p> Examples of Research Objects <p>Boettiger 2018</p> <p>Gillan et al. 2021</p> <p>  Research Objects from ResearchObject.org</p> Research Object Services <p>ResearchObject</p> <p>ROHub - Garcia-Silva et al. 2019</p>"},{"location":"old.02_project_management/#research-object-organization","title":"Research Object Organization","text":"<p>If you've ever had to navigate someone else's computer or a GitHub repository, you probably know that a poorly organized project can greatly reduce its accessibility. On the other hand, a well-organized project can:</p> <ul> <li>make your work more accessible to others</li> <li>help collaborators effectively contribute to your project</li> <li>ease the growing pains of a rapidly scaling project</li> <li>make life much easier for your future self</li> </ul> <p>It can be easy to overlook sound project management, opting for a \"just get it done ASAP\" approach to your work, but this almost always costs you more time in the end. The best time to introduce good project management is at the start of a project, and the second best time is right now. </p> <p>  An hour spent reorganizing a project today may save you days of headaches later on.</p>"},{"location":"old.02_project_management/#organization-examples","title":"Organization Examples","text":"<ul> <li>Example data project organization from UArizona Libraries</li> <li>CookieCutter Templates</li> </ul> <p>Example project structure:</p> <pre><code>.\n\u251c\u2500\u2500 AUTHORS.md\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 bin                &lt;- Your compiled model code can be stored here (not tracked by git)\n\u251c\u2500\u2500 config             &lt;- Configuration files, e.g., for doxygen or for your model if needed\n\u251c\u2500\u2500 data\n\u2502   \u251c\u2500\u2500 external       &lt;- Data from third party sources.\n\u2502   \u251c\u2500\u2500 interim        &lt;- Intermediate data that has been transformed.\n\u2502   \u251c\u2500\u2500 processed      &lt;- The final, canonical data sets for modeling.\n\u2502   \u2514\u2500\u2500 raw            &lt;- The original, immutable data dump.\n\u251c\u2500\u2500 docs               &lt;- Documentation, e.g., doxygen or scientific papers (not tracked by git)\n\u251c\u2500\u2500 notebooks          &lt;- Ipython or R notebooks\n\u251c\u2500\u2500 reports            &lt;- For a manuscript source, e.g., LaTeX, Markdown, etc., or any project reports\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 figures        &lt;- Figures for the manuscript or reports\n\u2514\u2500\u2500 src                &lt;- Source code for this project\n    \u251c\u2500\u2500 data           &lt;- scripts and programs to process data\n    \u251c\u2500\u2500 external       &lt;- Any external source code, e.g., pull other git projects, or external libraries\n    \u251c\u2500\u2500 models         &lt;- Source code for your own model\n    \u251c\u2500\u2500 tools          &lt;- Any helper scripts go here\n    \u2514\u2500\u2500 visualization  &lt;- Scripts for visualisation of your results, e.g., matplotlib, ggplot2 related.\n</code></pre> Best Practices <ol> <li> <p>Projects should be self-contained</p> <ul> <li>this is probably the most important concept</li> <li>strictly necessary for version control</li> <li>use relative paths</li> </ul> </li> <li> <p>Use structure to organize files</p> </li> <li> <p>Don't underestimate complexity</p> </li> <li> <p>Keep raw data raw</p> </li> <li> <p>Treat generated output as disposable</p> </li> <li> <p>Avoid manual (point-and-click) steps as much as possible</p> <ul> <li>if necessary, record in detail</li> <li>should also be recorded in prior and subsequent steps</li> </ul> </li> <li> <p>Avoid spaces in file and folder names</p> <ul> <li>consider <code>snake_case</code> <code>camelCase</code> <code>PascalCase</code> <code>kebab-case</code> instead</li> </ul> </li> <li> <p>Describe structure in README</p> </li> <li> <p>The best time to organize is at the start, the 2<sup>nd</sup> best is right now</p> </li> <li> <p>Reorganize if necessary, but don't overdo it</p> </li> <li> <p>Using same basic structure can help you navigate new/old projects</p> </li> </ol> Automate the creation a working directory <p>You might find a nice basic structure that works as a good starting place for many of your projects, or smaller components of big projects.</p> <p>Instead of having to repeat the process of making that directory structure, which could be tedious and introduce mistakes, you could write some code to do it for you. </p> <p>The following is a <code>bash</code> script that takes one argument, the name of the new project (with no spaces), and creates that project with a premade directory structure for you to put files into.</p> <pre><code>#!/usr/bin/env bash\n\n# Run this script with the name of the new project as \n# an argument, like so: `bash make_project.sh my_project`\n# It will generate a project with the following structure:\n\n#.\n#|-- README.md\n#|-- data\n#|   |-- cleaned\n#|   `-- raw\n#|-- images\n#|-- reports\n#`-- scripts\n\nmkdir \"$1\"\n\ncd \"$1\" || exit\n\necho \"# $1\" &gt;&gt; README.md\n\nmkdir data\n\nmkdir data/raw\n\nmkdir data/cleaned\n\nmkdir scripts\n\nmkdir images\n\nmkdir reports\n</code></pre> <p>This approach to automating repetitive tasks is something we'll dig into even deeper in later lessons.</p> Productivity Software <p> CryptPad - online rich text pad. </p> <p> Draw.io - drawings and diagrams in browser.</p> <p> Excel - love it or hate it, many people still work in it or with <code>.xlsx</code> format files. </p> <p> Google Docs - is an online word processor included as part of the free, web-based Google Docs Editors suite offered by Google.</p> <p> HackMD - online markdown editor.</p> <p> JupyterBook - create documentation using Jupyter Notebooks and Markdown</p> <p> MkDocs - is a fast, simple and downright gorgeous static site generator that's geared towards building project documentation.</p> <p> LaTeX -  is a high-quality typesetting system</p> <p> Overleaf - LaTeX online document sharing platform.</p> <p> ReadTheDocs - documentation using a variety of Markup langages</p> <p>Software Heritage - preserves software source code for present and future generations.</p>  Project Management Software <p>OSF.io</p> <ul> <li>Examples</li> </ul> <p> Atlassian</p> <ul> <li> <p> Confluence</p> </li> <li> <p> Jira</p> </li> <li> <p> Trello</p> </li> </ul> <p> GitHub Issues</p> <p>Open Project</p> <p> ZenHub</p> <p>Basecamp</p>"},{"location":"old.02_project_management/#breakout-discussion_1","title":"Breakout Discussion","text":"<p>Now we will do a breakout discussion section to talk about research objects</p> <p>Who here has created a research object or attempted to?</p> <p>Do you think someone could reproduce your research by accessing your research object?</p> <p>Where might a research object not work for your research?</p> <p>What would a research object look like for your research?</p>"},{"location":"old.02_project_management/#other-resources","title":"Other Resources","text":"<p>There are many other resources on more specific elements of project management. We'll link to some of them here.</p> <ul> <li>Using R Projects with RStudio: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects</li> <li>Using the R package <code>here</code>: https://github.com/jennybc/here_here and https://here.r-lib.org/</li> <li>An even more compartmentalized approach to project management: https://hrdag.org/2016/06/14/the-task-is-a-quantum-of-workflow/</li> </ul>"},{"location":"old.02_project_management/#self-assessment","title":"Self Assessment","text":"Why is Project Management used in research? <ol> <li> <p>Reduces [wasted] effort </p> </li> <li> <p>Tracks progress or identifies more quickly when there is a lack of progress</p> </li> <li> <p>Establishes a formal structure for teams</p> </li> </ol> What are established roles and responsibilities of collaborative teams? <p>Example 1: Traditional University Research Teams</p> <p>i. Principal Investigator, Co-Principal Investigators</p> <p>ii. Senior Personnel, Postdoctoral Researchers, Bench Scientists </p> <p>iii. (Graduate) Students</p> <p>Example 2: Research Infrastructure Teams</p> <p>Research infrastructure job titles and roles (Turing Way)</p> <p>i. Community Managers</p> <p>ii. Data Science Educators</p> <p>iii. Data Scientists</p> <p>iv. Developer Advocates</p> <p>iv. Research Software Engineers</p> What are some uses of a Project Governance Document? Answers <ul> <li> <p>Sets expectations for behavior and operations</p> </li> <li> <p>Establishes roles and responsibilities of PI, staff, and senior personnel</p> </li> <li> <p>Uses Pre-registration techniques about what deliverables are expects, and by when </p> </li> <li> <p>Establishes what consequences will be for breaking trust</p> </li> </ul> Research Objects must include all components of research: governance document, manuals, documentation, research papers, analysis code, data, software containers Answers <p>While a Research Object (RO) may include the entire kitchen sink from a research project, it does NOT always contain all of these things.</p> <p>Fundamentally, a RO should contain enough information and detail to reproduce a scientific study from its linked or self-contained parts. </p> <p>Components like large datasets may not be a part of the RO, but the code or analysis scripts should have the ability to connect to or stream those data.</p>"},{"location":"plus_index/","title":"FOSS+ Home &amp; Schedule","text":"<p>Thank you for being with us throughout FOSS! Expanding on the concepts and activities covered throughout FOSS, we wanted to capitalize on certain aspects of reproducibility with FOSS+.</p> <p>In the next 4 weeks, we are going to resume our discussion on Docker and containerization, execution of containers on the HPC and Cloud, and we are going to have 2 guests lectures from Chris Reidy (UITS, covering the HPC in detail) and Shashank Yadav (DataLab, discussing SQL and databases).</p> <p>The workshop structure and schedule will be the same as FOSS: Thursdays 11am - 1pm Arizona Time using the same Zoom link as before.</p>"},{"location":"plus_index/#schedule","title":"Schedule","text":"Date Content Instructor(s) 03/21 Reproducibility III: Building Containers Michele Cosi, Jeff Gillan 03/28 Executing Containers on the HPC Michele Cosi 04/04 The HPC Chris Reidy (UITS) 03/11 SQL and Databases Shashank Yadav (DataLab)"},{"location":"plus_index/#expected-outcomes","title":"Expected Outcomes","text":"<ul> <li>Be able to build your own Container from a public containerized image.</li> <li>Be able to  deploy personalized images onto the HPC.</li> <li>Understand the HPC structure.</li> <li>Understand database structures and execute SQL commands.</li> </ul>"},{"location":"schedule/","title":"Weekly Schedule","text":"<p>Thursdays 11 am - 12:30 pm Arizona Time.</p> <p>This schedule is tentative and subject to change</p>"},{"location":"schedule/#calendar","title":"Calendar","text":"Week Date Content Description Week 1 Sept. 5 Intro to Open Science In the opening session of FOSS will we talk about the big picture of what Open Science is and why do it. We will discuss how an open approach can be applied to many aspects of the scientific process and enhance your individual research. This is our least technical session where we lay out a roadmap for the 12 week workshop. Week 2 Sept. 12 Data management The foundation of any science endeavor is data. In this session we will dive deep into storing, sharing, and managing your datasets. We'll specifically cover data management plans (DMPs) and explain how licenses can allow other researchers to build on your work. Week 3 Sept. 19 Documentation / Communication:  GitHub Pages websites Beyond publications, researchers and labs that are creating shareable assets (e.g., methods &amp; code) need strong documentation to make those assets usable by the scientific community. In this lesson, we will introduce Github as place to document the IP that you want to share with the world. We'll show you how to make a free website to promote your lab, project, or personal career. Week 4 Sept. 26 How to Talk to Computers Behind the veil of graphical point-and-click computing lies the command line, a more direct and powerful way to instruct your computer. In this session we will introduce you to the basics of the Unix command line (aka shell). This skill is not only useful for your personal computer, but also a necessity for cloud and HPC. We will also touch on LLM chatbots because they are changing the game of scientific computing very rapidly. Week 5 Oct. 3 Version Control As you and your colleagues improve your code and docs over time, it can get messy and difficult to know which version is the latest. In this session, we will focus on Git &amp; Github as tools for collaboratively working on projects while keeping track of versions. Week 6 Oct. 10 Reproducibility I:  - Software Environments Have you ever tried to run someone else's code on your machine and it won't work? You are not alone! Sharing reproducible analysis is a significant challenge in scientific research. To help alleviate some of that challenge, we will cover computing environments and package managers that can help your analysis run smoothly regardless of the machine you are using. Week 7 Oct. 17 Reproducibility II:  - Running Containers We will continue on the theme of reproducible analysis code by introducing the concept of software containers. Container technology (e.g., Docker) can free us from having to build a unique environment on the machine we are using. For our hands-on exercise, we will run several simple containers to illustrate how and why to use them. Week 8 Oct. 24 Reproducibility III:  - Building Containers For the third installment of reproducibility, we will look under the hood and show you how to build your own containers. Don't worry,  we'll move at learning pace and keeps things simple. Week 9 Oct. 31 Remote Computing:  - Cyverse Housed the University of Arizona, Cyverse is a one-of-a-kind cloud computing platform with large data storage and a computing environment built for running your customized analysis. Cyverse is free for of U of A personnel and a great alternative to commerical cloud providers. We'll show you how easy it is to use this platform from you laptop. Week 10 Nov. 7 Remote Computing:  - High Performance Computing (HPC) When your laptop just won't cut it for your large-scale analysis, what do you do? You get a bigger computer! In this session, we will cover the basics of high performance computers (HPC) and show you how to logon, navigate, and submit jobs to the University of Arizona HPC. Week 11 Nov. 14 Help Session We will take a break from new content and simply be available to answer any questions related to the workshop content including helping with your personal capstone projects. Week 12 Nov. 21 Capstone Presentations Each Student will present their capstone project!"},{"location":"documentation/githubpages/","title":"GitHub Pages - quick start","text":"<p>This is a quick introduction to GitHub Pages, a simple way to use GitHub to set up a small website written in Markdown. This page won't do everything, but you can throw up a basic website, use themes, and extend it.</p> <ol> <li>Go to https://github.com/. Login, or if you don't have an account get one and login.</li> <li>Go to the \"+\" icon on the upper right and select New repository.</li> <li>Enter a name for your repository (e.g. \"profile\"). Enter a description, and leave the repository as public. Select \"Initialize this repository with a README\". If desired select a license. Finally click Create repository.</li> <li>Look for the Settings menu (upper right, next to a \"gear\" icon). Scroll down to GitHub Pages and choose master branch and save your selection. Then Choose a theme and select your theme. You will be asked to Commit changes.</li> <li>Your website will be visible at <code>https://GITHUBUSERNAME.github.io/REPONAME/</code>. (be sure to change GITHUBUSERNAME to your username, and REPONAME to the name you selected for your repo.)</li> <li>You can edit your website by editing the readme file as desired.</li> </ol> <p>Tip</p> <pre><code>You can preview how your [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) looks using and editor like [Markdown Plus](https://mdp.tylingsoft.com/).\n</code></pre>"},{"location":"final_project/overview/","title":"Capstone Project Overview","text":"<p>The capstone project for FOSS is designed to give you the opportunity to apply some of the skills and ideas from the rest of the course to one of your own projects, get support and feedback from your peers, and share your experiences with the rest of the attendees.</p>"},{"location":"final_project/overview/#objectives","title":"Objectives","text":"<ul> <li>\"Level up\" the openness of an existing or planned project</li> <li>Apply a skill or concept from FOSS</li> <li>Discuss your applied skills/concepts with groupmates</li> <li>Determine possible next steps to \"level up\" your project</li> <li>Share your experiences with the rest of the attendees</li> </ul>"},{"location":"final_project/overview/#description","title":"Description","text":"<p>Choose one (or more) skill(s) or concept(s) from FOSS and apply it to one of your own projects. Here are some example projects you might consider:</p> <p>Example Projects</p> <ul> <li>Make a fully developed Data Management Plan (DMP) for a current or future project</li> <li>Deposit your data in an open repository that is appropriate for your field (cannot be a previous effort)</li> <li>Create a Git repository that shares code or data from a current project. Must have a detailed README that explains exactly how colleagues would use the code or data. Repo should provide an 'environment' file that allows others to reproduce your environment on their computer OR the scripts should be containerized.</li> <li>Create a fully developed personal website hosted in Github</li> <li>Create documentation of a project, tool, or workflow using Mkdocs or similar template</li> <li>Develop an educational tutorial or how-to guide to teach colleagues some aspect of your research. Use mkdocs or similar template on the web.</li> <li>Pre-register a protocol on a platform like Open Science Framework</li> <li>Publish a protocol on protocols.io or other 'protocol' website</li> <li>Conduct an open peer-review of new research in a preprint server</li> <li>Demonstrate how you are using a remote computing resource to run your analyses (e.g., Cyverse, HPC)</li> </ul> <p>You should have your skill/topic chosen by Week 8, and you will then enter your name/topic into a spreadsheet (shared during the week 8 session). We'll use this to help learners find others working on similar projects.</p> <ul> <li>You can do a project completely solo</li> <li>You can work solo, but join a 'support group' to:<ol> <li>discuss your experiences applying your skill or concept</li> <li>give each other help with sticking point you may encounter</li> </ol> </li> <li>You can work directly with a FOSS colleague on a joint project</li> </ul>"},{"location":"final_project/overview/#final-presentations","title":"Final Presentations","text":"<p>Each student or group will deliver a short (3-7 minute) presentation to the rest of the class on the final day of the course (Nov. 21, 2024)</p> <p>Your short presentation should focus on the challenges and tips you may have for other FOSS attendees who want to utilize your skill or concept in the future. Here are some prompts that you should address during your presentation:</p> <p>Presentation Thoughts</p> <ul> <li>What was the general topic or skill that members of your group worked on?</li> <li>What are some challenges you encountered while working on your projects?<ul> <li>Were you able to overcome these challenges? If so, how?</li> <li>Where did you look for help?</li> <li>Do any roadblocks remain? How might you try to overcome them?</li> </ul> </li> <li>Are there any new things you learned while working on your project?<ul> <li>Did you end up using any new or different tools?</li> </ul> </li> <li>What are some tips you might have for other FOSS attendees who want to work on the same topic/skill in the future?<ul> <li>Are there any pitfalls to avoid?</li> </ul> </li> <li>What things do you want to do next?<ul> <li>How might you \"level up\" in the current topic/skill compared to your project's current state?</li> <li>Are there any other FOSS skills that you want to tackle next? If so, how might they integrate with the topic/skill you focused on for your project?</li> </ul> </li> </ul>"}]}